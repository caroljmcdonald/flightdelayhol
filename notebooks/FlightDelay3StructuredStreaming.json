{"paragraphs":[{"text":"%md \n## Using Spark Structured Streaming in a data processing pipeline\nIn this notebook, we will use Spark Structured Streaming in a data processing pipeline for predicting Flight Delays.\nWe will use the machine learning model from the previous notebook to enrich the flight events with flight delay predictions and we will store the results in MapR Database. (Similar to the use case image below, but we are using flight data.) \n\n<img src=\"https://mapr.com/blog/real-time-analysis-popular-uber-locations-spark-structured-streaming-machine-learning-kafka-and-mapr-db/assets/image46.png\" width=\"500\" height=\"500\">\n\n\n## Streaming Data\nMapR Event Store is a distributed publish-subscribe event streaming system that enables producers and consumers to exchange events in real time in a parallel and fault-tolerant manner via the Apache Kafka API.\nA stream represents a continuous sequence of events that goes from producers to consumers, where an event is defined as a key-value pair.\n<img src=\"https://mapr.com/blog/real-time-analysis-popular-uber-locations-spark-structured-streaming-machine-learning-kafka-and-mapr-db/assets/image29.png\">\n\nTopics are a logical stream of events. Topics organize events into categories and decouple producers from consumers. Topics are partitioned for throughput and scalability. MapR-ES can scale to very high throughput levels, easily delivering millions of messages per second using very modest hardware.\n<img src=\"https://mapr.com/blog/real-time-analysis-popular-uber-locations-spark-structured-streaming-machine-learning-kafka-and-mapr-db/assets/image16.png\" width=\"500\" height=\"500\">\nYou can think of a partition like an event log: new events are appended to the end and are assigned a sequential ID number called the offset.\n\n<img src=\"https://mapr.com/blog/real-time-analysis-popular-uber-locations-spark-structured-streaming-machine-learning-kafka-and-mapr-db/assets/image4.png\" width=\"500\" height=\"500\">\n","user":"anonymous","dateUpdated":"2019-04-03T20:34:15+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>Using Spark Structured Streaming in a data processing pipeline</h2>\n<p>In this notebook, we will use Spark Structured Streaming in a data processing pipeline for predicting Flight Delays.<br/>We will use the machine learning model from the previous notebook to enrich the flight events with flight delay predictions and we will store the results in MapR Database. (Similar to the use case image below, but we are using flight data.) </p>\n<img src=\"https://mapr.com/blog/real-time-analysis-popular-uber-locations-spark-structured-streaming-machine-learning-kafka-and-mapr-db/assets/image46.png\" width=\"500\" height=\"500\">\n<h2>Streaming Data</h2>\n<p>MapR Event Store is a distributed publish-subscribe event streaming system that enables producers and consumers to exchange events in real time in a parallel and fault-tolerant manner via the Apache Kafka API.<br/>A stream represents a continuous sequence of events that goes from producers to consumers, where an event is defined as a key-value pair.<br/><img src=\"https://mapr.com/blog/real-time-analysis-popular-uber-locations-spark-structured-streaming-machine-learning-kafka-and-mapr-db/assets/image29.png\"></p>\n<p>Topics are a logical stream of events. Topics organize events into categories and decouple producers from consumers. Topics are partitioned for throughput and scalability. MapR-ES can scale to very high throughput levels, easily delivering millions of messages per second using very modest hardware.<br/><img src=\"https://mapr.com/blog/real-time-analysis-popular-uber-locations-spark-structured-streaming-machine-learning-kafka-and-mapr-db/assets/image16.png\" width=\"500\" height=\"500\"><br/>You can think of a partition like an event log: new events are appended to the end and are assigned a sequential ID number called the offset.</p>\n<img src=\"https://mapr.com/blog/real-time-analysis-popular-uber-locations-spark-structured-streaming-machine-learning-kafka-and-mapr-db/assets/image4.png\" width=\"500\" height=\"500\">\n</div>"}]},"apps":[],"jobName":"paragraph_1554323655634_-688276748","id":"20170530-122945_1594214131","dateCreated":"2019-04-03T20:34:15+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:315"},{"text":"%md\n## Spark Structured Streaming\n\nStructured Streaming is a scalable and fault-tolerant stream processing engine built on the Spark SQL engine. Structured Streaming enables you to view data published to Kafka as an unbounded DataFrame and process this data with the same DataFrame, Dataset, and SQL APIs used for batch processing.\n<img src=\"https://mapr.com/blog/real-time-analysis-popular-uber-locations-spark-structured-streaming-machine-learning-kafka-and-mapr-db/assets/image25.png\">","user":"anonymous","dateUpdated":"2019-04-03T20:34:15+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>Spark Structured Streaming</h2>\n<p>Structured Streaming is a scalable and fault-tolerant stream processing engine built on the Spark SQL engine. Structured Streaming enables you to view data published to Kafka as an unbounded DataFrame and process this data with the same DataFrame, Dataset, and SQL APIs used for batch processing.<br/><img src=\"https://mapr.com/blog/real-time-analysis-popular-uber-locations-spark-structured-streaming-machine-learning-kafka-and-mapr-db/assets/image25.png\"></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1554323655641_-2019343246","id":"20190220-173254_1728425170","dateCreated":"2019-04-03T20:34:15+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:316"},{"text":"%md\n## Spark Structured Streaming Use Case \n\nFlight event data is published to a MapR Event Store topic using the Kafka API.\nA Spark streaming application subscribed to the topic:\n* Ingests a stream of Flight data\n* Uses a deployed machine learning model to enrich the flight data with delay predictions\n* Stores the transformed and enriched data in MapR Database in JSON format","user":"anonymous","dateUpdated":"2019-04-03T20:34:15+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>Spark Structured Streaming Use Case</h2>\n<p>Flight event data is published to a MapR Event Store topic using the Kafka API.<br/>A Spark streaming application subscribed to the topic:<br/>* Ingests a stream of Flight data<br/>* Uses a deployed machine learning model to enrich the flight data with delay predictions<br/>* Stores the transformed and enriched data in MapR Database in JSON format</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1554323655641_-1642271593","id":"20190311-203939_1465736486","dateCreated":"2019-04-03T20:34:15+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:317"},{"title":"Import needed packages","text":"%spark\nimport org.apache.spark.sql.SparkSession\nimport org.apache.spark.sql.types._\nimport org.apache.spark.sql.functions._\nimport org.apache.spark.sql._\nimport org.apache.spark.streaming._\n\nimport org.apache.spark.ml._\nimport org.apache.spark.ml.feature._\nimport org.apache.spark.ml.classification._\nimport org.apache.spark.ml.evaluation._\nimport org.apache.spark.ml.tuning._\n","user":"anonymous","dateUpdated":"2019-04-03T20:34:15+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import org.apache.spark.sql.SparkSession\nimport org.apache.spark.sql.types._\nimport org.apache.spark.sql.functions._\nimport org.apache.spark.sql._\nimport org.apache.spark.streaming._\nimport org.apache.spark.ml._\nimport org.apache.spark.ml.feature._\nimport org.apache.spark.ml.classification._\nimport org.apache.spark.ml.evaluation._\nimport org.apache.spark.ml.tuning._\n"}]},"apps":[],"jobName":"paragraph_1554323655642_-1021501396","id":"20170508-144514_403247535","dateCreated":"2019-04-03T20:34:15+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:318"},{"text":"%md\n### The Streaming event values have the following format:\n\n{\"id\":\"ATL_BOS_2018-01-01_DL_104\",\"fldate\":\"2018-01-01\",\"month\":1,\"dofW\":1,\n\"carrier\":\"DL\",\"src\":\"ATL\",\"dst\":\"BOS\",\"crsdephour\":9,\"crsdeptime\":850,\"depdelay\":0.0,\n\"crsarrtime\":1116,\"arrdelay\":0.0,\"crselapsedtime\":146.0,\"dist\":946.0}\n\nwe enrich this data with the flight delay then transform it into the following JSON object:\n\n{\"id\":\"ATL_BOS_2018-01-01_DL_104\",\"fldate\":\"2018-01-01\",\"month\":1,\"dofW\":1,\n\"carrier\":\"DL\",\"src\":\"ATL\",\"dst\":\"BOS\",\"crsdephour\":9,\"crsdeptime\":850,\"depdelay\":0.0,\n\"crsarrtime\":1116,\"arrdelay\":0.0,\"crselapsedtime\":146.0,\"dist\":946.0, \n\"orig_dest\":\"ATL_BOS\", label:0.0, prediction:0.0}\n","user":"anonymous","dateUpdated":"2019-04-03T20:34:15+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>The Streaming event values have the following format:</h3>\n<p>{&ldquo;id&rdquo;:&ldquo;ATL_BOS_2018-01-01_DL_104&rdquo;,&ldquo;fldate&rdquo;:&ldquo;2018-01-01&rdquo;,&ldquo;month&rdquo;:1,&ldquo;dofW&rdquo;:1,<br/>&ldquo;carrier&rdquo;:&ldquo;DL&rdquo;,&ldquo;src&rdquo;:&ldquo;ATL&rdquo;,&ldquo;dst&rdquo;:&ldquo;BOS&rdquo;,&ldquo;crsdephour&rdquo;:9,&ldquo;crsdeptime&rdquo;:850,&ldquo;depdelay&rdquo;:0.0,<br/>&ldquo;crsarrtime&rdquo;:1116,&ldquo;arrdelay&rdquo;:0.0,&ldquo;crselapsedtime&rdquo;:146.0,&ldquo;dist&rdquo;:946.0}</p>\n<p>we enrich this data with the flight delay then transform it into the following JSON object:</p>\n<p>{&ldquo;id&rdquo;:&ldquo;ATL_BOS_2018-01-01_DL_104&rdquo;,&ldquo;fldate&rdquo;:&ldquo;2018-01-01&rdquo;,&ldquo;month&rdquo;:1,&ldquo;dofW&rdquo;:1,<br/>&ldquo;carrier&rdquo;:&ldquo;DL&rdquo;,&ldquo;src&rdquo;:&ldquo;ATL&rdquo;,&ldquo;dst&rdquo;:&ldquo;BOS&rdquo;,&ldquo;crsdephour&rdquo;:9,&ldquo;crsdeptime&rdquo;:850,&ldquo;depdelay&rdquo;:0.0,<br/>&ldquo;crsarrtime&rdquo;:1116,&ldquo;arrdelay&rdquo;:0.0,&ldquo;crselapsedtime&rdquo;:146.0,&ldquo;dist&rdquo;:946.0,<br/>&ldquo;orig_dest&rdquo;:&ldquo;ATL_BOS&rdquo;, label:0.0, prediction:0.0}</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1554323655642_53375916","id":"20190311-203402_1826680675","dateCreated":"2019-04-03T20:34:15+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:319"},{"title":"Define Schema for JSON streaming data","text":"\n// define the schema matching incoming data\n\n  val schema = StructType(Array(\n    StructField(\"id\", StringType, true),\n    StructField(\"fldate\", StringType, true),\n    StructField(\"month\", IntegerType, true),\n    StructField(\"dofW\", IntegerType, true),\n    StructField(\"carrier\", StringType, true),\n    StructField(\"src\", StringType, true),\n    StructField(\"dst\", StringType, true),\n    StructField(\"crsdephour\", IntegerType, true),\n    StructField(\"crsdeptime\", IntegerType, true),\n    StructField(\"depdelay\", DoubleType, true),\n    StructField(\"crsarrtime\", IntegerType, true),\n    StructField(\"arrdelay\", DoubleType, true),\n    StructField(\"crselapsedtime\", DoubleType, true),\n    StructField(\"dist\", DoubleType, true)\n  ))\n   ","user":"anonymous","dateUpdated":"2019-04-03T20:34:15+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"schema: org.apache.spark.sql.types.StructType = StructType(StructField(id,StringType,true), StructField(fldate,StringType,true), StructField(month,IntegerType,true), StructField(dofW,IntegerType,true), StructField(carrier,StringType,true), StructField(src,StringType,true), StructField(dst,StringType,true), StructField(crsdephour,IntegerType,true), StructField(crsdeptime,IntegerType,true), StructField(depdelay,DoubleType,true), StructField(crsarrtime,IntegerType,true), StructField(arrdelay,DoubleType,true), StructField(crselapsedtime,DoubleType,true), StructField(dist,DoubleType,true))\n"}]},"apps":[],"jobName":"paragraph_1554323655642_-892576849","id":"20170508-150032_326029627","dateCreated":"2019-04-03T20:34:15+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:320"},{"title":"Define Topic , Table , and Model Directory","text":"// MapR Event Store for Kafka Topic to read from \nvar topic: String = \"/user/mapr/stream:flights\"\n// MapR Database table to write to \nvar tableName: String = \"/user/mapr/flighttable\"\n// Directory to read the saved ML model from \nvar modeldirectory =\"/user/mapr/model/\"\n","user":"anonymous","dateUpdated":"2019-04-03T20:34:15+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"topic: String = /user/mapr/stream:flights\ntableName: String = /user/mapr/flighttable\nmodeldirectory: String = /user/mapr/model/\n"}]},"apps":[],"jobName":"paragraph_1554323655643_-1057243618","id":"20170508-150131_378637203","dateCreated":"2019-04-03T20:34:15+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:321"},{"text":"%md\n### Loading the Pipeline Model\nThe Spark PipelineModel class is used to load a the pipeline model, which was fitted on the historical flight data and then saved to the MapR-XD file system. ","user":"anonymous","dateUpdated":"2019-04-03T20:34:15+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Loading the Pipeline Model</h3>\n<p>The Spark PipelineModel class is used to load a the pipeline model, which was fitted on the historical flight data and then saved to the MapR-XD file system.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1554323655643_896594160","id":"20190311-210406_1328123679","dateCreated":"2019-04-03T20:34:15+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:322"},{"title":"Load the saved Machine Learning Model","text":"import spark.implicits._\nval model = org.apache.spark.ml.PipelineModel.load(modeldirectory)","user":"anonymous","dateUpdated":"2019-04-03T20:34:15+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import spark.implicits._\nmodel: org.apache.spark.ml.PipelineModel = pipeline_5da9e722de12\n"}]},"apps":[],"jobName":"paragraph_1554323655643_767541885","id":"20171129-221736_959969733","dateCreated":"2019-04-03T20:34:15+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:323"},{"title":"Print out the feature importances from the saved model","text":"// Print out the model feature importances\n val featureCols = Array(\"carrierIndexed\", \"dstIndexed\", \"srcIndexed\", \"dofWIndexed\", \"orig_destIndexed\", \"crsdephour\", \"crsdeptime\", \"crsarrtime\", \"crselapsedtime\", \"dist\")\nval rfm = model.stages.last.asInstanceOf[RandomForestClassificationModel]\nval featureImportances =rfm.featureImportances\nfeatureCols.zip(featureImportances.toArray).sortBy(-_._2).foreach { case (feat, imp) => println(s\"feature: $feat, importance: $imp\") }\n","user":"anonymous","dateUpdated":"2019-04-03T20:34:15+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"feature: crsdeptime, importance: 0.28351763249788353\nfeature: orig_destIndexed, importance: 0.19366046264846604\nfeature: crsarrtime, importance: 0.18539901941274597\nfeature: crsdephour, importance: 0.11189215100129155\nfeature: dofWIndexed, importance: 0.06079935925478266\nfeature: crselapsedtime, importance: 0.05199848773217375\nfeature: srcIndexed, importance: 0.041716384518939956\nfeature: dstIndexed, importance: 0.03598083086117173\nfeature: dist, importance: 0.019475337697743626\nfeature: carrierIndexed, importance: 0.01556033437480119\nfeatureCols: Array[String] = Array(carrierIndexed, dstIndexed, srcIndexed, dofWIndexed, orig_destIndexed, crsdephour, crsdeptime, crsarrtime, crselapsedtime, dist)\nrfm: org.apache.spark.ml.classification.RandomForestClassificationModel = RandomForestClassificationModel (uid=rfc_665455f14c70) with 10 trees\nfeatureImportances: org.apache.spark.ml.linalg.Vector = (10,[0,1,2,3,4,5,6,7,8,9],[0.01556033437480119,0.03598083086117173,0.041716384518939956,0.06079935925478266,0.19366046264846604,0.11189215100129155,0.28351763249788353,0.18539901941274597,0.05199848773217375,0.019475337697743626])\n"}]},"apps":[],"jobName":"paragraph_1554323655644_1668755281","id":"20190307-173159_764062524","dateCreated":"2019-04-03T20:34:15+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:324"},{"text":"%md\n## Reading Data from Kafka Topics\nIn order to read from Kafka, we must specify the stream format, topic, and offset options.\nNote that the data will not start streaming in until we call start on a streaming query, which we will do after the data is transformed the way we want it for saving. ","user":"anonymous","dateUpdated":"2019-04-03T20:34:15+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>Reading Data from Kafka Topics</h2>\n<p>In order to read from Kafka, we must specify the stream format, topic, and offset options.<br/>Note that the data will not start streaming in until we call start on a streaming query, which we will do after the data is transformed the way we want it for saving.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1554323655644_1071226941","id":"20190306-165333_491584061","dateCreated":"2019-04-03T20:34:15+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:325"},{"title":"Read Stream from Kafka topic ","text":"// read stream from Kafka\n// note data will not start streaming until later when we call start()\nval df1 = spark.readStream.format(\"kafka\").option(\"kafka.bootstrap.servers\", \"maprdemo:9092\").option(\"subscribe\", topic).option(\"group.id\", \"testgroup\").option(\"startingOffsets\", \"earliest\").option(\"failOnDataLoss\", false).option(\"maxOffsetsPerTrigger\", 1000).load()","user":"anonymous","dateUpdated":"2019-04-03T20:34:15+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"df1: org.apache.spark.sql.DataFrame = [key: binary, value: binary ... 5 more fields]\n"}]},"apps":[],"jobName":"paragraph_1554323655644_-1928789066","id":"20190306-002931_1225657206","dateCreated":"2019-04-03T20:34:15+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:326"},{"title":"Print Kafka DataFrame Schema","text":"// we can not see the incoming data yet but we can see the schema\n// readStream.format \"kafka\" returns a DataFrame with the following schema:\n// we are interested in the message value column\ndf1.printSchema","user":"anonymous","dateUpdated":"2019-04-03T20:34:15+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"root\n |-- key: binary (nullable = true)\n |-- value: binary (nullable = true)\n |-- topic: string (nullable = true)\n |-- partition: integer (nullable = true)\n |-- offset: long (nullable = true)\n |-- timestamp: timestamp (nullable = true)\n |-- timestampType: integer (nullable = true)\n\n"}]},"apps":[],"jobName":"paragraph_1554323655645_724066537","id":"20171129-223643_463511351","dateCreated":"2019-04-03T20:34:15+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:327"},{"text":"%md\n### Parsing the Message Values into a DataFrame of Flight Schema\nThe next step is to parse and transform the Kafka DataFrame column \"value\" from binary to a JSON String of Flight schema.\nIn the code below: \n* first we use a select expression with a String Cast of the df1 column value to convert the value from binary to string\n* then we use the from_json Spark SQL function in a select expression to retrieve the JSON string as the specified schema StructTyp\n","user":"anonymous","dateUpdated":"2019-04-03T20:34:15+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Parsing the Message Values into a DataFrame of Flight Schema</h3>\n<p>The next step is to parse and transform the Kafka DataFrame column &ldquo;value&rdquo; from binary to a JSON String of Flight schema.<br/>In the code below:<br/>* first we use a select expression with a String Cast of the df1 column value to convert the value from binary to string<br/>* then we use the from_json Spark SQL function in a select expression to retrieve the JSON string as the specified schema StructTyp</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1554323655645_-1676300286","id":"20190306-165945_2131987408","dateCreated":"2019-04-03T20:34:15+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:328"},{"title":"Parse the Message Values into a Dataframe of Flight Schema","text":"// cast the df1 column value to string\n// use the from_json function to convert value JSON string to flight schema\nval df2 = df1.select($\"value\" cast \"string\" as \"json\").select(from_json($\"json\", schema) as \"data\").select(\"data.*\")","user":"anonymous","dateUpdated":"2019-04-03T20:34:15+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"df2: org.apache.spark.sql.DataFrame = [id: string, fldate: string ... 12 more fields]\n"}]},"apps":[],"jobName":"paragraph_1554323655645_459666499","id":"20190306-003118_1790885997","dateCreated":"2019-04-03T20:34:15+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:329"},{"text":"df2.printSchema","user":"anonymous","dateUpdated":"2019-04-03T20:34:15+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"root\n |-- id: string (nullable = true)\n |-- fldate: string (nullable = true)\n |-- month: integer (nullable = true)\n |-- dofW: integer (nullable = true)\n |-- carrier: string (nullable = true)\n |-- src: string (nullable = true)\n |-- dst: string (nullable = true)\n |-- crsdephour: integer (nullable = true)\n |-- crsdeptime: integer (nullable = true)\n |-- depdelay: double (nullable = true)\n |-- crsarrtime: integer (nullable = true)\n |-- arrdelay: double (nullable = true)\n |-- crselapsedtime: double (nullable = true)\n |-- dist: double (nullable = true)\n\n"}]},"apps":[],"jobName":"paragraph_1554323655646_1042431867","id":"20190312-152719_517956706","dateCreated":"2019-04-03T20:34:15+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:330"},{"title":"Add the column orig_dest","text":" // add column orig_dest, needed feature for ML model\n val df3 = df2.withColumn(\"orig_dest\", concat($\"src\", lit(\"_\"), $\"dst\"))","user":"anonymous","dateUpdated":"2019-04-03T20:34:15+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"df3: org.apache.spark.sql.DataFrame = [id: string, fldate: string ... 13 more fields]\n"}]},"apps":[],"jobName":"paragraph_1554323655646_-305157543","id":"20190306-010238_1100520892","dateCreated":"2019-04-03T20:34:15+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:331"},{"text":"%md\n## Enriching the flight Dataframe with label and predictions\nNext we transform the DataFrame with the model pipeline, which will tranform the features according to the pipeline, estimate and then return the predictions in a column of a new DateFrame.\n<img src=\"https://mapr.com/blog/apache-spark-machine-learning-tutorial/assets/image19.png\">","user":"anonymous","dateUpdated":"2019-04-03T20:34:15+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>Enriching the flight Dataframe with label and predictions</h2>\n<p>Next we transform the DataFrame with the model pipeline, which will tranform the features according to the pipeline, estimate and then return the predictions in a column of a new DateFrame.<br/><img src=\"https://mapr.com/blog/apache-spark-machine-learning-tutorial/assets/image19.png\"></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1554323655647_-1697459600","id":"20190306-171339_1154203095","dateCreated":"2019-04-03T20:34:15+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:332"},{"title":"Use the model to add Flight Delay Predictions to a DataFrame","text":"// transform the DataFrame with the model pipeline, which will tranform the features according to the pipeline, \n// estimate and then return the predictions in a column of a new DateFrame\nval predictions = model.transform(df3)","user":"anonymous","dateUpdated":"2019-04-03T20:34:15+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"predictions: org.apache.spark.sql.DataFrame = [id: string, fldate: string ... 23 more fields]\n"}]},"apps":[],"jobName":"paragraph_1554323655647_-1648199380","id":"20190306-010315_921932660","dateCreated":"2019-04-03T20:34:15+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:333"},{"text":"// print the schema of the predictions enriched dataframe\npredictions.printSchema","user":"anonymous","dateUpdated":"2019-04-03T20:34:15+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"root\n |-- id: string (nullable = true)\n |-- fldate: string (nullable = true)\n |-- month: integer (nullable = true)\n |-- dofW: integer (nullable = true)\n |-- carrier: string (nullable = true)\n |-- src: string (nullable = true)\n |-- dst: string (nullable = true)\n |-- crsdephour: integer (nullable = true)\n |-- crsdeptime: integer (nullable = true)\n |-- depdelay: double (nullable = true)\n |-- crsarrtime: integer (nullable = true)\n |-- arrdelay: double (nullable = true)\n |-- crselapsedtime: double (nullable = true)\n |-- dist: double (nullable = true)\n |-- orig_dest: string (nullable = true)\n |-- carrierIndexed: double (nullable = false)\n |-- srcIndexed: double (nullable = false)\n |-- dstIndexed: double (nullable = false)\n |-- dofWIndexed: double (nullable = false)\n |-- orig_destIndexed: double (nullable = false)\n |-- label: double (nullable = true)\n |-- features: vector (nullable = true)\n |-- rawPrediction: vector (nullable = true)\n |-- probability: vector (nullable = true)\n |-- prediction: double (nullable = false)\n\n"}]},"apps":[],"jobName":"paragraph_1554323655647_-1725157619","id":"20190312-152809_1705439164","dateCreated":"2019-04-03T20:34:15+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:334"},{"title":"From the Predictions DataFrame, Drop the columns that we do not want to store in MapR Database","text":"// drop columns we do not want to store\nval df4 = predictions.drop(\"features\").drop(\"rawPrediction\").drop(\"probability\")","user":"anonymous","dateUpdated":"2019-04-03T20:34:15+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"df4: org.apache.spark.sql.DataFrame = [id: string, fldate: string ... 20 more fields]\n"}]},"apps":[],"jobName":"paragraph_1554323655648_-265102671","id":"20190312-152933_1751253136","dateCreated":"2019-04-03T20:34:15+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:335"},{"text":"// print the schema of the transformed dataframe that we will write to MapR Database\ndf4.printSchema","user":"anonymous","dateUpdated":"2019-04-03T20:34:15+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"root\n |-- id: string (nullable = true)\n |-- fldate: string (nullable = true)\n |-- month: integer (nullable = true)\n |-- dofW: integer (nullable = true)\n |-- carrier: string (nullable = true)\n |-- src: string (nullable = true)\n |-- dst: string (nullable = true)\n |-- crsdephour: integer (nullable = true)\n |-- crsdeptime: integer (nullable = true)\n |-- depdelay: double (nullable = true)\n |-- crsarrtime: integer (nullable = true)\n |-- arrdelay: double (nullable = true)\n |-- crselapsedtime: double (nullable = true)\n |-- dist: double (nullable = true)\n |-- orig_dest: string (nullable = true)\n |-- carrierIndexed: double (nullable = false)\n |-- srcIndexed: double (nullable = false)\n |-- dstIndexed: double (nullable = false)\n |-- dofWIndexed: double (nullable = false)\n |-- orig_destIndexed: double (nullable = false)\n |-- label: double (nullable = true)\n |-- prediction: double (nullable = false)\n\n"}]},"apps":[],"jobName":"paragraph_1554323655648_-97543012","id":"20190312-152835_1004281453","dateCreated":"2019-04-03T20:34:15+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:336"},{"text":" %md\n### MapR-DB Connector for Apache Spark  \nThe MapR Database Connector for Apache Spark enables you to use MapR Database as a sink for Spark Structured streaming or Spark Streaming. One of the challenges when you are processing lots of streaming data is where do you want to store it? For this application, MapR Database JSON, a high performance NoSQL database, was chosen for its scalability and flexible ease of use with JSON. MapR Database supports JSON documents as a native data store.  The Spark connector makes it easy to build real-time or batch pipelines between your JSON data and MapR Database and leverage Spark within the pipeline.\n<img src=\"https://mapr.com/blog/real-time-analysis-popular-uber-locations-spark-structured-streaming-machine-learning-kafka-and-mapr-db/assets/image38.png\">\n With MapR Database, a table is automatically partitioned into tablets across a cluster by key range, providing for scalable and fast reads and writes by row key. \n<img src=\"https://mapr.com/blog/real-time-analysis-popular-uber-locations-spark-structured-streaming-machine-learning-kafka-and-mapr-db/assets/image8.png\" width=\"400\" height=\"400\">\nIn this use case, the row key (the id) starts with the origin (destination airport codes), followed by the flightdate and carrier, so the table is automatically partitioned and sorted by the src, dst, date, and carrier.\n <img src=\"https://mapr.com/blog/tips-and-best-practices-to-take-advantage-of-spark-2-x/assets/image4.png\">\nThe Spark MapR Database Connector architecture has a connection object in every Spark Executor, allowing for distributed parallel writes, reads, or scans with MapR Database partitions.\n\n<img src=\"https://mapr.com/blog/real-time-analysis-popular-uber-locations-spark-structured-streaming-machine-learning-kafka-and-mapr-db/assets/image32.png\" width=\"400\" height=\"400\">\n###  Writing to a MapR Database Sink\nTo write a Spark Stream to MapR Datbase, specify the format with the tablePath, idFieldPath, createTable, bulkMode, and sampleSize parameters. \nThe code below writes out the df4 DataFrame to MapR Database and starts the stream.\n<img src=\"https://mapr.com/blog/real-time-analysis-popular-uber-locations-spark-structured-streaming-machine-learning-kafka-and-mapr-db/assets/image48.png\" width=\"400\" height=\"400\">\n","user":"anonymous","dateUpdated":"2019-04-03T20:34:15+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>MapR-DB Connector for Apache Spark</h3>\n<p>The MapR Database Connector for Apache Spark enables you to use MapR Database as a sink for Spark Structured streaming or Spark Streaming. One of the challenges when you are processing lots of streaming data is where do you want to store it? For this application, MapR Database JSON, a high performance NoSQL database, was chosen for its scalability and flexible ease of use with JSON. MapR Database supports JSON documents as a native data store. The Spark connector makes it easy to build real-time or batch pipelines between your JSON data and MapR Database and leverage Spark within the pipeline.<br/><img src=\"https://mapr.com/blog/real-time-analysis-popular-uber-locations-spark-structured-streaming-machine-learning-kafka-and-mapr-db/assets/image38.png\"><br/> With MapR Database, a table is automatically partitioned into tablets across a cluster by key range, providing for scalable and fast reads and writes by row key.<br/><img src=\"https://mapr.com/blog/real-time-analysis-popular-uber-locations-spark-structured-streaming-machine-learning-kafka-and-mapr-db/assets/image8.png\" width=\"400\" height=\"400\"><br/>In this use case, the row key (the id) starts with the origin (destination airport codes), followed by the flightdate and carrier, so the table is automatically partitioned and sorted by the src, dst, date, and carrier.<br/> <img src=\"https://mapr.com/blog/tips-and-best-practices-to-take-advantage-of-spark-2-x/assets/image4.png\"><br/>The Spark MapR Database Connector architecture has a connection object in every Spark Executor, allowing for distributed parallel writes, reads, or scans with MapR Database partitions.</p>\n<img src=\"https://mapr.com/blog/real-time-analysis-popular-uber-locations-spark-structured-streaming-machine-learning-kafka-and-mapr-db/assets/image32.png\" width=\"400\" height=\"400\">\n<h3>Writing to a MapR Database Sink</h3>\n<p>To write a Spark Stream to MapR Datbase, specify the format with the tablePath, idFieldPath, createTable, bulkMode, and sampleSize parameters.<br/>The code below writes out the df4 DataFrame to MapR Database and starts the stream.<br/><img src=\"https://mapr.com/blog/real-time-analysis-popular-uber-locations-spark-structured-streaming-machine-learning-kafka-and-mapr-db/assets/image48.png\" width=\"400\" height=\"400\"></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1554323655648_-150719837","id":"20190311-213501_729174936","dateCreated":"2019-04-03T20:34:15+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:337"},{"title":"Write the Stream to MapR Database","text":"import com.mapr.db.spark.impl._\nimport com.mapr.db.spark.streaming._\nimport com.mapr.db.spark.sql._\nimport com.mapr.db.spark.streaming.MapRDBSourceConfig\n// write out the df4 DataFrame to MapR Database and start the stream.\n// note you will not see the data being written until when we read from MapR Database\nval writedb = df4.writeStream.format(MapRDBSourceConfig.Format)\n.option(MapRDBSourceConfig.TablePathOption, tableName)\n.option(MapRDBSourceConfig.IdFieldPathOption, \"id\")\n.option(MapRDBSourceConfig.CreateTableOption, false)\n.option(\"checkpointLocation\", \"/tmp/flightn\")\n.option(MapRDBSourceConfig.BulkModeOption, true)\n.option(MapRDBSourceConfig.SampleSizeOption, 1000).start()\n\n","user":"anonymous","dateUpdated":"2019-04-03T20:34:15+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import com.mapr.db.spark.impl._\nimport com.mapr.db.spark.streaming._\nimport com.mapr.db.spark.sql._\nimport com.mapr.db.spark.streaming.MapRDBSourceConfig\nwritedb: org.apache.spark.sql.streaming.StreamingQuery = org.apache.spark.sql.execution.streaming.StreamingQueryWrapper@2f59298\n"}]},"apps":[],"jobName":"paragraph_1554323655649_1007257897","id":"20190306-003127_1670791655","dateCreated":"2019-04-03T20:34:15+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:338"},{"title":"New Schema with label and prediction for Reading from MapR Database","text":"// define new schema with label and prediction for reading from MapR Database\nval schema2 = StructType(Array(\n    StructField(\"id\", StringType, true),\n    StructField(\"fldate\", StringType, true),\n    StructField(\"month\", IntegerType, true),\n    StructField(\"dofW\", IntegerType, true),\n    StructField(\"carrier\", StringType, true),\n    StructField(\"src\", StringType, true),\n    StructField(\"dst\", StringType, true),\n    StructField(\"crsdephour\", IntegerType, true),\n    StructField(\"crsdeptime\", IntegerType, true),\n    StructField(\"depdelay\", DoubleType, true),\n    StructField(\"crsarrtime\", IntegerType, true),\n    StructField(\"arrdelay\", DoubleType, true),\n    StructField(\"crselapsedtime\", DoubleType, true),\n    StructField(\"dist\", DoubleType, true),\n    StructField(\"orig_dest\", StringType, true),\n    StructField(\"label\", DoubleType, true),\n    StructField(\"prediction\", DoubleType, true)\n  ))","user":"anonymous","dateUpdated":"2019-04-03T20:34:15+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"schema2: org.apache.spark.sql.types.StructType = StructType(StructField(id,StringType,true), StructField(fldate,StringType,true), StructField(month,IntegerType,true), StructField(dofW,IntegerType,true), StructField(carrier,StringType,true), StructField(src,StringType,true), StructField(dst,StringType,true), StructField(crsdephour,IntegerType,true), StructField(crsdeptime,IntegerType,true), StructField(depdelay,DoubleType,true), StructField(crsarrtime,IntegerType,true), StructField(arrdelay,DoubleType,true), StructField(crselapsedtime,DoubleType,true), StructField(dist,DoubleType,true), StructField(orig_dest,StringType,true), StructField(label,DoubleType,true), StructField(prediction,DoubleType,true))\n"}]},"apps":[],"jobName":"paragraph_1554323655649_-2106383732","id":"20190306-211342_1150192494","dateCreated":"2019-04-03T20:34:15+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:339"},{"title":"Imports for  Reading from MapR Database","text":"import org.apache.spark._\n\nimport com.mapr.db._\nimport com.mapr.db.spark._\nimport com.mapr.db.spark.impl._\nimport com.mapr.db.spark.sql._\n// get spark session to read from MapR Database\nval spark = org.apache.spark.sql.SparkSession.builder().appName(\"flightread\").getOrCreate()","user":"anonymous","dateUpdated":"2019-04-03T20:34:15+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import org.apache.spark._\nimport com.mapr.db._\nimport com.mapr.db.spark._\nimport com.mapr.db.spark.impl._\nimport com.mapr.db.spark.sql._\nspark: org.apache.spark.sql.SparkSession = org.apache.spark.sql.SparkSession@7f238932\n"}]},"apps":[],"jobName":"paragraph_1554323655649_746764983","id":"20190306-011141_1523714467","dateCreated":"2019-04-03T20:34:15+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:340"},{"text":"%md\n### Loading Data from MapR Database into a Spark Dataset\nThe Spark MapR Database Connector enables users to perform complex SQL queries and updates on top of MapR-DB using a Spark Dataset, while applying critical techniques such as projection and filter pushdown, custom partitioning, and data locality.\n<img src=\"https://mapr.com/blog/real-time-analysis-popular-uber-locations-spark-structured-streaming-machine-learning-kafka-and-mapr-db/assets/image7.png\">\n\nTo load data from a MapR Database JSON table into an Apache Spark Dataset, we invoke the loadFromMapRDB method on a SparkSession object, providing the tableName and schema. This returns a DataFrame of the flight schema","user":"anonymous","dateUpdated":"2019-04-03T20:34:15+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Loading Data from MapR Database into a Spark Dataset</h3>\n<p>The Spark MapR Database Connector enables users to perform complex SQL queries and updates on top of MapR-DB using a Spark Dataset, while applying critical techniques such as projection and filter pushdown, custom partitioning, and data locality.<br/><img src=\"https://mapr.com/blog/real-time-analysis-popular-uber-locations-spark-structured-streaming-machine-learning-kafka-and-mapr-db/assets/image7.png\"></p>\n<p>To load data from a MapR Database JSON table into an Apache Spark Dataset, we invoke the loadFromMapRDB method on a SparkSession object, providing the tableName and schema. This returns a DataFrame of the flight schema</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1554323655650_-1995633908","id":"20190311-225414_469831482","dateCreated":"2019-04-03T20:34:15+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:341"},{"title":"Load Flight DataFrame from MapR Database","text":" // load flight dataframe from MapR Database \nval df = spark.sparkSession.loadFromMapRDB(tableName, schema2)\n// show the first 20 rows\ndf.show\n// create a temp view in order to use Spark SQL\ndf.createOrReplaceTempView(\"flights\")","user":"anonymous","dateUpdated":"2019-04-03T20:34:15+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+--------------------+----------+-----+----+-------+---+---+----------+----------+--------+----------+--------+--------------+-----+---------+-----+----------+\n|                  id|    fldate|month|dofW|carrier|src|dst|crsdephour|crsdeptime|depdelay|crsarrtime|arrdelay|crselapsedtime| dist|orig_dest|label|prediction|\n+--------------------+----------+-----+----+-------+---+---+----------+----------+--------+----------+--------+--------------+-----+---------+-----+----------+\n|ATL_BOS_2018-01-0...|2018-01-01|    1|   1|     DL|ATL|BOS|         9|       850|     0.0|      1116|     0.0|         146.0|946.0|  ATL_BOS|  0.0|       0.0|\n|ATL_BOS_2018-01-0...|2018-01-01|    1|   1|     DL|ATL|BOS|        11|      1122|     8.0|      1349|     0.0|         147.0|946.0|  ATL_BOS|  0.0|       0.0|\n|ATL_BOS_2018-01-0...|2018-01-01|    1|   1|     DL|ATL|BOS|        14|      1356|     9.0|      1623|     0.0|         147.0|946.0|  ATL_BOS|  0.0|       0.0|\n|ATL_BOS_2018-01-0...|2018-01-01|    1|   1|     DL|ATL|BOS|        16|      1620|     0.0|      1851|     3.0|         151.0|946.0|  ATL_BOS|  0.0|       1.0|\n|ATL_BOS_2018-01-0...|2018-01-01|    1|   1|     DL|ATL|BOS|        19|      1940|     6.0|      2210|     0.0|         150.0|946.0|  ATL_BOS|  0.0|       1.0|\n|ATL_BOS_2018-01-0...|2018-01-01|    1|   1|     DL|ATL|BOS|        12|      1248|     0.0|      1513|     0.0|         145.0|946.0|  ATL_BOS|  0.0|       0.0|\n|ATL_BOS_2018-01-0...|2018-01-01|    1|   1|     DL|ATL|BOS|        22|      2215|     0.0|        39|     0.0|         144.0|946.0|  ATL_BOS|  0.0|       1.0|\n|ATL_BOS_2018-01-0...|2018-01-01|    1|   1|     DL|ATL|BOS|        15|      1500|    21.0|      1734|    33.0|         154.0|946.0|  ATL_BOS|  0.0|       1.0|\n|ATL_BOS_2018-01-0...|2018-01-01|    1|   1|     WN|ATL|BOS|        15|      1500|   198.0|      1725|   208.0|         145.0|946.0|  ATL_BOS|  1.0|       1.0|\n|ATL_BOS_2018-01-0...|2018-01-01|    1|   1|     WN|ATL|BOS|        21|      2055|    14.0|      2330|     0.0|         155.0|946.0|  ATL_BOS|  0.0|       1.0|\n|ATL_BOS_2018-01-0...|2018-01-01|    1|   1|     WN|ATL|BOS|        10|      1015|   215.0|      1250|   191.0|         155.0|946.0|  ATL_BOS|  1.0|       0.0|\n|ATL_BOS_2018-01-0...|2018-01-02|    1|   2|     DL|ATL|BOS|         9|       850|     9.0|      1116|     0.0|         146.0|946.0|  ATL_BOS|  0.0|       0.0|\n|ATL_BOS_2018-01-0...|2018-01-02|    1|   2|     DL|ATL|BOS|        11|      1123|     0.0|      1350|     0.0|         147.0|946.0|  ATL_BOS|  0.0|       0.0|\n|ATL_BOS_2018-01-0...|2018-01-02|    1|   2|     DL|ATL|BOS|        10|      1000|    22.0|      1232|    10.0|         152.0|946.0|  ATL_BOS|  0.0|       0.0|\n|ATL_BOS_2018-01-0...|2018-01-02|    1|   2|     DL|ATL|BOS|        14|      1356|     6.0|      1623|    21.0|         147.0|946.0|  ATL_BOS|  0.0|       0.0|\n|ATL_BOS_2018-01-0...|2018-01-02|    1|   2|     DL|ATL|BOS|        22|      2227|     8.0|        51|     0.0|         144.0|946.0|  ATL_BOS|  0.0|       1.0|\n|ATL_BOS_2018-01-0...|2018-01-02|    1|   2|     DL|ATL|BOS|        16|      1620|     0.0|      1851|     0.0|         151.0|946.0|  ATL_BOS|  0.0|       1.0|\n|ATL_BOS_2018-01-0...|2018-01-02|    1|   2|     DL|ATL|BOS|        19|      1940|    62.0|      2210|    50.0|         150.0|946.0|  ATL_BOS|  1.0|       1.0|\n|ATL_BOS_2018-01-0...|2018-01-02|    1|   2|     DL|ATL|BOS|        12|      1248|    15.0|      1513|     7.0|         145.0|946.0|  ATL_BOS|  0.0|       0.0|\n|ATL_BOS_2018-01-0...|2018-01-02|    1|   2|     DL|ATL|BOS|        21|      2107|    12.0|      2335|    29.0|         148.0|946.0|  ATL_BOS|  0.0|       1.0|\n+--------------------+----------+-----+----+-------+---+---+----------+----------+--------+----------+--------+--------------+-----+---------+-----+----------+\nonly showing top 20 rows\n\ndf: org.apache.spark.sql.DataFrame = [id: string, fldate: string ... 15 more fields]\n"}]},"apps":[],"jobName":"paragraph_1554323655650_1000414172","id":"20190306-011320_1619042382","dateCreated":"2019-04-03T20:34:15+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:342"},{"text":"%md \n## Explore and Query the enriched Flight Data with Spark SQL\nNow we can query the data that is continuously streaming from the MapR Event Store into MapR Database to ask questions with the Spark DataFrames domain-specific language or with Spark SQL. Note how the streaming result values change as more data streams in and you execute a query again. \n","user":"anonymous","dateUpdated":"2019-04-03T20:34:15+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>Explore and Query the enriched Flight Data with Spark SQL</h2>\n<p>Now we can query the data that is continuously streaming from the MapR Event Store into MapR Database to ask questions with the Spark DataFrames domain-specific language or with Spark SQL. Note how the streaming result values change as more data streams in and you execute a query again.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1554323655650_530939805","id":"20170603-182655_1680505289","dateCreated":"2019-04-03T20:34:15+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:343"},{"title":"Count the rows in the DataFrame","text":"// note how this value changes as you run it again\ndf.count","user":"anonymous","dateUpdated":"2019-04-03T20:34:15+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"res18: Long = 115475\n"}]},"apps":[],"jobName":"paragraph_1554323655651_-1914416493","id":"20190306-003457_1891238408","dateCreated":"2019-04-03T20:34:15+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:344"},{"title":"Count the label, prediction by src, dst using DataFrame transformation","text":"// group by src, dst, label, prediction and count\ndf.groupBy(\"src\",\"dst\",\"label\",\"prediction\").count.show","user":"anonymous","dateUpdated":"2019-04-03T20:34:15+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+---+---+-----+----------+-----+\n|src|dst|label|prediction|count|\n+---+---+-----+----------+-----+\n|CLT|DFW|  0.0|       0.0|  415|\n|MIA|IAH|  1.0|       1.0|   11|\n|IAH|ORD|  1.0|       1.0|   27|\n|LAX|BOS|  1.0|       0.0|   19|\n|CLT|DEN|  1.0|       1.0|    8|\n|DEN|CLT|  0.0|       0.0|  261|\n|ORD|SFO|  0.0|       1.0|  551|\n|LAX|SFO|  0.0|       1.0|  531|\n|SFO|CLT|  1.0|       0.0|    9|\n|LGA|DFW|  0.0|       0.0|  418|\n|SFO|SEA|  1.0|       1.0|   16|\n|ATL|ORD|  1.0|       1.0|   43|\n|DEN|EWR|  1.0|       0.0|    5|\n|MIA|EWR|  1.0|       1.0|   35|\n|LGA|DFW|  0.0|       1.0|  172|\n|ATL|CLT|  0.0|       0.0|  737|\n|EWR|DFW|  0.0|       0.0|  192|\n|MIA|DEN|  1.0|       1.0|    2|\n|IAH|SEA|  0.0|       0.0|  151|\n|SEA|SFO|  1.0|       0.0|   23|\n+---+---+-----+----------+-----+\nonly showing top 20 rows\n\n"}]},"apps":[],"jobName":"paragraph_1554323655651_-1429192327","id":"20190307-013831_777164675","dateCreated":"2019-04-03T20:34:15+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:345"},{"text":"%md\n## Projection and Filter Pushdown into MapR Database\nBelow, we see the physical plan for a DataFrame query, with projection and filter pushdown. This means that the scanning of the src, dst, and depdelay columns and the filter on the depdelay column are pushed down into MapR Database, meaning that the scanning and filtering will take place in MapR Database before returning the data to Spark. Projection pushdown minimizes data transfer between MapR Database and the Spark engine by omitting unnecessary fields from table scans. It is especially beneficial when a table contains many columns. Filter pushdown improves performance by reducing the amount of data passed between MapR Database and the Spark engine when filtering data.","user":"anonymous","dateUpdated":"2019-04-03T20:34:15+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>Projection and Filter Pushdown into MapR Database</h2>\n<p>Below, we see the physical plan for a DataFrame query, with projection and filter pushdown. This means that the scanning of the src, dst, and depdelay columns and the filter on the depdelay column are pushed down into MapR Database, meaning that the scanning and filtering will take place in MapR Database before returning the data to Spark. Projection pushdown minimizes data transfer between MapR Database and the Spark engine by omitting unnecessary fields from table scans. It is especially beneficial when a table contains many columns. Filter pushdown improves performance by reducing the amount of data passed between MapR Database and the Spark engine when filtering data.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1554323655652_587280805","id":"20190311-233318_669843904","dateCreated":"2019-04-03T20:34:15+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:346"},{"title":"Use Explain to show physical query plan","text":"// notice projection of selected fields [src#26125,dst#26126,depdelay#26129]\n// notice PushedFilters: [IsNotNull(src), IsNotNull(depdelay), EqualTo(src,ATL), GreaterThan(depdelay,1.0)]\ndf.filter(\"src = 'ATL' and depdelay > 1\").groupBy(\"src\", \"dst\").avg(\"depdelay\").sort(desc(\"avg(depdelay)\")).explain","user":"anonymous","dateUpdated":"2019-04-03T20:34:15+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"== Physical Plan ==\n*(3) Sort [avg(depdelay)#19308 DESC NULLS LAST], true, 0\n+- Exchange rangepartitioning(avg(depdelay)#19308 DESC NULLS LAST, 200)\n   +- *(2) HashAggregate(keys=[src#4438, dst#4439], functions=[avg(depdelay#4442)])\n      +- Exchange hashpartitioning(src#4438, dst#4439, 200)\n         +- *(1) HashAggregate(keys=[src#4438, dst#4439], functions=[partial_avg(depdelay#4442)])\n            +- *(1) Filter (((isnotnull(src#4438) && isnotnull(depdelay#4442)) && (src#4438 = ATL)) && (depdelay#4442 > 1.0))\n               +- *(1) Scan MapRDBRelation(/user/mapr/flighttable,StructType(StructField(id,StringType,true), StructField(fldate,StringType,true), StructField(month,IntegerType,true), StructField(dofW,IntegerType,true), StructField(carrier,StringType,true), StructField(src,StringType,true), StructField(dst,StringType,true), StructField(crsdephour,IntegerType,true), StructField(crsdeptime,IntegerType,true), StructField(depdelay,DoubleType,true), StructField(crsarrtime,IntegerType,true), StructField(arrdelay,DoubleType,true), StructField(crselapsedtime,DoubleType,true), StructField(dist,DoubleType,true), StructField(orig_dest,StringType,true), StructField(label,DoubleType,true), StructField(prediction,DoubleType,true)),MapRDBTableScanRDD[505] at RDD at MapRDBBaseRDD.scala:21,InsertOrReplace) [src#4438,dst#4439,depdelay#4442] PushedFilters: [IsNotNull(src), IsNotNull(depdelay), EqualTo(src,ATL), GreaterThan(depdelay,1.0)], ReadSchema: struct<src:string,dst:string,depdelay:double>\n"}]},"apps":[],"jobName":"paragraph_1554323655652_-401538165","id":"20190311-233223_189893269","dateCreated":"2019-04-03T20:34:15+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:347"},{"title":"What are the average departure delays originating from Atlanta? ","text":"df.filter(\"src = 'ATL' and depdelay > 1\").groupBy(\"src\", \"dst\").avg(\"depdelay\").sort(desc(\"avg(depdelay)\")).show","user":"anonymous","dateUpdated":"2019-04-03T20:34:15+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+---+---+------------------+\n|src|dst|     avg(depdelay)|\n+---+---+------------------+\n|ATL|EWR| 45.46594005449591|\n|ATL|ORD| 38.70454545454545|\n|ATL|LGA| 36.07165109034268|\n|ATL|DFW| 35.25283630470016|\n|ATL|MIA| 33.10144927536232|\n|ATL|SFO| 33.02068965517241|\n|ATL|CLT|32.391061452513966|\n|ATL|IAH|29.808580858085808|\n|ATL|BOS|29.794212218649516|\n|ATL|DEN| 25.93439716312057|\n|ATL|LAX| 24.85807150595883|\n|ATL|SEA|23.784172661870503|\n+---+---+------------------+\n\n"}]},"apps":[],"jobName":"paragraph_1554323655653_-1387908553","id":"20190311-232848_1613662724","dateCreated":"2019-04-03T20:34:15+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:348"},{"title":"Top 5 Longest departure delays","text":"%sql \nselect carrier,src, dst, depdelay,crsdephour, dist, dofW\nfrom flights \norder by depdelay desc limit 5 \n","user":"anonymous","dateUpdated":"2019-04-03T20:34:15+0000","config":{"tableHide":false,"editorSetting":{"language":"sql","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/sql","editorHide":false,"fontSize":9,"title":true,"results":{"0":{"graph":{"mode":"table","height":300,"optionOpen":false,"setting":{"table":{"tableGridState":{},"tableColumnTypeState":{"names":{"carrier":"string","src":"string","dst":"string","depdelay":"string","crsdephour":"string","dist":"string","dofW":"string"},"updated":false},"tableOptionSpecHash":"[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]","tableOptionValue":{"useFilter":false,"showPagination":false,"showAggregationFooter":false},"updated":false,"initialized":false},"multiBarChart":{"rotate":{"degree":"-45"},"xLabelStatus":"default"}},"commonSetting":{},"keys":[{"name":"carrier","index":0,"aggr":"sum"}],"groups":[],"values":[{"name":"src","index":1,"aggr":"sum"}]},"helium":{}}},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TABLE","data":"carrier\tsrc\tdst\tdepdelay\tcrsdephour\tdist\tdofW\nAA\tIAH\tMIA\t1559.0\t11\t964.0\t5\nAA\tIAH\tDFW\t1445.0\t18\t224.0\t3\nUA\tBOS\tORD\t1334.0\t9\t867.0\t4\nAA\tBOS\tLAX\t1242.0\t10\t2611.0\t3\nAA\tATL\tMIA\t1158.0\t12\t594.0\t5\n"},{"type":"TEXT","data":""}]},"apps":[],"jobName":"paragraph_1554323655653_-1670118081","id":"20171110-195321_1924356975","dateCreated":"2019-04-03T20:34:15+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:349"},{"title":"Prediction by Carrier","text":"%sql\nselect carrier, prediction, count(prediction) from flights \ngroup by carrier, prediction order by carrier","user":"anonymous","dateUpdated":"2019-04-03T20:40:13+0000","config":{"editorSetting":{"language":"sql","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/sql","fontSize":9,"editorHide":false,"title":true,"results":{"0":{"graph":{"mode":"multiBarChart","height":300,"optionOpen":false,"setting":{"multiBarChart":{"rotate":{"degree":"-45"},"xLabelStatus":"default"},"table":{"tableGridState":{},"tableColumnTypeState":{"names":{"carrier":"string","prediction":"string","count(prediction)":"string"},"updated":false},"tableOptionSpecHash":"[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]","tableOptionValue":{"useFilter":false,"showPagination":false,"showAggregationFooter":false},"updated":false,"initialized":false}},"commonSetting":{},"keys":[{"name":"carrier","index":0,"aggr":"sum"}],"groups":[{"name":"prediction","index":1,"aggr":"sum"}],"values":[{"name":"count(prediction)","index":2,"aggr":"sum"}]},"helium":{}}},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TABLE","data":"carrier\tprediction\tcount(prediction)\nAA\t1.0\t38496\nAA\t0.0\t62254\nDL\t1.0\t17130\nDL\t0.0\t35174\nUA\t0.0\t55033\nUA\t1.0\t36023\nWN\t0.0\t7675\nWN\t1.0\t7003\n"},{"type":"TEXT","data":""}]},"apps":[],"jobName":"paragraph_1554323655653_-1032515448","id":"20171110-195759_439800395","dateCreated":"2019-04-03T20:34:15+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:350"},{"title":"Label by Carrier","text":"%sql\nselect carrier, label, count(label) from flights \ngroup by carrier, label order by carrier","user":"anonymous","dateUpdated":"2019-04-03T20:40:12+0000","config":{"editorSetting":{"language":"sql","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/sql","fontSize":9,"editorHide":false,"title":true,"results":{"0":{"graph":{"mode":"multiBarChart","height":300,"optionOpen":false,"setting":{"multiBarChart":{"rotate":{"degree":"-45"},"xLabelStatus":"default"},"table":{"tableGridState":{},"tableColumnTypeState":{"names":{"carrier":"string","prediction":"string","count(prediction)":"string"},"updated":false},"tableOptionSpecHash":"[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]","tableOptionValue":{"useFilter":false,"showPagination":false,"showAggregationFooter":false},"updated":false,"initialized":false}},"commonSetting":{},"keys":[{"name":"carrier","index":0,"aggr":"sum"}],"groups":[{"name":"label","index":1,"aggr":"sum"}],"values":[{"name":"count(label)","index":2,"aggr":"sum"}]},"helium":{}}},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TABLE","data":"carrier\tlabel\tcount(label)\nAA\t0.0\t97600\nAA\t1.0\t11827\nDL\t0.0\t52730\nDL\t1.0\t5465\nUA\t0.0\t88465\nUA\t1.0\t10513\nWN\t1.0\t2164\nWN\t0.0\t13864\n"},{"type":"TEXT","data":""}]},"apps":[],"jobName":"paragraph_1554323655654_-759584661","id":"20190307-185916_989655140","dateCreated":"2019-04-03T20:34:15+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:351"},{"title":"Label  by Destination Airport","text":"%sql\nSELECT dst,label, count(label)  \nFROM flights \nGROUP BY dst, label\n","user":"anonymous","dateUpdated":"2019-04-03T20:40:12+0000","config":{"editorSetting":{"language":"sql","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/sql","fontSize":9,"editorHide":false,"title":true,"results":{"0":{"graph":{"mode":"multiBarChart","height":300,"optionOpen":false,"setting":{"multiBarChart":{"rotate":{"degree":"-45"},"xLabelStatus":"default"},"table":{"tableGridState":{},"tableColumnTypeState":{"names":{"dst":"string","count(label)":"string"},"updated":false},"tableOptionSpecHash":"[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]","tableOptionValue":{"useFilter":false,"showPagination":false,"showAggregationFooter":false},"updated":false,"initialized":false}},"commonSetting":{},"keys":[{"name":"dst","index":0,"aggr":"sum"}],"groups":[{"name":"label","index":1,"aggr":"sum"}],"values":[{"name":"count(label)","index":2,"aggr":"sum"}]},"helium":{}}},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TABLE","data":"dst\tlabel\tcount(label)\nDEN\t0.0\t20975\nCLT\t0.0\t15378\nBOS\t0.0\t16557\nLGA\t1.0\t2425\nLGA\t0.0\t18009\nMIA\t1.0\t1785\nCLT\t1.0\t1421\nDFW\t0.0\t22434\nIAH\t1.0\t1504\nSEA\t0.0\t11505\nEWR\t1.0\t2855\nEWR\t0.0\t15681\nMIA\t0.0\t16218\nIAH\t0.0\t16037\nLAX\t0.0\t24325\nORD\t1.0\t3535\nORD\t0.0\t28779\nSFO\t1.0\t2997\nDFW\t1.0\t2513\nATL\t1.0\t2809\nDEN\t1.0\t2227\nLAX\t1.0\t2544\nSEA\t1.0\t1221\nBOS\t1.0\t2133\nSFO\t0.0\t19353\nATL\t0.0\t27408\n"},{"type":"TEXT","data":""}]},"apps":[],"jobName":"paragraph_1554323655654_2083142322","id":"20171122-204956_303346727","dateCreated":"2019-04-03T20:34:15+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:352"},{"title":"Prediction by Destination Airport","text":"%sql\nSELECT dst,prediction, count(prediction)  \nFROM flights \nGROUP BY dst, prediction\n","user":"anonymous","dateUpdated":"2019-04-03T20:40:12+0000","config":{"editorSetting":{"language":"sql","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/sql","fontSize":9,"editorHide":false,"title":true,"results":{"0":{"graph":{"mode":"multiBarChart","height":300,"optionOpen":false,"setting":{"multiBarChart":{"rotate":{"degree":"-45"},"xLabelStatus":"default"},"table":{"tableGridState":{},"tableColumnTypeState":{"names":{"dst":"string","count(label)":"string"},"updated":false},"tableOptionSpecHash":"[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]","tableOptionValue":{"useFilter":false,"showPagination":false,"showAggregationFooter":false},"updated":false,"initialized":false}},"commonSetting":{},"keys":[{"name":"dst","index":0,"aggr":"sum"}],"groups":[{"name":"prediction","index":1,"aggr":"sum"}],"values":[{"name":"count(prediction)","index":2,"aggr":"sum"}]},"helium":{}}},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TABLE","data":"dst\tprediction\tcount(prediction)\nDEN\t0.0\t15086\nCLT\t0.0\t13538\nBOS\t0.0\t11267\nLGA\t1.0\t10105\nLGA\t0.0\t10329\nMIA\t1.0\t5585\nCLT\t1.0\t3261\nDFW\t0.0\t15682\nIAH\t1.0\t5002\nSEA\t0.0\t8775\nEWR\t1.0\t9590\nEWR\t0.0\t8946\nMIA\t0.0\t12418\nIAH\t0.0\t12539\nLAX\t0.0\t16503\nORD\t1.0\t14079\nORD\t0.0\t18235\nSFO\t1.0\t12215\nDFW\t1.0\t9265\nATL\t1.0\t9108\nDEN\t1.0\t8116\nLAX\t1.0\t10366\nSEA\t1.0\t3951\nBOS\t1.0\t7423\nSFO\t0.0\t10135\nATL\t0.0\t21109\n"},{"type":"TEXT","data":""}]},"apps":[],"jobName":"paragraph_1554323655655_264697932","id":"20190307-190127_23633985","dateCreated":"2019-04-03T20:34:15+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:353"},{"title":"Label Departure Delay by Originating Airport","text":"%sql\nSELECT src, label, count(label)\nFROM flights \nGROUP BY src, label\n","user":"anonymous","dateUpdated":"2019-04-03T20:40:12+0000","config":{"editorSetting":{"language":"sql","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/sql","fontSize":9,"editorHide":false,"title":true,"results":{"0":{"graph":{"mode":"multiBarChart","height":300,"optionOpen":false,"setting":{"multiBarChart":{"rotate":{"degree":"-45"},"xLabelStatus":"default"},"table":{"tableGridState":{},"tableColumnTypeState":{"names":{"src":"string","label":"string","count(label)":"string"},"updated":false},"tableOptionSpecHash":"[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]","tableOptionValue":{"useFilter":false,"showPagination":false,"showAggregationFooter":false},"updated":false,"initialized":false}},"commonSetting":{},"keys":[{"name":"src","index":0,"aggr":"sum"}],"groups":[{"name":"label","index":1,"aggr":"sum"}],"values":[{"name":"count(label)","index":2,"aggr":"sum"}]},"helium":{}}},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TABLE","data":"src\tlabel\tcount(label)\nDEN\t0.0\t21052\nCLT\t0.0\t14912\nBOS\t0.0\t16840\nLGA\t1.0\t1984\nLGA\t0.0\t18498\nMIA\t1.0\t2340\nCLT\t1.0\t1796\nDFW\t0.0\t22114\nIAH\t1.0\t1862\nSEA\t0.0\t11833\nEWR\t1.0\t2372\nEWR\t0.0\t16279\nMIA\t0.0\t15649\nIAH\t0.0\t15812\nLAX\t0.0\t24694\nORD\t1.0\t4128\nORD\t0.0\t27944\nSFO\t1.0\t2308\nDFW\t1.0\t2858\nATL\t1.0\t3186\nDEN\t1.0\t2358\nLAX\t1.0\t2170\nSEA\t1.0\t864\nBOS\t1.0\t1743\nATL\t0.0\t26979\nSFO\t0.0\t20053\n"},{"type":"TEXT","data":""}]},"apps":[],"jobName":"paragraph_1554323655655_1899081748","id":"20171122-204822_1853914961","dateCreated":"2019-04-03T20:34:15+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:354"},{"title":"Prediction Departure Delay by Originating Airport","text":"%sql\nSELECT src, prediction, count(prediction)\nFROM flights \nGROUP BY src, prediction\n","user":"anonymous","dateUpdated":"2019-04-03T20:40:12+0000","config":{"editorSetting":{"language":"sql","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/sql","fontSize":9,"editorHide":false,"title":true,"results":{"0":{"graph":{"mode":"multiBarChart","height":300,"optionOpen":false,"setting":{"multiBarChart":{"rotate":{"degree":"-45"},"xLabelStatus":"default"},"table":{"tableGridState":{},"tableColumnTypeState":{"names":{"src":"string","label":"string","count(label)":"string"},"updated":false},"tableOptionSpecHash":"[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]","tableOptionValue":{"useFilter":false,"showPagination":false,"showAggregationFooter":false},"updated":false,"initialized":false}},"commonSetting":{},"keys":[{"name":"src","index":0,"aggr":"sum"}],"groups":[{"name":"prediction","index":1,"aggr":"sum"}],"values":[{"name":"count(prediction)","index":2,"aggr":"sum"}]},"helium":{}}},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TABLE","data":"src\tprediction\tcount(prediction)\nDEN\t0.0\t13668\nCLT\t0.0\t10381\nBOS\t0.0\t14141\nLGA\t1.0\t7546\nLGA\t0.0\t12936\nMIA\t1.0\t9119\nCLT\t1.0\t6327\nDFW\t0.0\t13541\nIAH\t1.0\t5036\nSEA\t0.0\t11369\nEWR\t1.0\t8223\nEWR\t0.0\t10428\nMIA\t0.0\t8870\nIAH\t0.0\t12638\nLAX\t0.0\t20980\nORD\t1.0\t18516\nORD\t0.0\t13556\nSFO\t1.0\t8289\nDFW\t1.0\t11431\nATL\t1.0\t12183\nDEN\t1.0\t9742\nLAX\t1.0\t5884\nSEA\t1.0\t1328\nBOS\t1.0\t4442\nATL\t0.0\t17982\nSFO\t0.0\t14072\n"},{"type":"TEXT","data":""}]},"apps":[],"jobName":"paragraph_1554323655655_-651502531","id":"20190307-190334_411445587","dateCreated":"2019-04-03T20:34:15+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:355"},{"title":"Count of Departure Delays by Day of the Week (1=Monday, 7=Sunday)","text":"%sql\nselect dofW, label, count(label), prediction, count(prediction)\nfrom flights \ngroup by dofW, label, prediction\n","user":"anonymous","dateUpdated":"2019-04-03T20:40:12+0000","config":{"editorSetting":{"language":"sql","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/sql","fontSize":9,"editorHide":false,"title":true,"results":{"0":{"graph":{"mode":"multiBarChart","height":300,"optionOpen":false,"setting":{"multiBarChart":{"rotate":{"degree":"-45"},"xLabelStatus":"default"},"table":{"tableGridState":{},"tableColumnTypeState":{"names":{"dofW":"string","label":"string","count(label)":"string","prediction":"string","count(prediction)":"string"},"updated":false},"tableOptionSpecHash":"[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]","tableOptionValue":{"useFilter":false,"showPagination":false,"showAggregationFooter":false},"updated":false,"initialized":false}},"commonSetting":{},"keys":[{"name":"dofW","index":0,"aggr":"sum"}],"groups":[{"name":"label","index":1,"aggr":"sum"}],"values":[{"name":"count(label)","index":2,"aggr":"sum"}]},"helium":{}}},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TABLE","data":"dofW\tlabel\tcount(label)\tprediction\tcount(prediction)\n1\t0.0\t22838\t0.0\t22838\n3\t1.0\t2395\t1.0\t2395\n3\t0.0\t12663\t1.0\t12663\n6\t0.0\t25114\t0.0\t25114\n5\t1.0\t1607\t0.0\t1607\n3\t0.0\t24127\t0.0\t24127\n1\t1.0\t1660\t0.0\t1660\n4\t1.0\t3440\t1.0\t3440\n3\t1.0\t1684\t0.0\t1684\n1\t0.0\t14831\t1.0\t14831\n5\t0.0\t13922\t1.0\t13922\n2\t1.0\t2963\t1.0\t2963\n2\t0.0\t24206\t0.0\t24206\n7\t1.0\t2796\t1.0\t2796\n7\t1.0\t1458\t0.0\t1458\n5\t0.0\t23772\t0.0\t23772\n6\t0.0\t5926\t1.0\t5926\n7\t0.0\t20786\t0.0\t20786\n6\t1.0\t1714\t0.0\t1714\n2\t0.0\t14136\t1.0\t14136\n4\t0.0\t14568\t1.0\t14568\n7\t0.0\t13186\t1.0\t13186\n1\t1.0\t3113\t1.0\t3113\n2\t1.0\t1534\t0.0\t1534\n4\t1.0\t1478\t0.0\t1478\n5\t1.0\t3186\t1.0\t3186\n6\t1.0\t941\t1.0\t941\n4\t0.0\t22584\t0.0\t22584\n"},{"type":"TEXT","data":""}]},"apps":[],"jobName":"paragraph_1554323655656_502343469","id":"20171123-101016_2040441762","dateCreated":"2019-04-03T20:34:15+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:356"},{"title":"Count of Departure Delays by Carrier (where label=1)","text":"%sql\nselect carrier, count(label)\nfrom flights where label = 1\ngroup by carrier\norder by carrier","user":"anonymous","dateUpdated":"2019-04-03T20:40:12+0000","config":{"editorSetting":{"language":"sql","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/sql","fontSize":9,"editorHide":false,"title":true,"results":{"0":{"graph":{"mode":"multiBarChart","height":300,"optionOpen":false,"setting":{"multiBarChart":{"rotate":{"degree":"-45"},"xLabelStatus":"default"},"table":{"tableGridState":{},"tableColumnTypeState":{"names":{"carrier":"string","count(label)":"string"},"updated":false},"tableOptionSpecHash":"[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]","tableOptionValue":{"useFilter":false,"showPagination":false,"showAggregationFooter":false},"updated":false,"initialized":false}},"commonSetting":{},"keys":[{"name":"carrier","index":0,"aggr":"sum"}],"groups":[],"values":[{"name":"count(label)","index":1,"aggr":"sum"}]},"helium":{}}},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TABLE","data":"carrier\tcount(label)\nAA\t11827\nDL\t5465\nUA\t10513\nWN\t2164\n"},{"type":"TEXT","data":""}]},"apps":[],"jobName":"paragraph_1554323655656_1424367348","id":"20171123-042011_1532799341","dateCreated":"2019-04-03T20:34:15+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:357"},{"title":"Count of Delayed Not Delayed  by Carrier","text":"%sql\nSELECT label, count(label),carrier\nFROM flights\nGROUP BY carrier, label\norder by carrier\n","user":"anonymous","dateUpdated":"2019-04-03T20:40:12+0000","config":{"editorSetting":{"language":"sql","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/sql","fontSize":9,"editorHide":true,"title":true,"results":{"0":{"graph":{"mode":"multiBarChart","height":300,"optionOpen":false,"setting":{"multiBarChart":{"stacked":false,"rotate":{"degree":"-45"},"xLabelStatus":"default"},"table":{"tableGridState":{},"tableColumnTypeState":{"names":{"label":"string","count(label)":"string","carrier":"string"},"updated":false},"tableOptionSpecHash":"[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]","tableOptionValue":{"useFilter":false,"showPagination":false,"showAggregationFooter":false},"updated":false,"initialized":false}},"commonSetting":{},"keys":[{"name":"carrier","index":2,"aggr":"sum"}],"groups":[{"name":"label","index":0,"aggr":"sum"}],"values":[{"name":"count(label)","index":1,"aggr":"sum"}]},"helium":{}}},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TABLE","data":"label\tcount(label)\tcarrier\n0.0\t97600\tAA\n1.0\t11827\tAA\n1.0\t5465\tDL\n0.0\t52730\tDL\n0.0\t88465\tUA\n1.0\t10513\tUA\n0.0\t13864\tWN\n1.0\t2164\tWN\n"},{"type":"TEXT","data":""}]},"apps":[],"jobName":"paragraph_1554323655657_1911572552","id":"20170524-144751_554129160","dateCreated":"2019-04-03T20:34:15+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:358"},{"title":"Count of Departure Delays by Hour of Day","text":"%sql\nselect crsdephour, count(depdelay)\nfrom flights where depdelay > 40\ngroup by crsdephour\n","user":"anonymous","dateUpdated":"2019-04-03T20:40:13+0000","config":{"editorSetting":{"language":"sql","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/sql","fontSize":9,"editorHide":false,"title":true,"results":{"0":{"graph":{"mode":"multiBarChart","height":300,"optionOpen":false,"setting":{"multiBarChart":{"rotate":{"degree":"-45"},"xLabelStatus":"default"}},"commonSetting":{},"keys":[{"name":"crsdephour","index":0,"aggr":"sum"}],"groups":[],"values":[{"name":"count(depdelay)","index":1,"aggr":"sum"}]},"helium":{}}},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TABLE","data":"crsdephour\tcount(depdelay)\n12\t1893\n22\t1066\n1\t51\n13\t1728\n16\t2309\n6\t518\n20\t2260\n5\t175\n19\t2198\n15\t1969\n9\t1112\n17\t2434\n8\t1067\n23\t364\n7\t1068\n10\t1472\n24\t58\n21\t1180\n11\t1321\n14\t2041\n0\t106\n18\t2929\n"},{"type":"TEXT","data":""}]},"apps":[],"jobName":"paragraph_1554323655657_-2017973221","id":"20171129-200107_756396508","dateCreated":"2019-04-03T20:34:15+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:359"},{"title":"Count of Delayed , Not Delayed by Hour","text":"%sql\nSELECT prediction, count(prediction),crsdephour\nFROM flights\nGROUP BY crsdephour, prediction\n","user":"anonymous","dateUpdated":"2019-04-03T20:40:13+0000","config":{"editorSetting":{"language":"sql","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/sql","fontSize":9,"editorHide":false,"title":true,"results":{"0":{"graph":{"mode":"multiBarChart","height":300,"optionOpen":false,"setting":{"multiBarChart":{"stacked":false,"rotate":{"degree":"-45"},"xLabelStatus":"default"},"table":{"tableGridState":{},"tableColumnTypeState":{"names":{"prediction":"string","count(prediction)":"string","crsdephour":"string"},"updated":false},"tableOptionSpecHash":"[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]","tableOptionValue":{"useFilter":false,"showPagination":false,"showAggregationFooter":false},"updated":false,"initialized":false}},"commonSetting":{},"keys":[{"name":"crsdephour","index":2,"aggr":"sum"}],"groups":[{"name":"prediction","index":0,"aggr":"sum"}],"values":[{"name":"count(prediction)","index":1,"aggr":"sum"}]},"helium":{}}},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TABLE","data":"prediction\tcount(prediction)\tcrsdephour\n0.0\t14116\t11\n1.0\t1096\t9\n1.0\t4538\t12\n1.0\t11552\t19\n0.0\t1268\t1\n1.0\t11411\t20\n0.0\t23136\t7\n1.0\t2145\t11\n0.0\t1517\t19\n1.0\t714\t23\n1.0\t12656\t17\n1.0\t15286\t18\n1.0\t585\t8\n1.0\t8307\t14\n0.0\t2124\t21\n1.0\t5567\t21\n0.0\t2609\t18\n0.0\t2355\t23\n0.0\t1457\t0\n1.0\t6442\t13\n1.0\t24\t24\n0.0\t3240\t22\n0.0\t14145\t12\n0.0\t17483\t8\n0.0\t17317\t10\n0.0\t1524\t20\n0.0\t8857\t14\n1.0\t5068\t22\n0.0\t9181\t13\n1.0\t297\t7\n1.0\t11639\t16\n0.0\t1051\t24\n0.0\t17178\t6\n0.0\t14962\t9\n0.0\t18\t2\n0.0\t5331\t16\n1.0\t9109\t15\n1.0\t148\t0\n0.0\t6162\t15\n0.0\t6265\t5\n1.0\t1482\t10\n0.0\t3266\t17\n"},{"type":"TEXT","data":""}]},"apps":[],"jobName":"paragraph_1554323655658_-979257313","id":"20170524-095127_757444423","dateCreated":"2019-04-03T20:34:15+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:360"},{"title":"Count of Departure Delays by Origin, Destination","text":"%sql\nselect src, dst, count(label)\nfrom flights where label=1.0\ngroup by src, dst\nORDER BY count(label) desc\n","user":"anonymous","dateUpdated":"2019-04-03T20:40:13+0000","config":{"editorSetting":{"language":"sql","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/sql","fontSize":9,"editorHide":false,"title":true,"results":{"0":{"graph":{"mode":"multiBarChart","height":300,"optionOpen":false,"setting":{"multiBarChart":{"rotate":{"degree":"-45"},"xLabelStatus":"default"},"table":{"tableGridState":{},"tableColumnTypeState":{"names":{"src":"string","dst":"string","count(label)":"string"},"updated":false},"tableOptionSpecHash":"[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]","tableOptionValue":{"useFilter":false,"showPagination":false,"showAggregationFooter":false},"updated":false,"initialized":false}},"commonSetting":{},"keys":[{"name":"src","index":0,"aggr":"sum"}],"groups":[{"name":"dst","index":1,"aggr":"sum"}],"values":[{"name":"count(label)","index":2,"aggr":"sum"}]},"helium":{}}},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TABLE","data":"src\tdst\tcount(label)\nORD\tLGA\t601\nLAX\tSFO\t589\nATL\tEWR\t576\nLGA\tORD\t541\nORD\tSFO\t478\nSFO\tLAX\t476\nATL\tLGA\t464\nORD\tLAX\t433\nORD\tDFW\t432\nDEN\tSFO\t395\nDFW\tORD\t392\nEWR\tATL\t386\nMIA\tLGA\t362\nORD\tEWR\t353\nSFO\tORD\t351\nLGA\tATL\t350\nORD\tATL\t337\nDFW\tATL\t337\nORD\tBOS\t329\nDEN\tLAX\t321\nLAX\tDEN\t310\nORD\tDEN\t310\nMIA\tATL\t304\nSFO\tDEN\t303\nLAX\tORD\t302\nEWR\tORD\t300\nATL\tDFW\t297\nBOS\tLGA\t285\nATL\tLAX\t280\nATL\tORD\t279\nDEN\tEWR\t279\nLGA\tBOS\t279\nIAH\tEWR\t276\nBOS\tEWR\t275\nDFW\tSFO\t272\nDEN\tORD\t272\nBOS\tORD\t271\nMIA\tORD\t267\nIAH\tDFW\t266\nDFW\tIAH\t265\nMIA\tDFW\t264\nEWR\tSFO\t262\nEWR\tBOS\t261\nCLT\tEWR\t261\nATL\tMIA\t259\nLGA\tMIA\t254\nATL\tBOS\t247\nORD\tSEA\t236\nDFW\tMIA\t227\nDFW\tDEN\t226\nORD\tMIA\t223\nORD\tIAH\t220\nDFW\tLAX\t220\nDFW\tLGA\t219\nSFO\tEWR\t219\nCLT\tORD\t214\nLAX\tATL\t209\nMIA\tEWR\t207\nEWR\tLAX\t207\nSFO\tDFW\t205\nMIA\tLAX\t204\nIAH\tSFO\t202\nDFW\tEWR\t201\nSFO\tSEA\t201\nDEN\tDFW\t201\nATL\tDEN\t199\nBOS\tATL\t198\nIAH\tORD\t195\nSEA\tSFO\t193\nEWR\tMIA\t190\nCLT\tATL\t189\nLGA\tDEN\t189\nATL\tSFO\t189\nDFW\tCLT\t188\nDEN\tLGA\t187\nCLT\tBOS\t186\nEWR\tDEN\t185\nMIA\tBOS\t183\nEWR\tIAH\t180\nDFW\tSEA\t178\nATL\tCLT\t177\nORD\tCLT\t176\nLAX\tDFW\t176\nMIA\tCLT\t174\nSFO\tBOS\t168\nEWR\tCLT\t167\nMIA\tSFO\t166\nLGA\tDFW\t165\nDEN\tATL\t164\nDEN\tSEA\t163\nEWR\tDFW\t161\nCLT\tDFW\t159\nIAH\tLGA\t154\nCLT\tLGA\t153\nSEA\tORD\t151\nCLT\tMIA\t145\nLAX\tEWR\t141\nIAH\tDEN\t141\nIAH\tLAX\t139\nIAH\tATL\t136\nDFW\tBOS\t133\nSEA\tDEN\t130\nSFO\tATL\t130\nLAX\tMIA\t129\nLGA\tCLT\t127\nATL\tIAH\t127\nMIA\tIAH\t126\nCLT\tSFO\t126\nBOS\tSFO\t125\nSFO\tIAH\t124\nDEN\tIAH\t122\nBOS\tCLT\t119\nDEN\tBOS\t118\nLAX\tBOS\t116\nBOS\tLAX\t115\nCLT\tDEN\t109\nCLT\tLAX\t100\nSEA\tDFW\t100\nBOS\tMIA\t99\nIAH\tMIA\t97\nATL\tSEA\t92\nIAH\tBOS\t92\nCLT\tIAH\t89\nBOS\tDFW\t87\nIAH\tCLT\t87\nBOS\tDEN\t83\nLGA\tIAH\t79\nIAH\tSEA\t77\nEWR\tSEA\t73\nLAX\tSEA\t72\nSFO\tMIA\t71\nDEN\tCLT\t70\nSEA\tATL\t69\nLAX\tCLT\t67\nSEA\tEWR\t67\nDEN\tMIA\t66\nCLT\tSEA\t65\nBOS\tIAH\t63\nSFO\tCLT\t60\nLAX\tIAH\t59\nSEA\tIAH\t50\nSEA\tLAX\t49\nMIA\tDEN\t42\nMIA\tSEA\t41\nSEA\tMIA\t25\nBOS\tSEA\t23\nSEA\tBOS\t21\nSEA\tCLT\t9\n"},{"type":"TEXT","data":""}]},"apps":[],"jobName":"paragraph_1554323655658_1565000983","id":"20171123-102627_1669385618","dateCreated":"2019-04-03T20:34:15+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:361"},{"title":"Calculate some more metrics","text":"val lp = df.select( \"label\", \"prediction\")\nval counttotal = lp.count().toDouble\nval correct = lp.filter($\"label\" === $\"prediction\").count().toDouble\nval wrong = lp.filter(not($\"label\" === $\"prediction\")).count().toDouble\nval truep =( lp.filter($\"label\" === 1.0).filter($\"label\" === $\"prediction\").count()) /counttotal\nval truen = (lp.filter($\"label\" === 0.0).filter($\"label\" === $\"prediction\").count())/counttotal\nval falsep = (lp.filter($\"label\" === 1.0).filter(not($\"label\" === $\"prediction\")).count())/counttotal\nval falsen = (lp.filter($\"label\" === 0.0).filter(not($\"label\" === $\"prediction\")).count())/counttotal\nval ratioWrong=wrong/counttotal\nval ratioCorrect=correct/counttotal\n\n","user":"anonymous","dateUpdated":"2019-04-03T20:34:15+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"lp: org.apache.spark.sql.DataFrame = [label: double, prediction: double]\ncounttotal: Double = 282628.0\ncorrect: Double = 182261.0\nwrong: Double = 100367.0\ntruep: Double = 0.06663883267050681\ntruen: Double = 0.5782406555613739\nfalsep: Double = 0.03939807803897703\nfalsen: Double = 0.3157224337291422\nratioWrong: Double = 0.3551205117681192\nratioCorrect: Double = 0.6448794882318808\nprecision: Double = 0.628449397710968\n"}]},"apps":[],"jobName":"paragraph_1554323655658_-1081859317","id":"20181015-224231_2027590368","dateCreated":"2019-04-03T20:34:15+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:362"},{"title":"stop the streaming from Kafka to MapR Database","text":"// stop the streaming from Kafka to MapR Database\nwritedb.stop()","user":"anonymous","dateUpdated":"2019-04-03T20:34:15+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1554323655659_-1503441268","id":"20171122-091021_1615582434","dateCreated":"2019-04-03T20:34:15+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:363"},{"title":"Unpersist Dataframe","text":"// when you are finished with your queries please run this\ndf.unpersist","user":"anonymous","dateUpdated":"2019-04-03T20:34:15+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1554323655659_-1886725580","id":"20190312-154408_916743367","dateCreated":"2019-04-03T20:34:15+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:364"},{"text":"%md\n## End of Part 3\nThis is the end of this notebook, and the end of this workshop\nWhen you are finished, make sure you ran the command above to save the model and unpersist the cached DataFrames.\nNext:\n* This is the end of this workshop, if you have time you can look at the graphframes lab\n* Scroll up to the top of this notebook page\n* Click on the Zeppelin Icon at the top of this page\n* This will take you to the list of notebooks\n* Select the notebook FlightDelay5GraphFrames","user":"anonymous","dateUpdated":"2019-04-03T20:34:15+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>End of Part 3</h2>\n<p>This is the end of this notebook, and the end of this workshop<br/>When you are finished, make sure you ran the command above to save the model and unpersist the cached DataFrames.<br/>Next:<br/>* This is the end of this workshop, if you have time you can look at the graphframes lab<br/>* Scroll up to the top of this notebook page<br/>* Click on the Zeppelin Icon at the top of this page<br/>* This will take you to the list of notebooks<br/>* Select the notebook FlightDelay5GraphFrames</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1554323655660_1290335085","id":"20190312-154230_1455949290","dateCreated":"2019-04-03T20:34:15+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:365"},{"user":"anonymous","dateUpdated":"2019-04-03T20:34:15+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1554323655660_-310697920","id":"20190307-175040_1835736035","dateCreated":"2019-04-03T20:34:15+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:366"}],"name":"FlightDelay3StructuredStreaming","id":"2E8D9A574","noteParams":{},"noteForms":{},"angularObjects":{},"config":{"isZeppelinNotebookCronEnable":false,"looknfeel":"default","personalizedMode":"false"},"info":{}}