{"paragraphs":[{"text":"%md\n# Fast data processing pipeline for predicting flight delays using Apache APIs: Kafka, Spark Streaming and Machine Learning\n# Part 1: Datasets, DataFrames, and Spark SQL for Processing of Tabular Data\nThis notebook is part one of series of notebooks demonstrating how to use Apache Spark’s ML pipelines with a Random Forest Classifier to predict flight delays, and then how to use this model with Streaming Data. In this Notebook we will give an introduction to Spark Datasets, DataFrames and Spark SQL. With Apache Spark 2.0 and later versions, big improvements were implemented to make Spark easier to program and execute faster: the Spark SQL and the Dataset/DataFrame APIs provide ease of use, space efficiency, and performance gains with Spark SQL's optimized execution engine. For more information, see [this](https://mapr.com/ebook/getting-started-with-apache-spark-v2/)  MapR Spark ebook.\n<img src=\"https://mapr.com/blog/datasets-dataframes-and-spark-sql-for-processing-of-tabular-data/assets/image4.jpg\">","user":"mapr","dateUpdated":"2019-03-08T20:23:39+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Fast data processing pipeline for predicting flight delays using Apache APIs: Kafka, Spark Streaming and Machine Learning</h1>\n<h1>Part 1: Datasets, DataFrames, and Spark SQL for Processing of Tabular Data</h1>\n<p>This notebook is part one of series of notebooks demonstrating how to use Apache Spark’s ML pipelines with a Random Forest Classifier to predict flight delays, and then how to use this model with Streaming Data. In this Notebook we will give an introduction to Spark Datasets, DataFrames and Spark SQL. With Apache Spark 2.0 and later versions, big improvements were implemented to make Spark easier to program and execute faster: the Spark SQL and the Dataset/DataFrame APIs provide ease of use, space efficiency, and performance gains with Spark SQL&rsquo;s optimized execution engine. For more information, see <a href=\"https://mapr.com/ebook/getting-started-with-apache-spark-v2/\">this</a> MapR Spark ebook.<br/><img src=\"https://mapr.com/blog/datasets-dataframes-and-spark-sql-for-processing-of-tabular-data/assets/image4.jpg\"></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1552060947891_-1546707004","id":"20190220-173254_1728425170","dateCreated":"2019-03-08T16:02:27+0000","dateStarted":"2019-03-08T19:50:57+0000","dateFinished":"2019-03-08T19:50:57+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:968"},{"text":"%md \n## Data Exploration\nTo go over some core concepts of Spark Datasets, we will be using some flight information from the United States Department of Transportation. Later, we will use this same data to predict flight delays, so we want to explore the flight attributes that most contribute to flight delays. Using Spark Datasets, we will explore the data to answer questions, like: which airline carriers, days of the week, originating airport, and hours of the day have the highest number of flight delays, when a delay is greater than 40 minutes?\n\nThe flight data is in JSON files, with each flight having the following information:\n\nid: ID composed of origin_destination_date_carrier_flight number\ndofW: day of week (1=Monday, 7=Sunday)\ncarrier: carrier code\nsrc: originating airport code\ndst: destination airport code\ncrsdephour: scheduled departure hour\ncrsdeptime: scheduled departure time\ndepdelay: departure delay in minutes\ncrsarrtime: scheduled arrival time\narrdelay: arrival delay minutes\ncrselapsedtime: elapsed time\ndist: distance\n\nIt appears in the following format:\n{\n    \"id\": \"ATL_BOS_2018-01-01_DL_104\",\n    \"fldate\": \"2018-01-01\",\n    \"month\": 1,\n    \"dofW\": 1,\n    \"carrier\": \"DL\",\n    \"src\": \"ATL\",\n    \"dst\": \"BOS\",\n    \"crsdephour\": 9,\n    \"crsdeptime\": 850,\n    \"depdelay\": 0.0,\n    \"crsarrtime\": 1116,\n    \"arrdelay\": 0.0,\n    \"crselapsedtime\": 146.0,\n    \"dist\": 946.0\n}\n","user":"mapr","dateUpdated":"2019-03-08T19:45:59+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>Data Exploration</h2>\n<p>To go over some core concepts of Spark Datasets, we will be using some flight information from the United States Department of Transportation. Later, we will use this same data to predict flight delays, so we want to explore the flight attributes that most contribute to flight delays. Using Spark Datasets, we will explore the data to answer questions, like: which airline carriers, days of the week, originating airport, and hours of the day have the highest number of flight delays, when a delay is greater than 40 minutes?</p>\n<p>The flight data is in JSON files, with each flight having the following information:</p>\n<p>id: ID composed of origin_destination_date_carrier_flight number<br/>dofW: day of week (1=Monday, 7=Sunday)<br/>carrier: carrier code<br/>src: originating airport code<br/>dst: destination airport code<br/>crsdephour: scheduled departure hour<br/>crsdeptime: scheduled departure time<br/>depdelay: departure delay in minutes<br/>crsarrtime: scheduled arrival time<br/>arrdelay: arrival delay minutes<br/>crselapsedtime: elapsed time<br/>dist: distance</p>\n<p>It appears in the following format:<br/>{<br/> &ldquo;id&rdquo;: &ldquo;ATL_BOS_2018-01-01_DL_104&rdquo;,<br/> &ldquo;fldate&rdquo;: &ldquo;2018-01-01&rdquo;,<br/> &ldquo;month&rdquo;: 1,<br/> &ldquo;dofW&rdquo;: 1,<br/> &ldquo;carrier&rdquo;: &ldquo;DL&rdquo;,<br/> &ldquo;src&rdquo;: &ldquo;ATL&rdquo;,<br/> &ldquo;dst&rdquo;: &ldquo;BOS&rdquo;,<br/> &ldquo;crsdephour&rdquo;: 9,<br/> &ldquo;crsdeptime&rdquo;: 850,<br/> &ldquo;depdelay&rdquo;: 0.0,<br/> &ldquo;crsarrtime&rdquo;: 1116,<br/> &ldquo;arrdelay&rdquo;: 0.0,<br/> &ldquo;crselapsedtime&rdquo;: 146.0,<br/> &ldquo;dist&rdquo;: 946.0<br/>}</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1552060947895_1516761955","id":"20170530-122945_1594214131","dateCreated":"2019-03-08T16:02:27+0000","dateStarted":"2019-03-08T19:45:59+0000","dateFinished":"2019-03-08T19:45:59+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:969"},{"title":"Import needed packages","text":"%spark\nimport org.apache.spark._\nimport org.apache.spark.ml._\nimport org.apache.spark.ml.feature._\nimport org.apache.spark.ml.classification._\nimport org.apache.spark.ml.evaluation._\nimport org.apache.spark.ml.tuning._\nimport org.apache.spark.sql._\nimport org.apache.spark.sql.functions._\nimport org.apache.spark.sql.types._","user":"mapr","dateUpdated":"2019-03-08T19:25:25+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import org.apache.spark._\nimport org.apache.spark.ml._\nimport org.apache.spark.ml.feature._\nimport org.apache.spark.ml.classification._\nimport org.apache.spark.ml.evaluation._\nimport org.apache.spark.ml.tuning._\nimport org.apache.spark.sql._\nimport org.apache.spark.sql.functions._\nimport org.apache.spark.sql.types._\n"}]},"apps":[],"jobName":"paragraph_1552060947897_1573407744","id":"20170508-144514_403247535","dateCreated":"2019-03-08T16:02:27+0000","dateStarted":"2019-03-08T19:25:25+0000","dateFinished":"2019-03-08T19:25:27+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:970"},{"title":"Define Schema for JSON file data","text":"// We use a Scala case class and Spark SQL Structype to define the Dataset schema, \n// corresponding to a line in the JSON data file.\n\ncase class Flight(id: String,fldate: String,month:Integer, dofW: Integer, carrier: String, src: String,dst: String, crsdephour: Integer, crsdeptime: Integer, depdelay: Double, crsarrtime: Integer, arrdelay: Double, crselapsedtime: Double, dist: Double)\n  \n  val schema = StructType(Array(\n    StructField(\"id\", StringType, true),\n    StructField(\"fldate\", StringType, true),\n    StructField(\"month\", IntegerType, true),\n    StructField(\"dofW\", IntegerType, true),\n    StructField(\"carrier\", StringType, true),\n    StructField(\"src\", StringType, true),\n    StructField(\"dst\", StringType, true),\n    StructField(\"crsdephour\", IntegerType, true),\n    StructField(\"crsdeptime\", IntegerType, true),\n    StructField(\"depdelay\", DoubleType, true),\n    StructField(\"crsarrtime\", IntegerType, true),\n    StructField(\"arrdelay\", DoubleType, true),\n    StructField(\"crselapsedtime\", DoubleType, true),\n    StructField(\"dist\", DoubleType, true)\n  ))\n   ","user":"mapr","dateUpdated":"2019-03-08T19:38:11+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"defined class Flight\nschema: org.apache.spark.sql.types.StructType = StructType(StructField(id,StringType,true), StructField(fldate,StringType,true), StructField(month,IntegerType,true), StructField(dofW,IntegerType,true), StructField(carrier,StringType,true), StructField(src,StringType,true), StructField(dst,StringType,true), StructField(crsdephour,IntegerType,true), StructField(crsdeptime,IntegerType,true), StructField(depdelay,DoubleType,true), StructField(crsarrtime,IntegerType,true), StructField(arrdelay,DoubleType,true), StructField(crselapsedtime,DoubleType,true), StructField(dist,DoubleType,true))\n"}]},"apps":[],"jobName":"paragraph_1552060947899_-248155214","id":"20170508-150032_326029627","dateCreated":"2019-03-08T16:02:27+0000","dateStarted":"2019-03-08T19:25:29+0000","dateFinished":"2019-03-08T19:25:31+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:971"},{"text":"%md\n# Loading Data from the a distributed File into a Dataset\n<img src=\"https://mapr.com/blog/datasets-dataframes-and-spark-sql-for-processing-of-tabular-data/assets/image10.png\">\nA Spark Dataset is a distributed collection of typed objects, which are partitioned across multiple nodes in a cluster and can be operated on in parallel.\nDatasets can be created from MapR-XD files, MapR-DB tables, or MapR-ES topics, and can be cached, allowing reuse across parallel operations. A Dataset can be manipulated using functional transformations (map, flatMap, filter, etc.) and/or Spark SQL. A DataFrame is a Dataset of Row objects and represents a table of data with rows and columns. A DataFrame consists of partitions, each of which is a range of rows in cache on a data node.\n<img src=\"https://mapr.com/blog/datasets-dataframes-and-spark-sql-for-processing-of-tabular-data/assets/image12.png\">\nThe entry point to programming in Spark is the org.apache.spark.sql.SparkSession class\nIf you are using the spark-shell or a notebook, the SparkSession object is already created and available as the variable spark.\nWith the SparkSession read method, we can read data from a file into a DataFrame, specifying the file type, file path, and input options for the schema. \nThe schema can optionally be inferred from the contents of the JSON file, but you will get better performance and accuracy by specifying the schema.\n\n","user":"mapr","dateUpdated":"2019-03-08T17:15:53+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Loading Data from the a distributed File into a Dataset</h1>\n<img src=\"https://mapr.com/blog/datasets-dataframes-and-spark-sql-for-processing-of-tabular-data/assets/image10.png\">\n<p>A Spark Dataset is a distributed collection of typed objects, which are partitioned across multiple nodes in a cluster and can be operated on in parallel.<br/>Datasets can be created from MapR-XD files, MapR-DB tables, or MapR-ES topics, and can be cached, allowing reuse across parallel operations. A Dataset can be manipulated using functional transformations (map, flatMap, filter, etc.) and/or Spark SQL. A DataFrame is a Dataset of Row objects and represents a table of data with rows and columns. A DataFrame consists of partitions, each of which is a range of rows in cache on a data node.<br/><img src=\"https://mapr.com/blog/datasets-dataframes-and-spark-sql-for-processing-of-tabular-data/assets/image12.png\"><br/>The entry point to programming in Spark is the org.apache.spark.sql.SparkSession class<br/>If you are using the spark-shell or a notebook, the SparkSession object is already created and available as the variable spark.<br/>With the SparkSession read method, we can read data from a file into a DataFrame, specifying the file type, file path, and input options for the schema.<br/>The schema can optionally be inferred from the contents of the JSON file, but you will get better performance and accuracy by specifying the schema.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1552063372880_-37929817","id":"20190308-164252_1081219350","dateCreated":"2019-03-08T16:42:52+0000","dateStarted":"2019-03-08T17:02:42+0000","dateFinished":"2019-03-08T17:02:42+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:972"},{"title":"Read the data from JSON file into a Dataset of type Flight","text":"import spark.implicits._\n\n// file path location\n var file =\"/user/mapr/data/flightdata2018.json\"\n// With the SparkSession read method, read data from a file into a Dataset\n val df: Dataset[Flight] = spark.read.format(\"json\").option(\"inferSchema\", \"false\").schema(schema).load(file).as[Flight]\n// display the first 20 rows of the DataFrame\n df.show\n","user":"mapr","dateUpdated":"2019-03-08T19:25:34+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import spark.implicits._\nfile: String = /user/mapr/data/flightdata2018.json\ndf: org.apache.spark.sql.Dataset[Flight] = [id: string, fldate: string ... 12 more fields]\n+--------------------+----------+-----+----+-------+---+---+----------+----------+--------+----------+--------+--------------+-----+\n|                  id|    fldate|month|dofW|carrier|src|dst|crsdephour|crsdeptime|depdelay|crsarrtime|arrdelay|crselapsedtime| dist|\n+--------------------+----------+-----+----+-------+---+---+----------+----------+--------+----------+--------+--------------+-----+\n|ATL_BOS_2018-01-0...|2018-01-01|    1|   1|     DL|ATL|BOS|         9|       850|     0.0|      1116|     0.0|         146.0|946.0|\n|ATL_BOS_2018-01-0...|2018-01-01|    1|   1|     DL|ATL|BOS|        11|      1122|     8.0|      1349|     0.0|         147.0|946.0|\n|ATL_BOS_2018-01-0...|2018-01-01|    1|   1|     DL|ATL|BOS|        14|      1356|     9.0|      1623|     0.0|         147.0|946.0|\n|ATL_BOS_2018-01-0...|2018-01-01|    1|   1|     DL|ATL|BOS|        16|      1620|     0.0|      1851|     3.0|         151.0|946.0|\n|ATL_BOS_2018-01-0...|2018-01-01|    1|   1|     DL|ATL|BOS|        19|      1940|     6.0|      2210|     0.0|         150.0|946.0|\n|ATL_BOS_2018-01-0...|2018-01-01|    1|   1|     DL|ATL|BOS|        12|      1248|     0.0|      1513|     0.0|         145.0|946.0|\n|ATL_BOS_2018-01-0...|2018-01-01|    1|   1|     DL|ATL|BOS|        22|      2215|     0.0|        39|     0.0|         144.0|946.0|\n|ATL_BOS_2018-01-0...|2018-01-01|    1|   1|     DL|ATL|BOS|        15|      1500|    21.0|      1734|    33.0|         154.0|946.0|\n|ATL_BOS_2018-01-0...|2018-01-01|    1|   1|     WN|ATL|BOS|        15|      1500|   198.0|      1725|   208.0|         145.0|946.0|\n|ATL_BOS_2018-01-0...|2018-01-01|    1|   1|     WN|ATL|BOS|        21|      2055|    14.0|      2330|     0.0|         155.0|946.0|\n|ATL_BOS_2018-01-0...|2018-01-01|    1|   1|     WN|ATL|BOS|        10|      1015|   215.0|      1250|   191.0|         155.0|946.0|\n|ATL_CLT_2018-01-0...|2018-01-01|    1|   1|     AA|ATL|CLT|        11|      1114|     0.0|      1238|     0.0|          84.0|226.0|\n|ATL_CLT_2018-01-0...|2018-01-01|    1|   1|     AA|ATL|CLT|         8|       845|     0.0|      1011|     0.0|          86.0|226.0|\n|ATL_CLT_2018-01-0...|2018-01-01|    1|   1|     AA|ATL|CLT|        15|      1548|     0.0|      1710|     0.0|          82.0|226.0|\n|ATL_CLT_2018-01-0...|2018-01-01|    1|   1|     AA|ATL|CLT|         7|       705|     0.0|       821|     0.0|          76.0|226.0|\n|ATL_CLT_2018-01-0...|2018-01-01|    1|   1|     AA|ATL|CLT|        12|      1226|     0.0|      1347|     0.0|          81.0|226.0|\n|ATL_CLT_2018-01-0...|2018-01-01|    1|   1|     AA|ATL|CLT|        22|      2205|     0.0|      2319|     1.0|          74.0|226.0|\n|ATL_CLT_2018-01-0...|2018-01-01|    1|   1|     DL|ATL|CLT|        22|      2210|    11.0|      2324|     0.0|          74.0|226.0|\n|ATL_CLT_2018-01-0...|2018-01-01|    1|   1|     DL|ATL|CLT|        15|      1543|     1.0|      1659|     0.0|          76.0|226.0|\n|ATL_CLT_2018-01-0...|2018-01-01|    1|   1|     DL|ATL|CLT|        10|      1008|     0.0|      1124|     0.0|          76.0|226.0|\n+--------------------+----------+-----+----+-------+---+---+----------+----------+--------+----------+--------+--------------+-----+\nonly showing top 20 rows\n\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://mapr-resman:8088/proxy/application_1551978809362_0003//jobs"],"interpreterSettingId":"spark"}},"apps":[],"jobName":"paragraph_1552060947900_2057789070","id":"20170508-150131_378637203","dateCreated":"2019-03-08T16:02:27+0000","dateStarted":"2019-03-08T19:25:34+0000","dateFinished":"2019-03-08T19:25:41+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:973"},{"title":" Take method on Dataset returns an array of Flight objects.","text":"// If we supply a scala case class with the as method when loading the data, \n// then the data is read into a Dataset of typed objects corresponding to the case class.\n// the take 1 method returns an Array with 1 flight object\ndf.take(1)","user":"mapr","dateUpdated":"2019-03-08T16:53:02+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala","title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"res66: Array[Flight] = Array(Flight(ATL_BOS_2018-01-01_DL_104,2018-01-01,1,1,DL,ATL,BOS,9,850,0.0,1116,0.0,146.0,946.0))\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://mapr-resman:8088/proxy/application_1551978809362_0002//jobs"],"interpreterSettingId":"spark"}},"apps":[],"jobName":"paragraph_1552063790409_-294218351","id":"20190308-164950_1853207952","dateCreated":"2019-03-08T16:49:50+0000","dateStarted":"2019-03-08T16:50:14+0000","dateFinished":"2019-03-08T16:50:17+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:974"},{"title":"Print DataFrame Schema","text":"// printSchema method prints out the dataFrame schmea \ndf.printSchema","user":"mapr","dateUpdated":"2019-03-08T17:06:14+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"root\n |-- id: string (nullable = true)\n |-- fldate: string (nullable = true)\n |-- month: integer (nullable = true)\n |-- dofW: integer (nullable = true)\n |-- carrier: string (nullable = true)\n |-- src: string (nullable = true)\n |-- dst: string (nullable = true)\n |-- crsdephour: integer (nullable = true)\n |-- crsdeptime: integer (nullable = true)\n |-- depdelay: double (nullable = true)\n |-- crsarrtime: integer (nullable = true)\n |-- arrdelay: double (nullable = true)\n |-- crselapsedtime: double (nullable = true)\n |-- dist: double (nullable = true)\n\n"}]},"apps":[],"jobName":"paragraph_1552060947904_1033838456","id":"20171129-223643_463511351","dateCreated":"2019-03-08T16:02:27+0000","dateStarted":"2019-03-08T17:06:14+0000","dateFinished":"2019-03-08T17:06:15+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:975"},{"text":"%md\nThe describe() function performs summary statistics calculations on  numeric columns ","user":"mapr","dateUpdated":"2019-03-08T17:06:23+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>The describe() function performs summary statistics calculations on numeric columns</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1552060947906_-1460400728","id":"20170524-214640_973339640","dateCreated":"2019-03-08T16:02:27+0000","dateStarted":"2019-03-08T17:06:23+0000","dateFinished":"2019-03-08T17:06:23+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:976"},{"title":"Perform summary statistics  on selected columns","text":"\ndf.describe(\"dist\", \"crselapsedtime\",\"depdelay\", \"arrdelay\").show","user":"mapr","dateUpdated":"2019-03-08T17:06:37+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+-------+------------------+------------------+------------------+------------------+\n|summary|              dist|    crselapsedtime|          depdelay|          arrdelay|\n+-------+------------------+------------------+------------------+------------------+\n|  count|            282628|            282628|            282628|            282628|\n|   mean|1154.9526267744172|189.82255119804125|14.468792900915691|14.565644592892424|\n| stddev| 629.5585331710331| 75.74564106190759| 43.72836248563901| 43.47539843809362|\n|    min|             184.0|              61.0|               0.0|               0.0|\n|    max|            2724.0|             433.0|            1559.0|            1576.0|\n+-------+------------------+------------------+------------------+------------------+\n\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://mapr-resman:8088/proxy/application_1551978809362_0002//jobs"],"interpreterSettingId":"spark"}},"apps":[],"jobName":"paragraph_1552060947907_-323548913","id":"20170524-083228_1459810795","dateCreated":"2019-03-08T16:02:27+0000","dateStarted":"2019-03-08T17:06:37+0000","dateFinished":"2019-03-08T17:06:40+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:977"},{"text":"%md\n# Transformations and Actions\nThere are two types of operations you can perform on a Dataset:\n\ntransformations: create a new Dataset from the current Dataset\nactions: trigger computation and return a result to the driver program\n<img src=\"https://mapr.com/blog/datasets-dataframes-and-spark-sql-for-processing-of-tabular-data/assets/image1.png\">\nDataFrame Transformations\nHere is a list of some commonly used untyped transformations, which can be used on Dataframes (Dataset[Row]).\n\nTransformation\tDescription\nselect\tSelects a set of columns\njoin\tJoin with another DataFrame, using the given join expression\ngroupBy\tGroups the DataFrame, using the specified columns\n\nHere is a list of some commonly used Dataset actions.\nAction\tDescription\nshow(n)\tDisplays the first n rows in a tabular form\ntake(n)\tReturns the first n objects in the Dataset in an array\ncount\tReturns the number of rows in the Dataset\n","user":"mapr","dateUpdated":"2019-03-08T17:16:10+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Transformations and Actions</h1>\n<p>There are two types of operations you can perform on a Dataset:</p>\n<p>transformations: create a new Dataset from the current Dataset<br/>actions: trigger computation and return a result to the driver program<br/><img src=\"https://mapr.com/blog/datasets-dataframes-and-spark-sql-for-processing-of-tabular-data/assets/image1.png\"><br/>DataFrame Transformations<br/>Here is a list of some commonly used untyped transformations, which can be used on Dataframes (Dataset[Row]).</p>\n<p>Transformation Description<br/>select Selects a set of columns<br/>join Join with another DataFrame, using the given join expression<br/>groupBy Groups the DataFrame, using the specified columns</p>\n<p>Here is a list of some commonly used Dataset actions.<br/>Action Description<br/>show(n) Displays the first n rows in a tabular form<br/>take(n) Returns the first n objects in the Dataset in an array<br/>count Returns the number of rows in the Dataset</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1552065120537_1836412768","id":"20190308-171200_853490725","dateCreated":"2019-03-08T17:12:00+0000","dateStarted":"2019-03-08T17:16:10+0000","dateFinished":"2019-03-08T17:16:10+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:978"},{"text":"// Here is an example using typed and untyped transformations and actions to get the originating airports \n// with the highest number of departure delays, where a delay is greater than 40 minutes. \n// We count the departure delays greater than 40 minutes by src and sort them with the highest first.\ndf.filter($\"depdelay\" > 40).groupBy(\"src\").count().orderBy(desc(\"count\")).show","user":"mapr","dateUpdated":"2019-03-08T17:15:47+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala","editorHide":false,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+---+-----+\n|src|count|\n+---+-----+\n|ORD| 4033|\n|ATL| 3106|\n|DFW| 2782|\n|EWR| 2328|\n|DEN| 2304|\n|MIA| 2294|\n|SFO| 2261|\n|LAX| 2126|\n|LGA| 1944|\n|IAH| 1829|\n|CLT| 1755|\n|BOS| 1711|\n|SEA|  846|\n+---+-----+\n\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://mapr-resman:8088/proxy/application_1551978809362_0002//jobs"],"interpreterSettingId":"spark"}},"apps":[],"jobName":"paragraph_1552065219839_-834072039","id":"20190308-171339_1735802559","dateCreated":"2019-03-08T17:13:39+0000","dateStarted":"2019-03-08T17:14:35+0000","dateFinished":"2019-03-08T17:14:38+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:979"},{"text":"%md\nIn the code below a Spark Bucketizer is used to split the dataset into delayed and not delayed flights (where delayed > 40 minutes ) \nwith a delayed 0/1 column. Then the resulting total counts are displayed. ","user":"mapr","dateUpdated":"2019-03-08T17:17:21+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>In the code below a Spark Bucketizer is used to split the dataset into delayed and not delayed flights (where delayed &gt; 40 minutes )<br/>with a delayed 0/1 column. Then the resulting total counts are displayed.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1552060947909_2069362344","id":"20190305-221927_113621865","dateCreated":"2019-03-08T16:02:27+0000","dateStarted":"2019-03-08T17:17:21+0000","dateFinished":"2019-03-08T17:17:21+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:980"},{"title":"Add Column for Delayed Flights and count","text":"// bucket > 40 minutes = delayed\nval delaybucketizer = new Bucketizer().setInputCol(\"depdelay\").setOutputCol(\"delayed\").setSplits(Array(0.0,41.0,Double.PositiveInfinity))\nval df1= delaybucketizer.transform(df)\ndf1.cache\ndf1.groupBy(\"delayed\").count.show","user":"mapr","dateUpdated":"2019-03-08T19:25:47+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"delaybucketizer: org.apache.spark.ml.feature.Bucketizer = bucketizer_3d161416fffb\ndf1: org.apache.spark.sql.DataFrame = [id: string, fldate: string ... 13 more fields]\nres14: df1.type = [id: string, fldate: string ... 13 more fields]\n+-------+------+\n|delayed| count|\n+-------+------+\n|    0.0|253309|\n|    1.0| 29319|\n+-------+------+\n\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://mapr-resman:8088/proxy/application_1551978809362_0003//jobs","http://mapr-resman:8088/proxy/application_1551978809362_0003//jobs","http://mapr-resman:8088/proxy/application_1551978809362_0003//jobs","http://mapr-resman:8088/proxy/application_1551978809362_0003//jobs","http://mapr-resman:8088/proxy/application_1551978809362_0003//jobs"],"interpreterSettingId":"spark"}},"apps":[],"jobName":"paragraph_1552060947911_-870707347","id":"20170524-093402_1430077788","dateCreated":"2019-03-08T16:02:27+0000","dateStarted":"2019-03-08T19:25:47+0000","dateFinished":"2019-03-08T19:25:55+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:981"},{"text":"%md \n# Exploring the Flight Dataset with Spark SQL\nNow let’s explore the flight Dataset using Spark SQL and DataFrame transformations. After we register the DataFrame as a SQL temporary view, we can use SQL functions on the SparkSession to run SQL queries, which will return the results as a DataFrame. We cache the DataFrame, since we will reuse it and because Spark can cache DataFrames or Tables in columnar format in memory, which can improve memory usage and performance.","user":"mapr","dateUpdated":"2019-03-08T17:18:18+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Exploring the Flight Dataset with Spark SQL</h1>\n<p>Now let’s explore the flight Dataset using Spark SQL and DataFrame transformations. After we register the DataFrame as a SQL temporary view, we can use SQL functions on the SparkSession to run SQL queries, which will return the results as a DataFrame. We cache the DataFrame, since we will reuse it and because Spark can cache DataFrames or Tables in columnar format in memory, which can improve memory usage and performance.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1552060947914_-1373646507","id":"20170603-182655_1680505289","dateCreated":"2019-03-08T16:02:27+0000","dateStarted":"2019-03-08T17:18:18+0000","dateFinished":"2019-03-08T17:18:18+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:982"},{"title":"Register Dataset as a Temporary View in order to explore with SQL","text":"df1.createOrReplaceTempView(\"flights\")\ndf1.cache\n","user":"mapr","dateUpdated":"2019-03-08T19:25:51+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"title":true,"results":{"0":{"graph":{"mode":"table","height":300,"optionOpen":true,"setting":{"stackedAreaChart":{}},"commonSetting":{},"keys":[{"name":"churn","index":19,"aggr":"sum"}],"groups":[],"values":[{"name":"len","index":1,"aggr":"sum"}]},"helium":{}}},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"res18: df1.type = [id: string, fldate: string ... 13 more fields]\n"}]},"apps":[],"jobName":"paragraph_1552060947912_-1359662772","id":"20170508-150408_505244914","dateCreated":"2019-03-08T16:02:27+0000","dateStarted":"2019-03-08T19:25:51+0000","dateFinished":"2019-03-08T19:25:56+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:983"},{"title":"Top 5 Longest departure delays with Spark DataFrame transformations","text":"//Below, we display information for the top five longest departure delays with DataFrame transformations\ndf1.select($\"carrier\",$\"src\",$\"dst\",$\"depdelay\", $\"crsdephour\").filter($\"depdelay\" > 40).orderBy(desc( \"depdelay\" )).show(5)","user":"mapr","dateUpdated":"2019-03-08T19:12:07+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala","title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+-------+---+---+--------+----------+\n|carrier|src|dst|depdelay|crsdephour|\n+-------+---+---+--------+----------+\n|     AA|IAH|MIA|  1559.0|        11|\n|     AA|IAH|DFW|  1445.0|        18|\n|     AA|BOS|DFW|  1345.0|        10|\n|     UA|BOS|ORD|  1334.0|         9|\n|     AA|LAX|MIA|  1283.0|         9|\n+-------+---+---+--------+----------+\nonly showing top 5 rows\n\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://mapr-resman:8088/proxy/application_1551978809362_0002//jobs"],"interpreterSettingId":"spark"}},"apps":[],"jobName":"paragraph_1552065555828_248569115","id":"20190308-171915_1304323195","dateCreated":"2019-03-08T17:19:15+0000","dateStarted":"2019-03-08T17:19:57+0000","dateFinished":"2019-03-08T17:19:59+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:984"},{"title":"Top 5 Longest departure delays with Spark SQL ","text":"%sql \nselect carrier,src, dst, depdelay,crsdephour, dist, dofW\nfrom flights where depdelay > 40\norder by depdelay desc limit 5 \n","user":"mapr","dateUpdated":"2019-03-08T19:12:01+0000","config":{"tableHide":false,"editorSetting":{"language":"sql","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/sql","editorHide":false,"fontSize":9,"title":true,"results":{"0":{"graph":{"mode":"table","height":300,"optionOpen":false,"setting":{"table":{"tableGridState":{},"tableColumnTypeState":{"names":{"carrier":"string","src":"string","dst":"string","depdelay":"string","crsdephour":"string","dist":"string","dofW":"string"},"updated":false},"tableOptionSpecHash":"[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]","tableOptionValue":{"useFilter":false,"showPagination":false,"showAggregationFooter":false},"updated":false,"initialized":false}},"commonSetting":{}}}},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TABLE","data":"carrier\tsrc\tdst\tdepdelay\tcrsdephour\tdist\tdofW\nAA\tIAH\tMIA\t1559.0\t11\t964.0\t5\nAA\tIAH\tDFW\t1445.0\t18\t224.0\t3\nAA\tBOS\tDFW\t1345.0\t10\t1562.0\t4\nUA\tBOS\tORD\t1334.0\t9\t867.0\t4\nAA\tLAX\tMIA\t1283.0\t9\t2342.0\t1\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://mapr-resman:8088/proxy/application_1551978809362_0002//jobs"],"interpreterSettingId":"spark"}},"apps":[],"jobName":"paragraph_1552060947916_755329476","id":"20171110-195321_1924356975","dateCreated":"2019-03-08T16:02:27+0000","dateStarted":"2019-03-08T17:21:17+0000","dateFinished":"2019-03-08T17:21:19+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:985"},{"text":"%md\nWith a notebook like Zeppelin or Jupyter, you can also display the SQL results in graph formats. Click on the bargraph, pie chart.. icons then click on settings\nto explore the result display formats \n","user":"mapr","dateUpdated":"2019-03-08T19:11:24+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>With a notebook like Zeppelin or Jupyter, you can also display the SQL results in graph formats. Click on the bargraph, pie chart.. icons then click on settings<br/>to explore the result display formats</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1552072204511_-1965650170","id":"20190308-191004_1663643379","dateCreated":"2019-03-08T19:10:04+0000","dateStarted":"2019-03-08T19:11:24+0000","dateFinished":"2019-03-08T19:11:27+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:986"},{"title":"Average Departure Delay by Carrier","text":"%sql select carrier, avg(depdelay)\nfrom flights\ngroup by carrier","user":"mapr","dateUpdated":"2019-03-08T20:23:37+0000","config":{"editorSetting":{"language":"sql","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/sql","fontSize":9,"editorHide":false,"title":true,"results":{"0":{"graph":{"mode":"multiBarChart","height":300,"optionOpen":false,"setting":{"multiBarChart":{"rotate":{"degree":"-45"},"xLabelStatus":"default"},"stackedAreaChart":{"rotate":{"degree":"-45"},"xLabelStatus":"default"}},"commonSetting":{},"keys":[{"name":"carrier","index":0,"aggr":"sum"}],"groups":[],"values":[{"name":"avg(depdelay)","index":1,"aggr":"sum"}]},"helium":{}}},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TABLE","data":"carrier\tavg(depdelay)\nUA\t14.442583200307139\nAA\t14.129090626627798\nDL\t14.26168914855228\nWN\t17.70183428999251\n"},{"type":"TEXT","data":""}]},"apps":[],"jobName":"paragraph_1552060947917_-354014296","id":"20171110-195759_439800395","dateCreated":"2019-03-08T16:02:27+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:987"},{"title":"Average Departure Delay by Originating Airport","text":"%sql\nSELECT src, avg(depdelay) as avgdelay\nFROM flights \nGROUP BY src\nORDER BY avgdelay desc","user":"mapr","dateUpdated":"2019-03-08T20:23:37+0000","config":{"editorSetting":{"language":"sql","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/sql","fontSize":9,"editorHide":false,"title":true,"results":{"0":{"graph":{"mode":"multiBarChart","height":300,"optionOpen":false,"setting":{"multiBarChart":{"rotate":{"degree":"-45"},"xLabelStatus":"default"}},"commonSetting":{},"keys":[{"name":"src","index":0,"aggr":"sum"}],"groups":[],"values":[{"name":"avgdelay","index":1,"aggr":"sum"}]},"helium":{}}},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TABLE","data":"src\tavgdelay\nEWR\t17.818079459546404\nMIA\t17.768691978431264\nORD\t16.5199551010227\nATL\t15.330084535057185\nDFW\t15.061909338459074\nDEN\t14.192011960700555\nCLT\t14.081517835767297\nIAH\t13.804911168948738\nSFO\t13.792674746209919\nLGA\t13.586563812127721\nBOS\t12.940644675240812\nLAX\t11.223347230494342\nSEA\t10.140899425061038\n"},{"type":"TEXT","data":""}]},"apps":[],"jobName":"paragraph_1552060947921_-1087670761","id":"20171122-204822_1853914961","dateCreated":"2019-03-08T16:02:27+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:988"},{"text":"%md\nLet’s explore this data for flight delays, where the departure delay is greater than 40 minutes.\n","user":"mapr","dateUpdated":"2019-03-08T19:13:30+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>Let’s explore this data for flight delays, where the departure delay is greater than 40 minutes.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1552072383935_-695958348","id":"20190308-191303_1290065302","dateCreated":"2019-03-08T19:13:03+0000","dateStarted":"2019-03-08T19:13:30+0000","dateFinished":"2019-03-08T19:13:30+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:989"},{"title":"Count of Departure Delays by Day of the Week (1=Monday, 7=Sunday)","text":"%sql\nselect dofW, count(depdelay)\nfrom flights where depdelay > 40\ngroup by dofW\n","user":"mapr","dateUpdated":"2019-03-08T20:23:37+0000","config":{"editorSetting":{"language":"sql","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/sql","fontSize":9,"editorHide":false,"title":true,"results":{"0":{"graph":{"mode":"multiBarChart","height":300,"optionOpen":false,"setting":{"multiBarChart":{"rotate":{"degree":"-45"},"xLabelStatus":"default"}},"commonSetting":{},"keys":[{"name":"dofW","index":0,"aggr":"sum"}],"groups":[],"values":[{"name":"count(depdelay)","index":1,"aggr":"sum"}]},"helium":{}}},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TABLE","data":"dofW\tcount(depdelay)\n1\t4680\n6\t2598\n3\t3986\n5\t4677\n4\t4809\n7\t4163\n2\t4406\n"},{"type":"TEXT","data":""}]},"apps":[],"jobName":"paragraph_1552060947922_-702608044","id":"20171123-101016_2040441762","dateCreated":"2019-03-08T16:02:27+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:990"},{"title":"Count of Departure Delays by Carrier (where delay=40 minutes)","text":"%sql\nselect carrier, count(delayed)\nfrom flights where delayed = 1\ngroup by carrier\norder by carrier","user":"mapr","dateUpdated":"2019-03-08T20:23:37+0000","config":{"editorSetting":{"language":"sql","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/sql","fontSize":9,"editorHide":false,"title":true,"results":{"0":{"graph":{"mode":"multiBarChart","height":300,"optionOpen":false,"setting":{"multiBarChart":{"rotate":{"degree":"-45"},"xLabelStatus":"default"}},"commonSetting":{},"keys":[{"name":"carrier","index":0,"aggr":"sum"}],"groups":[],"values":[{"name":"count(delayed)","index":1,"aggr":"sum"}]},"helium":{}}},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TABLE","data":"carrier\tcount(delayed)\nAA\t11570\nDL\t5354\nUA\t10297\nWN\t2098\n"},{"type":"TEXT","data":""}]},"apps":[],"jobName":"paragraph_1552060947924_-839269781","id":"20171123-042011_1532799341","dateCreated":"2019-03-08T16:02:27+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:991"},{"title":"Count of Delayed Not Delayed  by Carrier","text":"%sql\nSELECT delayed, count(delayed),carrier\nFROM flights\nGROUP BY carrier, delayed\norder by carrier\n","user":"mapr","dateUpdated":"2019-03-08T20:23:37+0000","config":{"editorSetting":{"language":"sql","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/sql","fontSize":9,"editorHide":false,"title":true,"results":{"0":{"graph":{"mode":"multiBarChart","height":300,"optionOpen":false,"setting":{"multiBarChart":{"stacked":false,"rotate":{"degree":"-45"},"xLabelStatus":"default"}},"commonSetting":{},"keys":[{"name":"carrier","index":2,"aggr":"sum"}],"groups":[{"name":"delayed","index":0,"aggr":"sum"}],"values":[{"name":"count(delayed)","index":1,"aggr":"sum"}]},"helium":{}}},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TABLE","data":"delayed\tcount(delayed)\tcarrier\n1.0\t11570\tAA\n0.0\t97857\tAA\n0.0\t52841\tDL\n1.0\t5354\tDL\n0.0\t88681\tUA\n1.0\t10297\tUA\n1.0\t2098\tWN\n0.0\t13930\tWN\n"},{"type":"TEXT","data":""}]},"apps":[],"jobName":"paragraph_1552060947925_1387658132","id":"20170524-144751_554129160","dateCreated":"2019-03-08T16:02:27+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:992"},{"text":"%md\nIn the query below, we see that the hours between 14:00-20:00 have the highest count of flight delays.\n","user":"mapr","dateUpdated":"2019-03-08T19:18:41+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>In the query below, we see that the hours between 14:00-20:00 have the highest count of flight delays.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1552072650934_-416445707","id":"20190308-191730_1553740160","dateCreated":"2019-03-08T19:17:30+0000","dateStarted":"2019-03-08T19:18:41+0000","dateFinished":"2019-03-08T19:18:41+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:993"},{"title":"Count of Departure Delays by Hour of Day","text":"%sql\nselect crsdephour, count(depdelay)\nfrom flights where depdelay > 40\ngroup by crsdephour\n","user":"mapr","dateUpdated":"2019-03-08T20:23:37+0000","config":{"editorSetting":{"language":"sql","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/sql","fontSize":9,"editorHide":false,"title":true,"results":{"0":{"graph":{"mode":"multiBarChart","height":300,"optionOpen":false,"setting":{"multiBarChart":{"rotate":{"degree":"-45"},"xLabelStatus":"default"}},"commonSetting":{},"keys":[{"name":"crsdephour","index":0,"aggr":"sum"}],"groups":[],"values":[{"name":"count(depdelay)","index":1,"aggr":"sum"}]},"helium":{}}},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TABLE","data":"crsdephour\tcount(depdelay)\n12\t1893\n22\t1066\n1\t51\n13\t1728\n6\t518\n16\t2309\n20\t2260\n5\t175\n19\t2198\n15\t1969\n17\t2434\n9\t1112\n8\t1067\n23\t364\n7\t1068\n10\t1472\n24\t58\n21\t1180\n11\t1321\n14\t2041\n0\t106\n18\t2929\n"},{"type":"TEXT","data":""}]},"apps":[],"jobName":"paragraph_1552060947927_-1194476238","id":"20171129-200107_756396508","dateCreated":"2019-03-08T16:02:27+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:994"},{"title":"Count of Delayed , Not Delayed by Hour","text":"%sql\nSELECT delayed, count(delayed),crsdephour\nFROM flights\nGROUP BY crsdephour, delayed\norder by delayed","user":"mapr","dateUpdated":"2019-03-08T20:23:37+0000","config":{"editorSetting":{"language":"sql","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/sql","fontSize":9,"editorHide":false,"title":true,"results":{"0":{"graph":{"mode":"multiBarChart","height":300,"optionOpen":false,"setting":{"multiBarChart":{"stacked":false,"rotate":{"degree":"-45"},"xLabelStatus":"default"}},"commonSetting":{},"keys":[{"name":"crsdephour","index":2,"aggr":"sum"}],"groups":[{"name":"delayed","index":0,"aggr":"sum"}],"values":[{"name":"count(delayed)","index":1,"aggr":"sum"}]},"helium":{}}},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TABLE","data":"delayed\tcount(delayed)\tcrsdephour\n0.0\t22365\t7\n0.0\t1499\t0\n0.0\t7242\t22\n0.0\t10675\t20\n0.0\t1217\t1\n0.0\t14966\t18\n0.0\t17327\t10\n0.0\t6511\t21\n0.0\t16790\t12\n0.0\t17001\t8\n0.0\t1017\t24\n0.0\t16660\t6\n0.0\t14946\t9\n0.0\t18\t2\n0.0\t14940\t11\n0.0\t2705\t23\n0.0\t13895\t13\n0.0\t15123\t14\n0.0\t14661\t16\n0.0\t13302\t15\n0.0\t10871\t19\n0.0\t13488\t17\n0.0\t6090\t5\n1.0\t1893\t12\n1.0\t364\t23\n1.0\t1321\t11\n1.0\t2260\t20\n1.0\t2434\t17\n1.0\t1112\t9\n1.0\t2198\t19\n1.0\t2041\t14\n1.0\t1728\t13\n1.0\t175\t5\n1.0\t58\t24\n1.0\t2929\t18\n1.0\t51\t1\n1.0\t1180\t21\n1.0\t1067\t8\n1.0\t1969\t15\n1.0\t1066\t22\n1.0\t1472\t10\n1.0\t1068\t7\n1.0\t2309\t16\n1.0\t518\t6\n1.0\t106\t0\n"},{"type":"TEXT","data":""}]},"apps":[],"jobName":"paragraph_1552060947928_1415326022","id":"20170524-095127_757444423","dateCreated":"2019-03-08T16:02:27+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:995"},{"text":"%md\nIn the query below, we see that the originating airports, Chicago and Atlanta, have the highest count of flight delays.\n","user":"mapr","dateUpdated":"2019-03-08T19:19:26+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>In the query below, we see that the originating airports, Chicago and Atlanta, have the highest count of flight delays.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1552072755393_2036504545","id":"20190308-191915_1484138904","dateCreated":"2019-03-08T19:19:15+0000","dateStarted":"2019-03-08T19:19:26+0000","dateFinished":"2019-03-08T19:19:26+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:996"},{"title":"Count of Departure Delays by Origin","text":"%sql\nSELECT delayed, count(delayed),src\nFROM flights where delayed=1\nGROUP BY src, delayed\norder by count(delayed) desc\n","user":"mapr","dateUpdated":"2019-03-08T20:23:37+0000","config":{"editorSetting":{"language":"sql","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/sql","fontSize":9,"editorHide":false,"title":true,"results":{"0":{"graph":{"mode":"multiBarChart","height":300,"optionOpen":false,"setting":{"pieChart":{},"multiBarChart":{"stacked":false,"rotate":{"degree":"-45"},"xLabelStatus":"default"}},"commonSetting":{},"keys":[{"name":"src","index":2,"aggr":"sum"}],"groups":[{"name":"delayed","index":0,"aggr":"sum"}],"values":[{"name":"count(delayed)","index":1,"aggr":"sum"}]},"helium":{}}},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TABLE","data":"delayed\tcount(delayed)\tsrc\n1.0\t4033\tORD\n1.0\t3106\tATL\n1.0\t2782\tDFW\n1.0\t2328\tEWR\n1.0\t2304\tDEN\n1.0\t2294\tMIA\n1.0\t2261\tSFO\n1.0\t2126\tLAX\n1.0\t1944\tLGA\n1.0\t1829\tIAH\n1.0\t1755\tCLT\n1.0\t1711\tBOS\n1.0\t846\tSEA\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://mapr-resman:8088/proxy/application_1551978809362_0003//jobs"],"interpreterSettingId":"spark"}},"apps":[],"jobName":"paragraph_1552060947930_1326816909","id":"20171110-211045_792848918","dateCreated":"2019-03-08T16:02:27+0000","dateStarted":"2019-03-08T19:27:43+0000","dateFinished":"2019-03-08T19:27:44+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:997"},{"title":"Count of Delayed Not Delayed by Originating Airport","text":"%sql\nSELECT delayed, count(delayed),src\nFROM flights \nGROUP BY src, delayed\norder by count(delayed) desc\n","user":"mapr","dateUpdated":"2019-03-08T20:23:37+0000","config":{"editorSetting":{"language":"sql","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/sql","fontSize":9,"editorHide":false,"title":true,"results":{"0":{"graph":{"mode":"multiBarChart","height":300,"optionOpen":false,"setting":{"pieChart":{},"multiBarChart":{"stacked":false,"rotate":{"degree":"-45"},"xLabelStatus":"default"}},"commonSetting":{},"keys":[{"name":"src","index":2,"aggr":"sum"}],"groups":[{"name":"delayed","index":0,"aggr":"sum"}],"values":[{"name":"count(delayed)","index":1,"aggr":"sum"}]},"helium":{}}},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TABLE","data":"delayed\tcount(delayed)\tsrc\n0.0\t28039\tORD\n0.0\t27059\tATL\n0.0\t24738\tLAX\n0.0\t22190\tDFW\n0.0\t21106\tDEN\n0.0\t20100\tSFO\n0.0\t18538\tLGA\n0.0\t16872\tBOS\n0.0\t16323\tEWR\n0.0\t15845\tIAH\n0.0\t15695\tMIA\n0.0\t14953\tCLT\n0.0\t11851\tSEA\n1.0\t4033\tORD\n1.0\t3106\tATL\n1.0\t2782\tDFW\n1.0\t2328\tEWR\n1.0\t2304\tDEN\n1.0\t2294\tMIA\n1.0\t2261\tSFO\n1.0\t2126\tLAX\n1.0\t1944\tLGA\n1.0\t1829\tIAH\n1.0\t1755\tCLT\n1.0\t1711\tBOS\n1.0\t846\tSEA\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://mapr-resman:8088/proxy/application_1551978809362_0003//jobs"],"interpreterSettingId":"spark"}},"apps":[],"jobName":"paragraph_1552073279790_810276054","id":"20190308-192759_1763865304","dateCreated":"2019-03-08T19:27:59+0000","dateStarted":"2019-03-08T19:28:27+0000","dateFinished":"2019-03-08T19:28:28+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:998"},{"title":"Count of Delayed not Delayed by Destination Airport","text":"%sql\nSELECT delayed, count(delayed),dst\nFROM flights\nGROUP BY dst, delayed\norder by count(delayed) desc","user":"mapr","dateUpdated":"2019-03-08T20:23:37+0000","config":{"editorSetting":{"language":"sql","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/sql","fontSize":9,"editorHide":false,"title":true,"results":{"0":{"graph":{"mode":"multiBarChart","height":300,"optionOpen":false,"setting":{"multiBarChart":{"rotate":{"degree":"-45"},"xLabelStatus":"default"}},"commonSetting":{},"keys":[{"name":"dst","index":2,"aggr":"sum"}],"groups":[{"name":"delayed","index":0,"aggr":"sum"}],"values":[{"name":"count(delayed)","index":1,"aggr":"sum"}]},"helium":{}}},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TABLE","data":"delayed\tcount(delayed)\tdst\n0.0\t28849\tORD\n0.0\t27458\tATL\n0.0\t24389\tLAX\n0.0\t22476\tDFW\n0.0\t21031\tDEN\n0.0\t19404\tSFO\n0.0\t18071\tLGA\n0.0\t16612\tBOS\n0.0\t16262\tMIA\n0.0\t16073\tIAH\n0.0\t15740\tEWR\n0.0\t15409\tCLT\n0.0\t11535\tSEA\n1.0\t3465\tORD\n1.0\t2946\tSFO\n1.0\t2796\tEWR\n1.0\t2759\tATL\n1.0\t2480\tLAX\n1.0\t2471\tDFW\n1.0\t2363\tLGA\n1.0\t2171\tDEN\n1.0\t2078\tBOS\n1.0\t1741\tMIA\n1.0\t1468\tIAH\n1.0\t1390\tCLT\n1.0\t1191\tSEA\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://mapr-resman:8088/proxy/application_1551978809362_0003//jobs"],"interpreterSettingId":"spark"}},"apps":[],"jobName":"paragraph_1552060947932_-1000814089","id":"20171122-211508_2036968500","dateCreated":"2019-03-08T16:02:27+0000","dateStarted":"2019-03-08T19:28:54+0000","dateFinished":"2019-03-08T19:28:55+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:999"},{"title":"Count of Departure Delays by Origin, Destination","text":"%sql\nselect src, dst, count(depdelay)\nfrom flights where depdelay > 40\ngroup by src, dst\nORDER BY count(depdelay) desc\n","user":"mapr","dateUpdated":"2019-03-08T20:23:37+0000","config":{"editorSetting":{"language":"sql","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/sql","fontSize":9,"editorHide":false,"title":true,"results":{"0":{"graph":{"mode":"multiBarChart","height":300,"optionOpen":false,"setting":{"multiBarChart":{"rotate":{"degree":"-45"},"xLabelStatus":"default"}},"commonSetting":{},"keys":[{"name":"src","index":0,"aggr":"sum"}],"groups":[{"name":"dst","index":1,"aggr":"sum"}],"values":[{"name":"count(depdelay)","index":2,"aggr":"sum"}]},"helium":{}}},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TABLE","data":"src\tdst\tcount(depdelay)\nORD\tLGA\t588\nLAX\tSFO\t578\nATL\tEWR\t561\nLGA\tORD\t532\nORD\tSFO\t470\nSFO\tLAX\t463\nATL\tLGA\t445\nORD\tLAX\t425\nORD\tDFW\t423\nDEN\tSFO\t388\nEWR\tATL\t381\nDFW\tORD\t377\nMIA\tLGA\t355\nORD\tEWR\t347\nLGA\tATL\t344\nSFO\tORD\t343\nDFW\tATL\t328\nORD\tATL\t326\nORD\tBOS\t318\nDEN\tLAX\t311\nLAX\tDEN\t303\nORD\tDEN\t302\nSFO\tDEN\t299\nMIA\tATL\t299\nLAX\tORD\t298\nEWR\tORD\t297\nATL\tDFW\t293\nBOS\tLGA\t279\nLGA\tBOS\t276\nDEN\tEWR\t275\nATL\tLAX\t275\nATL\tORD\t273\nDFW\tSFO\t269\nBOS\tEWR\t269\nIAH\tEWR\t269\nBOS\tORD\t267\nDEN\tORD\t265\nIAH\tDFW\t264\nMIA\tORD\t262\nMIA\tDFW\t259\nEWR\tSFO\t257\nCLT\tEWR\t255\nEWR\tBOS\t255\nDFW\tIAH\t255\nATL\tMIA\t255\nLGA\tMIA\t248\nATL\tBOS\t243\nORD\tSEA\t232\nDFW\tDEN\t222\nDFW\tMIA\t217\nORD\tIAH\t217\nDFW\tLAX\t216\nSFO\tEWR\t214\nDFW\tLGA\t214\nCLT\tORD\t213\nORD\tMIA\t212\nSFO\tDFW\t202\nEWR\tLAX\t202\nLAX\tATL\t201\nMIA\tEWR\t201\nDFW\tEWR\t200\nIAH\tSFO\t199\nDEN\tDFW\t198\nMIA\tLAX\t198\nBOS\tATL\t198\nSFO\tSEA\t196\nATL\tDEN\t192\nSEA\tSFO\t191\nIAH\tORD\t189\nEWR\tMIA\t188\nCLT\tATL\t186\nATL\tSFO\t185\nDFW\tCLT\t185\nDEN\tLGA\t184\nLGA\tDEN\t182\nCLT\tBOS\t181\nEWR\tDEN\t178\nMIA\tBOS\t178\nEWR\tIAH\t177\nMIA\tCLT\t174\nDFW\tSEA\t174\nLAX\tDFW\t174\nORD\tCLT\t173\nATL\tCLT\t170\nSFO\tBOS\t165\nDEN\tATL\t164\nMIA\tSFO\t164\nEWR\tCLT\t162\nLGA\tDFW\t162\nEWR\tDFW\t159\nDEN\tSEA\t155\nCLT\tDFW\t155\nIAH\tLGA\t151\nSEA\tORD\t149\nCLT\tLGA\t147\nCLT\tMIA\t144\nLAX\tEWR\t140\nIAH\tDEN\t139\nIAH\tLAX\t136\nIAH\tATL\t136\nSFO\tATL\t128\nSEA\tDEN\t126\nLAX\tMIA\t126\nCLT\tSFO\t125\nDFW\tBOS\t125\nLGA\tCLT\t124\nATL\tIAH\t124\nMIA\tIAH\t123\nSFO\tIAH\t122\nDEN\tIAH\t120\nBOS\tSFO\t120\nBOS\tCLT\t116\nLAX\tBOS\t114\nBOS\tLAX\t113\nDEN\tBOS\t112\nCLT\tDEN\t106\nBOS\tMIA\t97\nSEA\tDFW\t97\nIAH\tMIA\t94\nCLT\tLAX\t93\nIAH\tBOS\t90\nATL\tSEA\t90\nIAH\tCLT\t86\nCLT\tIAH\t86\nBOS\tDFW\t85\nBOS\tDEN\t81\nIAH\tSEA\t76\nLGA\tIAH\t76\nEWR\tSEA\t72\nSFO\tMIA\t70\nLAX\tSEA\t69\nSEA\tATL\t68\nDEN\tCLT\t67\nLAX\tCLT\t65\nDEN\tMIA\t65\nSEA\tEWR\t65\nCLT\tSEA\t64\nBOS\tIAH\t63\nSFO\tCLT\t59\nLAX\tIAH\t58\nSEA\tLAX\t48\nSEA\tIAH\t47\nMIA\tDEN\t41\nMIA\tSEA\t40\nSEA\tMIA\t25\nBOS\tSEA\t23\nSEA\tBOS\t21\nSEA\tCLT\t9\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://mapr-resman:8088/proxy/application_1551978809362_0003//jobs"],"interpreterSettingId":"spark"}},"apps":[],"jobName":"paragraph_1552060947933_400525635","id":"20171123-102627_1669385618","dateCreated":"2019-03-08T16:02:27+0000","dateStarted":"2019-03-08T19:30:29+0000","dateFinished":"2019-03-08T19:30:31+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:1000"},{"title":"Add origin_dest column  and display the first 20 rows","text":"// Here we add a column to the DataFrame named orig_dest, consisting of the originating and destination airports\nval df2 = df1.withColumn(\"orig_dest\", concat($\"src\",lit(\"_\"), $\"dst\"))\ndf2.createOrReplaceTempView(\"flights\")\ndf2.show()\n\n","user":"mapr","dateUpdated":"2019-03-08T19:40:50+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"df2: org.apache.spark.sql.DataFrame = [id: string, fldate: string ... 14 more fields]\n+--------------------+----------+-----+----+-------+---+---+----------+----------+--------+----------+--------+--------------+-----+-------+---------+\n|                  id|    fldate|month|dofW|carrier|src|dst|crsdephour|crsdeptime|depdelay|crsarrtime|arrdelay|crselapsedtime| dist|delayed|orig_dest|\n+--------------------+----------+-----+----+-------+---+---+----------+----------+--------+----------+--------+--------------+-----+-------+---------+\n|ATL_BOS_2018-01-0...|2018-01-01|    1|   1|     DL|ATL|BOS|         9|       850|     0.0|      1116|     0.0|         146.0|946.0|    0.0|  ATL_BOS|\n|ATL_BOS_2018-01-0...|2018-01-01|    1|   1|     DL|ATL|BOS|        11|      1122|     8.0|      1349|     0.0|         147.0|946.0|    0.0|  ATL_BOS|\n|ATL_BOS_2018-01-0...|2018-01-01|    1|   1|     DL|ATL|BOS|        14|      1356|     9.0|      1623|     0.0|         147.0|946.0|    0.0|  ATL_BOS|\n|ATL_BOS_2018-01-0...|2018-01-01|    1|   1|     DL|ATL|BOS|        16|      1620|     0.0|      1851|     3.0|         151.0|946.0|    0.0|  ATL_BOS|\n|ATL_BOS_2018-01-0...|2018-01-01|    1|   1|     DL|ATL|BOS|        19|      1940|     6.0|      2210|     0.0|         150.0|946.0|    0.0|  ATL_BOS|\n|ATL_BOS_2018-01-0...|2018-01-01|    1|   1|     DL|ATL|BOS|        12|      1248|     0.0|      1513|     0.0|         145.0|946.0|    0.0|  ATL_BOS|\n|ATL_BOS_2018-01-0...|2018-01-01|    1|   1|     DL|ATL|BOS|        22|      2215|     0.0|        39|     0.0|         144.0|946.0|    0.0|  ATL_BOS|\n|ATL_BOS_2018-01-0...|2018-01-01|    1|   1|     DL|ATL|BOS|        15|      1500|    21.0|      1734|    33.0|         154.0|946.0|    0.0|  ATL_BOS|\n|ATL_BOS_2018-01-0...|2018-01-01|    1|   1|     WN|ATL|BOS|        15|      1500|   198.0|      1725|   208.0|         145.0|946.0|    1.0|  ATL_BOS|\n|ATL_BOS_2018-01-0...|2018-01-01|    1|   1|     WN|ATL|BOS|        21|      2055|    14.0|      2330|     0.0|         155.0|946.0|    0.0|  ATL_BOS|\n|ATL_BOS_2018-01-0...|2018-01-01|    1|   1|     WN|ATL|BOS|        10|      1015|   215.0|      1250|   191.0|         155.0|946.0|    1.0|  ATL_BOS|\n|ATL_CLT_2018-01-0...|2018-01-01|    1|   1|     AA|ATL|CLT|        11|      1114|     0.0|      1238|     0.0|          84.0|226.0|    0.0|  ATL_CLT|\n|ATL_CLT_2018-01-0...|2018-01-01|    1|   1|     AA|ATL|CLT|         8|       845|     0.0|      1011|     0.0|          86.0|226.0|    0.0|  ATL_CLT|\n|ATL_CLT_2018-01-0...|2018-01-01|    1|   1|     AA|ATL|CLT|        15|      1548|     0.0|      1710|     0.0|          82.0|226.0|    0.0|  ATL_CLT|\n|ATL_CLT_2018-01-0...|2018-01-01|    1|   1|     AA|ATL|CLT|         7|       705|     0.0|       821|     0.0|          76.0|226.0|    0.0|  ATL_CLT|\n|ATL_CLT_2018-01-0...|2018-01-01|    1|   1|     AA|ATL|CLT|        12|      1226|     0.0|      1347|     0.0|          81.0|226.0|    0.0|  ATL_CLT|\n|ATL_CLT_2018-01-0...|2018-01-01|    1|   1|     AA|ATL|CLT|        22|      2205|     0.0|      2319|     1.0|          74.0|226.0|    0.0|  ATL_CLT|\n|ATL_CLT_2018-01-0...|2018-01-01|    1|   1|     DL|ATL|CLT|        22|      2210|    11.0|      2324|     0.0|          74.0|226.0|    0.0|  ATL_CLT|\n|ATL_CLT_2018-01-0...|2018-01-01|    1|   1|     DL|ATL|CLT|        15|      1543|     1.0|      1659|     0.0|          76.0|226.0|    0.0|  ATL_CLT|\n|ATL_CLT_2018-01-0...|2018-01-01|    1|   1|     DL|ATL|CLT|        10|      1008|     0.0|      1124|     0.0|          76.0|226.0|    0.0|  ATL_CLT|\n+--------------------+----------+-----+----+-------+---+---+----------+----------+--------+----------+--------+--------------+-----+-------+---------+\nonly showing top 20 rows\n\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://mapr-resman:8088/proxy/application_1551978809362_0003//jobs"],"interpreterSettingId":"spark"}},"apps":[],"jobName":"paragraph_1552060947902_1482335676","id":"20171129-221736_959969733","dateCreated":"2019-03-08T16:02:27+0000","dateStarted":"2019-03-08T19:40:50+0000","dateFinished":"2019-03-08T19:40:52+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:1001"},{"title":"What are the Top Orig->Dest route Delays?","text":"%sql\nselect orig_dest, delayed, count(delayed)\nfrom flights where delayed=1\ngroup by orig_dest, delayed\nORDER BY count(delayed) desc limit 30","user":"mapr","dateUpdated":"2019-03-08T20:23:37+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{"0":{"graph":{"mode":"multiBarChart","height":300,"optionOpen":false,"setting":{"table":{"tableGridState":{},"tableColumnTypeState":{"names":{"orig_dest":"string","delayed":"string","count(delayed)":"string"},"updated":false},"tableOptionSpecHash":"[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]","tableOptionValue":{"useFilter":false,"showPagination":false,"showAggregationFooter":false},"updated":false,"initialized":false},"multiBarChart":{"rotate":{"degree":"-45"},"xLabelStatus":"default"}},"commonSetting":{},"keys":[{"name":"orig_dest","index":0,"aggr":"sum"}],"groups":[],"values":[{"name":"count(delayed)","index":2,"aggr":"sum"}]},"helium":{}}},"editorSetting":{"language":"sql","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/sql","title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TABLE","data":"orig_dest\tdelayed\tcount(delayed)\nORD_LGA\t1.0\t588\nLAX_SFO\t1.0\t578\nATL_EWR\t1.0\t561\nLGA_ORD\t1.0\t532\nORD_SFO\t1.0\t470\nSFO_LAX\t1.0\t463\nATL_LGA\t1.0\t445\nORD_LAX\t1.0\t425\nORD_DFW\t1.0\t423\nDEN_SFO\t1.0\t388\nEWR_ATL\t1.0\t381\nDFW_ORD\t1.0\t377\nMIA_LGA\t1.0\t355\nORD_EWR\t1.0\t347\nLGA_ATL\t1.0\t344\nSFO_ORD\t1.0\t343\nDFW_ATL\t1.0\t328\nORD_ATL\t1.0\t326\nORD_BOS\t1.0\t318\nDEN_LAX\t1.0\t311\nLAX_DEN\t1.0\t303\nORD_DEN\t1.0\t302\nSFO_DEN\t1.0\t299\nMIA_ATL\t1.0\t299\nLAX_ORD\t1.0\t298\nEWR_ORD\t1.0\t297\nATL_DFW\t1.0\t293\nBOS_LGA\t1.0\t279\nLGA_BOS\t1.0\t276\nDEN_EWR\t1.0\t275\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://mapr-resman:8088/proxy/application_1551978809362_0003//jobs"],"interpreterSettingId":"spark"}},"apps":[],"jobName":"paragraph_1552073980474_748207073","id":"20190308-193940_877832928","dateCreated":"2019-03-08T19:39:40+0000","dateStarted":"2019-03-08T19:43:25+0000","dateFinished":"2019-03-08T19:43:27+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:1002"},{"text":"%md \nThis is the end of this notebook. You can modify or add some Spark Dataframe transformations or SQL (sql must be preceded by %sql) of you own. \nWhen you are finished please run the command below to unpersist the cached DataFrames, then click on the Zeppelin Icon at the top of this page \nto go to the list of notebooks. Then select the notebook FlightDelay2MachineLearning.","user":"mapr","dateUpdated":"2019-03-08T20:03:58+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>This is the end of this notebook. You can modify or add some Spark Dataframe transformations or SQL (sql must be preceded by %sql) of you own.<br/>When you are finished please run the command below to unpersist the cached DataFrames, then click on the Zeppelin Icon at the top of this page<br/>to go to the list of notebooks. Then select the notebook FlightDelay2MachineLearning.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1552060947959_-1269548202","id":"20181004-211413_1357524146","dateCreated":"2019-03-08T16:02:27+0000","dateStarted":"2019-03-08T20:03:58+0000","dateFinished":"2019-03-08T20:03:58+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:1003"},{"text":"df.unpersist\ndf1.unpersist\ndf2.unpersist\n","user":"mapr","dateUpdated":"2019-03-08T20:04:26+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"res24: df.type = [id: string, fldate: string ... 12 more fields]\nres25: df1.type = [id: string, fldate: string ... 13 more fields]\nres26: df2.type = [id: string, fldate: string ... 14 more fields]\n"}]},"apps":[],"jobName":"paragraph_1552075390120_1649477112","id":"20190308-200310_562574174","dateCreated":"2019-03-08T20:03:10+0000","dateStarted":"2019-03-08T20:04:26+0000","dateFinished":"2019-03-08T20:04:28+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:1004"},{"text":"\n","user":"mapr","dateUpdated":"2019-03-08T20:03:05+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1552075372448_-1842788843","id":"20190308-200252_1958361495","dateCreated":"2019-03-08T20:02:52+0000","status":"READY","progressUpdateIntervalMs":500,"$$hashKey":"object:1005"},{"user":"mapr","dateUpdated":"2019-03-08T16:02:27+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1552060947962_-816139212","id":"20171122-091021_1615582434","dateCreated":"2019-03-08T16:02:27+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:1006"}],"name":"FlightDelaySparkDatasets","id":"2E689NKHY","noteParams":{},"noteForms":{},"angularObjects":{"md:shared_process":[],"spark:shared_process":[]},"config":{"isZeppelinNotebookCronEnable":false,"looknfeel":"default","personalizedMode":"false"},"info":{}}