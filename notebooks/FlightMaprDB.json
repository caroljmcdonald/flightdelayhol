{"paragraphs":[{"text":"%md\n# Prediction Flight Delays with Spark ML\nThis notebook demonstrates how to use Apache Spark’s ML pipelines with a Random Forest Classifier to predict flight delays. For more information, see [this](https://mapr.com/ebook/getting-started-with-apache-spark-v2/)  MapR Spark ebook.\n<img src=\"https://mapr.com/blog/fast-data-processing-pipeline-predicting-flight-delays-using-apache-apis-pt-1/assets/spark-rdd-based-api.png\">","user":"anonymous","dateUpdated":"2019-03-06T00:38:27+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Prediction Flight Delays with Spark ML</h1>\n<p>This notebook demonstrates how to use Apache Spark’s ML pipelines with a Random Forest Classifier to predict flight delays. For more information, see <a href=\"https://mapr.com/ebook/getting-started-with-apache-spark-v2/\">this</a> MapR Spark ebook.<br/><img src=\"https://mapr.com/blog/fast-data-processing-pipeline-predicting-flight-delays-using-apache-apis-pt-1/assets/spark-rdd-based-api.png\"></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1551832707621_1391657950","id":"20190220-173254_1728425170","dateCreated":"2019-03-06T00:38:27+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:7317"},{"text":"%md \n## Data Exploration\nFor this tutorial, we'll be using data from http://www.transtats.bts.gov/DL_SelectFields.asp?Table_ID=236&DB_Short_Name=On-Time.\nThe CSV data has been cleaned and tranformed into a JSON file with the following format: \n{\n    \"id\": \"ATL_BOS_2018-01-01_DL_104\",\n    \"fldate\": \"2018-01-01\",\n    \"month\": 1,\n    \"dofW\": 1,\n    \"carrier\": \"DL\",\n    \"src\": \"ATL\",\n    \"dst\": \"BOS\",\n    \"crsdephour\": 9,\n    \"crsdeptime\": 850,\n    \"depdelay\": 0.0,\n    \"crsarrtime\": 1116,\n    \"arrdelay\": 0.0,\n    \"crselapsedtime\": 146.0,\n    \"dist\": 946.0\n}\n\nWe use a Scala case class and Structype to define the schema, corresponding to a line in the JSON data file.","user":"anonymous","dateUpdated":"2019-03-06T00:38:27+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>Data Exploration</h2>\n<p>For this tutorial, we&rsquo;ll be using data from <a href=\"http://www.transtats.bts.gov/DL_SelectFields.asp?Table_ID=236&DB_Short_Name=On-Time\">http://www.transtats.bts.gov/DL_SelectFields.asp?Table_ID=236&DB_Short_Name=On-Time</a>.<br/>The CSV data has been cleaned and tranformed into a JSON file with the following format:<br/>{<br/> &ldquo;id&rdquo;: &ldquo;ATL_BOS_2018-01-01_DL_104&rdquo;,<br/> &ldquo;fldate&rdquo;: &ldquo;2018-01-01&rdquo;,<br/> &ldquo;month&rdquo;: 1,<br/> &ldquo;dofW&rdquo;: 1,<br/> &ldquo;carrier&rdquo;: &ldquo;DL&rdquo;,<br/> &ldquo;src&rdquo;: &ldquo;ATL&rdquo;,<br/> &ldquo;dst&rdquo;: &ldquo;BOS&rdquo;,<br/> &ldquo;crsdephour&rdquo;: 9,<br/> &ldquo;crsdeptime&rdquo;: 850,<br/> &ldquo;depdelay&rdquo;: 0.0,<br/> &ldquo;crsarrtime&rdquo;: 1116,<br/> &ldquo;arrdelay&rdquo;: 0.0,<br/> &ldquo;crselapsedtime&rdquo;: 146.0,<br/> &ldquo;dist&rdquo;: 946.0<br/>}</p>\n<p>We use a Scala case class and Structype to define the schema, corresponding to a line in the JSON data file.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1551832707621_-1172266477","id":"20170530-122945_1594214131","dateCreated":"2019-03-06T00:38:27+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:7318"},{"title":"Import needed packages","text":"%spark\nimport org.apache.spark.sql.functions._\nimport org.apache.spark.sql.types._\nimport org.apache.spark.sql._\nimport com.mapr.db._\nimport com.mapr.db.spark._\nimport com.mapr.db.spark.impl._\nimport com.mapr.db.spark.sql._\n","user":"anonymous","dateUpdated":"2019-03-06T00:39:10+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import org.apache.spark.sql.SparkSession\nimport org.apache.spark.sql.types._\nimport org.apache.spark.sql.functions._\nimport org.apache.spark.sql._\nimport org.apache.spark.streaming._\nimport org.apache.spark.ml._\nimport org.apache.spark.ml.feature._\nimport org.apache.spark.ml.classification._\nimport org.apache.spark.ml.evaluation._\nimport org.apache.spark.ml.tuning._\n"}]},"apps":[],"jobName":"paragraph_1551832707622_314214295","id":"20170508-144514_403247535","dateCreated":"2019-03-06T00:38:27+0000","status":"PENDING","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:7319"},{"title":"Define Schema for JSON file data","text":"%spark\nimport org.apache.spark.sql.types._\n\ncase class Flight(id: String,fldate: String,month:Integer, dofW: Integer, carrier: String, src: String,dst: String,orig_dest: String, crsdephour: Integer, crsdeptime: Integer, depdelay: Double, crsarrtime: Integer, arrdelay: Double, crselapsedtime: Double, dist: Double)\n  \n  val schema = StructType(Array(\n    StructField(\"id\", StringType, true),\n    StructField(\"fldate\", StringType, true),\n    StructField(\"month\", IntegerType, true),\n    StructField(\"dofW\", IntegerType, true),\n    StructField(\"carrier\", StringType, true),\n    StructField(\"src\", StringType, true),\n    StructField(\"dst\", StringType, true),\n     StructField(\"orig_dest\", StringType, true),\n    StructField(\"crsdephour\", IntegerType, true),\n    StructField(\"crsdeptime\", IntegerType, true),\n    StructField(\"depdelay\", DoubleType, true),\n    StructField(\"crsarrtime\", IntegerType, true),\n    StructField(\"arrdelay\", DoubleType, true),\n    StructField(\"crselapsedtime\", DoubleType, true),\n    StructField(\"dist\", DoubleType, true)\n  ))\n   ","user":"anonymous","dateUpdated":"2019-03-06T00:40:35+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import org.apache.spark.sql.types._\ndefined class Flight\nschema: org.apache.spark.sql.types.StructType = StructType(StructField(id,StringType,true), StructField(fldate,StringType,true), StructField(month,IntegerType,true), StructField(dofW,IntegerType,true), StructField(carrier,StringType,true), StructField(src,StringType,true), StructField(dst,StringType,true), StructField(crsdephour,IntegerType,true), StructField(crsdeptime,IntegerType,true), StructField(depdelay,DoubleType,true), StructField(crsarrtime,IntegerType,true), StructField(arrdelay,DoubleType,true), StructField(crselapsedtime,DoubleType,true), StructField(dist,DoubleType,true))\n"}]},"apps":[],"jobName":"paragraph_1551832707622_600553880","id":"20170508-150032_326029627","dateCreated":"2019-03-06T00:38:27+0000","status":"PENDING","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:7320"},{"title":"Read the data from JSON file into a Dataset of type Flight","text":"var topic: String = \"/user/mapr/stream:flights\"\nvar tableName: String = \"/user/mapr/flighttable\"\nvar modeldirectory: String = \"/mapr/demo.mapr.com/model\"\n","user":"anonymous","dateUpdated":"2019-03-06T00:41:08+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"topic: String = /user/mapr/stream:flights\ntableName: String = /user/mapr/flighttable\nmodeldirectory: String = /mapr/demo.mapr.com/model\n"}]},"apps":[],"jobName":"paragraph_1551832707622_-1436885478","id":"20170508-150131_378637203","dateCreated":"2019-03-06T00:38:27+0000","status":"PENDING","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:7321"},{"title":"Add origin_dest column  and display the first 20 rows","text":" import com.mapr.db.spark._\n val spark: SparkSession = SparkSession.builder().appName(\"flightread\").getOrCreate()\n \n // load payment dataset from MapR-DB \nval df = spark.sparkSession.loadFromMapRDB[Flight](tableName, schema)\n\n df.take(1)\n\n\n\n","user":"anonymous","dateUpdated":"2019-03-06T00:41:30+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"ERROR","msg":[{"type":"TEXT","data":"org.apache.hadoop.mapred.InvalidInputException: Input path does not exist: maprfs:/mapr/demo.mapr.com/model/metadata\n  at org.apache.hadoop.mapred.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:289)\n  at org.apache.hadoop.mapred.FileInputFormat.listStatus(FileInputFormat.java:229)\n  at org.apache.hadoop.mapred.FileInputFormat.getSplits(FileInputFormat.java:317)\n  at org.apache.spark.rdd.HadoopRDD.getPartitions(HadoopRDD.scala:204)\n  at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:253)\n  at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:251)\n  at scala.Option.getOrElse(Option.scala:121)\n  at org.apache.spark.rdd.RDD.partitions(RDD.scala:251)\n  at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)\n  at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:253)\n  at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:251)\n  at scala.Option.getOrElse(Option.scala:121)\n  at org.apache.spark.rdd.RDD.partitions(RDD.scala:251)\n  at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1337)\n  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n  at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\n  at org.apache.spark.rdd.RDD.take(RDD.scala:1331)\n  at org.apache.spark.rdd.RDD$$anonfun$first$1.apply(RDD.scala:1372)\n  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n  at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\n  at org.apache.spark.rdd.RDD.first(RDD.scala:1371)\n  at org.apache.spark.ml.util.DefaultParamsReader$.loadMetadata(ReadWrite.scala:387)\n  at org.apache.spark.ml.tree.EnsembleModelReadWrite$.loadImpl(treeModels.scala:427)\n  at org.apache.spark.ml.classification.RandomForestClassificationModel$RandomForestClassificationModelReader.load(RandomForestClassifier.scala:313)\n  at org.apache.spark.ml.classification.RandomForestClassificationModel$RandomForestClassificationModelReader.load(RandomForestClassifier.scala:303)\n  at org.apache.spark.ml.util.MLReadable$class.load(ReadWrite.scala:223)\n  at org.apache.spark.ml.classification.RandomForestClassificationModel$.load(RandomForestClassifier.scala:287)\n  ... 67 elided\n"}]},"apps":[],"jobName":"paragraph_1551832707622_294838622","id":"20171129-221736_959969733","dateCreated":"2019-03-06T00:38:27+0000","status":"PENDING","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:7322"},{"text":"val df1 = spark.readStream.format(\"kafka\")\n      .option(\"kafka.bootstrap.servers\", \"maprdemo:9092\")\n      .option(\"subscribe\", topic)\n      .option(\"group.id\", \"testgroup\")\n      .option(\"startingOffsets\", \"earliest\")\n      .option(\"failOnDataLoss\", false)\n      .option(\"maxOffsetsPerTrigger\", 1000)\n      .load()","user":"anonymous","dateUpdated":"2019-03-06T00:38:27+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"df1: org.apache.spark.sql.DataFrame = [key: binary, value: binary ... 5 more fields]\n"}]},"apps":[],"jobName":"paragraph_1551832707623_-386507479","id":"20190306-002931_1225657206","dateCreated":"2019-03-06T00:38:27+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:7323"},{"title":"Print DataFrame Schema","text":"df1.printSchema","user":"anonymous","dateUpdated":"2019-03-06T00:38:27+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"root\n |-- key: binary (nullable = true)\n |-- value: binary (nullable = true)\n |-- topic: string (nullable = true)\n |-- partition: integer (nullable = true)\n |-- offset: long (nullable = true)\n |-- timestamp: timestamp (nullable = true)\n |-- timestampType: integer (nullable = true)\n\n"}]},"apps":[],"jobName":"paragraph_1551832707623_-1642317751","id":"20171129-223643_463511351","dateCreated":"2019-03-06T00:38:27+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:7324"},{"text":"val df2 = df1.select($\"value\" cast \"string\" as \"json\").select(from_json($\"json\", schema) as \"data\").select(\"data.*\")","user":"anonymous","dateUpdated":"2019-03-06T00:38:27+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"df2: org.apache.spark.sql.DataFrame = [id: string, fldate: string ... 12 more fields]\n"}]},"apps":[],"jobName":"paragraph_1551832707624_-1555413527","id":"20190306-003118_1790885997","dateCreated":"2019-03-06T00:38:27+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:7325"},{"text":"import com.mapr.db.spark.impl._\nimport com.mapr.db.spark.streaming._\nimport com.mapr.db.spark.sql._\nimport com.mapr.db.spark.streaming.MapRDBSourceConfig\nval query3 = df2.writeStream\n      .format(MapRDBSourceConfig.Format)\n      .option(MapRDBSourceConfig.TablePathOption, tableName)\n      .option(MapRDBSourceConfig.IdFieldPathOption, \"id\")\n      .option(MapRDBSourceConfig.CreateTableOption, false)\n      .option(\"checkpointLocation\", \"/tmp/uberdb\")\n      .option(MapRDBSourceConfig.BulkModeOption, true)\n      .option(MapRDBSourceConfig.SampleSizeOption, 1000).start()\n\nquery3.awaitTermination()","user":"anonymous","dateUpdated":"2019-03-06T00:38:27+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1551832707624_360922858","id":"20190306-003127_1670791655","dateCreated":"2019-03-06T00:38:27+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:7326"},{"text":"query3.stop()","user":"anonymous","dateUpdated":"2019-03-06T00:38:27+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1551832707624_-1628497909","id":"20190306-003457_1891238408","dateCreated":"2019-03-06T00:38:27+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:7327"},{"text":"%md\nThe describe() function performs summary statistics calculations on  numeric columns ","user":"anonymous","dateUpdated":"2019-03-06T00:38:27+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>The describe() function performs summary statistics calculations on numeric columns</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1551832707624_1275574773","id":"20170524-214640_973339640","dateCreated":"2019-03-06T00:38:27+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:7328"},{"title":"Perform summary statistics  on selected columns","text":"\ndf1.describe(\"dist\", \"crselapsedtime\",\"depdelay\", \"arrdelay\").show","user":"anonymous","dateUpdated":"2019-03-06T00:38:27+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+-------+------------------+------------------+------------------+------------------+\n|summary|              dist|    crselapsedtime|          depdelay|          arrdelay|\n+-------+------------------+------------------+------------------+------------------+\n|  count|            282628|            282628|            282628|            282628|\n|   mean|1154.9526267744172|189.82255119804125|14.468792900915691|14.565644592892424|\n| stddev| 629.5585331710324| 75.74564106190776| 43.72836248563875|  43.4753984380938|\n|    min|             184.0|              61.0|               0.0|               0.0|\n|    max|            2724.0|             433.0|            1559.0|            1576.0|\n+-------+------------------+------------------+------------------+------------------+\n\n"}]},"apps":[],"jobName":"paragraph_1551832707625_-1911002474","id":"20170524-083228_1459810795","dateCreated":"2019-03-06T00:38:27+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:7329"},{"text":"%md\nIn the code below a Spark Bucketizer is used to split the dataset into delayed and not delayed flights with a \ndelayed 0/1 column. Then the resulting total counts are displayed. ","user":"anonymous","dateUpdated":"2019-03-06T00:38:27+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>In the code below a Spark Bucketizer is used to split the dataset into delayed and not delayed flights with a<br/>delayed 0/1 column. Then the resulting total counts are displayed.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1551832707625_612750635","id":"20190305-221927_113621865","dateCreated":"2019-03-06T00:38:27+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:7330"},{"title":"Add Column for Delayed Flights and count","text":"// bucket > 40 minutes = delayed\nval delaybucketizer = new Bucketizer().setInputCol(\"depdelay\").setOutputCol(\"delayed\").setSplits(Array(0.0,41.0,Double.PositiveInfinity))\nval df2= delaybucketizer.transform(df1)\ndf2.cache\ndf2.groupBy(\"delayed\").count.show","user":"anonymous","dateUpdated":"2019-03-06T00:38:27+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+-------+------+\n|delayed| count|\n+-------+------+\n|    0.0|253309|\n|    1.0| 29319|\n+-------+------+\n\ndelaybucketizer: org.apache.spark.ml.feature.Bucketizer = bucketizer_e9d5e993ce5a\ndf2: org.apache.spark.sql.DataFrame = [id: string, fldate: string ... 14 more fields]\n"}]},"apps":[],"jobName":"paragraph_1551832707625_1901904167","id":"20170524-093402_1430077788","dateCreated":"2019-03-06T00:38:27+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:7331"},{"title":"Register Dataset as a Temporary View in order to explore with SQL","text":"df2.createOrReplaceTempView(\"flights\")\nspark.catalog.cacheTable(\"flights\")","user":"anonymous","dateUpdated":"2019-03-06T00:38:27+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"title":true,"results":{"0":{"graph":{"mode":"table","height":300,"optionOpen":true,"setting":{"stackedAreaChart":{}},"commonSetting":{},"keys":[{"name":"churn","index":19,"aggr":"sum"}],"groups":[],"values":[{"name":"len","index":1,"aggr":"sum"}]},"helium":{}}},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1551832707625_-1522885691","id":"20170508-150408_505244914","dateCreated":"2019-03-06T00:38:27+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:7332"},{"text":"%md \n# Use Spark SQL to explore the dataset","user":"anonymous","dateUpdated":"2019-03-06T00:38:27+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Use Spark SQL to explore the dataset</h1>\n</div>"}]},"apps":[],"jobName":"paragraph_1551832707626_-1906917134","id":"20170603-182655_1680505289","dateCreated":"2019-03-06T00:38:27+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:7333"},{"title":"Top 5 Longest departure delays","text":"%sql \nselect carrier,src, dst, depdelay,crsdephour, dist, dofW\nfrom flights \norder by depdelay desc limit 5 \n","user":"anonymous","dateUpdated":"2019-03-06T00:38:27+0000","config":{"tableHide":false,"editorSetting":{"language":"sql","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/sql","editorHide":false,"fontSize":9,"title":true,"results":{"0":{"graph":{"mode":"table","height":300,"optionOpen":false,"setting":{"table":{"tableGridState":{},"tableColumnTypeState":{"names":{"carrier":"string","src":"string","dst":"string","depdelay":"string","crsdephour":"string","dist":"string","dofW":"string"},"updated":false},"tableOptionSpecHash":"[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]","tableOptionValue":{"useFilter":false,"showPagination":false,"showAggregationFooter":false},"updated":false,"initialized":false}},"commonSetting":{}}}},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TABLE","data":"carrier\tsrc\tdst\tdepdelay\tcrsdephour\tdist\tdofW\nAA\tIAH\tMIA\t1559.0\t11\t964.0\t5\nAA\tIAH\tDFW\t1445.0\t18\t224.0\t3\nAA\tBOS\tDFW\t1345.0\t10\t1562.0\t4\nUA\tBOS\tORD\t1334.0\t9\t867.0\t4\nAA\tLAX\tMIA\t1283.0\t9\t2342.0\t1\n"},{"type":"TEXT","data":""}]},"apps":[],"jobName":"paragraph_1551832707626_-1990392750","id":"20171110-195321_1924356975","dateCreated":"2019-03-06T00:38:27+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:7334"},{"title":"Average Departure Delay by Carrier","text":"%sql select carrier, avg(depdelay)\nfrom flights\ngroup by carrier","user":"anonymous","dateUpdated":"2019-03-06T00:38:35+0000","config":{"editorSetting":{"language":"sql","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/sql","fontSize":9,"editorHide":false,"title":true,"results":{"0":{"graph":{"mode":"multiBarChart","height":300,"optionOpen":false,"setting":{"multiBarChart":{"rotate":{"degree":"-45"},"xLabelStatus":"default"}},"commonSetting":{},"keys":[{"name":"carrier","index":0,"aggr":"sum"}],"groups":[],"values":[{"name":"avg(depdelay)","index":1,"aggr":"sum"}]},"helium":{}}},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TABLE","data":"carrier\tavg(depdelay)\nUA\t14.442583200307139\nAA\t14.129090626627798\nDL\t14.26168914855228\nWN\t17.70183428999251\n"},{"type":"TEXT","data":""}]},"apps":[],"jobName":"paragraph_1551832707626_-46131374","id":"20171110-195759_439800395","dateCreated":"2019-03-06T00:38:27+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:7335"},{"title":"Average Departure Delay by Destination Airport","text":"%sql\nSELECT dst, avg(depdelay) as avgdelay\nFROM flights \nGROUP BY dst\nORDER BY avgdelay desc","user":"anonymous","dateUpdated":"2019-03-06T00:38:35+0000","config":{"editorSetting":{"language":"sql","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/sql","fontSize":9,"editorHide":false,"title":true,"results":{"0":{"graph":{"mode":"multiBarChart","height":300,"optionOpen":false,"setting":{"multiBarChart":{"rotate":{"degree":"-45"},"xLabelStatus":"default"},"table":{"tableGridState":{},"tableColumnTypeState":{"names":{"dst":"string","avgdelay":"string"},"updated":false},"tableOptionSpecHash":"[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]","tableOptionValue":{"useFilter":false,"showPagination":false,"showAggregationFooter":false},"updated":false,"initialized":false}},"commonSetting":{},"keys":[{"name":"dst","index":0,"aggr":"sum"}],"groups":[],"values":[{"name":"avgdelay","index":1,"aggr":"sum"}]},"helium":{}}},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TABLE","data":"dst\tavgdelay\nEWR\t20.729607250755286\nSFO\t17.047248322147652\nLGA\t15.613878829401978\nBOS\t15.00700909577314\nORD\t14.846011016896702\nMIA\t14.371604732544576\nDFW\t13.946526636469315\nATL\t13.797100969652844\nLAX\t13.445941419479698\nSEA\t13.097595473833097\nDEN\t12.767347642444618\nIAH\t11.743971267316573\nCLT\t11.370676826001548\n"},{"type":"TEXT","data":""}]},"apps":[],"jobName":"paragraph_1551832707627_2043535097","id":"20171122-204956_303346727","dateCreated":"2019-03-06T00:38:27+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:7336"},{"title":"Average Departure Delay by Originating Airport","text":"%sql\nSELECT src, avg(depdelay) as avgdelay\nFROM flights \nGROUP BY src\nORDER BY avgdelay desc","user":"anonymous","dateUpdated":"2019-03-06T00:38:35+0000","config":{"editorSetting":{"language":"sql","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/sql","fontSize":9,"editorHide":false,"title":true,"results":{"0":{"graph":{"mode":"multiBarChart","height":300,"optionOpen":false,"setting":{"multiBarChart":{"rotate":{"degree":"-45"},"xLabelStatus":"default"}},"commonSetting":{},"keys":[{"name":"src","index":0,"aggr":"sum"}],"groups":[],"values":[{"name":"avgdelay","index":1,"aggr":"sum"}]},"helium":{}}},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TABLE","data":"src\tavgdelay\nEWR\t17.818079459546404\nMIA\t17.768691978431264\nORD\t16.5199551010227\nATL\t15.330084535057185\nDFW\t15.061909338459074\nDEN\t14.192011960700555\nCLT\t14.081517835767297\nIAH\t13.804911168948738\nSFO\t13.792674746209919\nLGA\t13.586563812127721\nBOS\t12.940644675240812\nLAX\t11.223347230494342\nSEA\t10.140899425061038\n"},{"type":"TEXT","data":""}]},"apps":[],"jobName":"paragraph_1551832707627_1951928909","id":"20171122-204822_1853914961","dateCreated":"2019-03-06T00:38:27+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:7337"},{"title":"Count of Departure Delays by Day of the Week (1=Monday, 7=Sunday)","text":"%sql\nselect dofW, count(depdelay)\nfrom flights where depdelay > 40\ngroup by dofW\n","user":"anonymous","dateUpdated":"2019-03-06T00:38:35+0000","config":{"editorSetting":{"language":"sql","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/sql","fontSize":9,"editorHide":false,"title":true,"results":{"0":{"graph":{"mode":"multiBarChart","height":300,"optionOpen":false,"setting":{"multiBarChart":{"rotate":{"degree":"-45"},"xLabelStatus":"default"}},"commonSetting":{},"keys":[{"name":"dofW","index":0,"aggr":"sum"}],"groups":[],"values":[{"name":"count(depdelay)","index":1,"aggr":"sum"}]},"helium":{}}},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TABLE","data":"dofW\tcount(depdelay)\n1\t4680\n6\t2598\n3\t3986\n5\t4677\n4\t4809\n7\t4163\n2\t4406\n"},{"type":"TEXT","data":""}]},"apps":[],"jobName":"paragraph_1551832707627_-233361914","id":"20171123-101016_2040441762","dateCreated":"2019-03-06T00:38:27+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:7338"},{"title":"Count of Departure Delays by Carrier (where delay=40 minutes)","text":"%sql\nselect carrier, count(delayed)\nfrom flights where delayed = 1\ngroup by carrier\norder by carrier","user":"anonymous","dateUpdated":"2019-03-06T00:38:36+0000","config":{"editorSetting":{"language":"sql","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/sql","fontSize":9,"editorHide":false,"title":true,"results":{"0":{"graph":{"mode":"multiBarChart","height":300,"optionOpen":false,"setting":{"multiBarChart":{"rotate":{"degree":"-45"},"xLabelStatus":"default"}},"commonSetting":{},"keys":[{"name":"carrier","index":0,"aggr":"sum"}],"groups":[],"values":[{"name":"count(delayed)","index":1,"aggr":"sum"}]},"helium":{}}},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TABLE","data":"carrier\tcount(delayed)\nAA\t11570\nDL\t5354\nUA\t10297\nWN\t2098\n"},{"type":"TEXT","data":""}]},"apps":[],"jobName":"paragraph_1551832707628_-492629829","id":"20171123-042011_1532799341","dateCreated":"2019-03-06T00:38:27+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:7339"},{"title":"Count of Delayed Not Delayed  by Carrier","text":"%sql\nSELECT delayed, count(delayed),carrier\nFROM flights\nGROUP BY carrier, delayed\norder by carrier\n","user":"anonymous","dateUpdated":"2019-03-06T00:38:36+0000","config":{"editorSetting":{"language":"sql","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/sql","fontSize":9,"editorHide":false,"title":true,"results":{"0":{"graph":{"mode":"multiBarChart","height":300,"optionOpen":false,"setting":{"multiBarChart":{"stacked":false,"rotate":{"degree":"-45"},"xLabelStatus":"default"}},"commonSetting":{},"keys":[{"name":"carrier","index":2,"aggr":"sum"}],"groups":[{"name":"delayed","index":0,"aggr":"sum"}],"values":[{"name":"count(delayed)","index":1,"aggr":"sum"}]},"helium":{}}},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TABLE","data":"delayed\tcount(delayed)\tcarrier\n1.0\t11570\tAA\n0.0\t97857\tAA\n0.0\t52841\tDL\n1.0\t5354\tDL\n0.0\t88681\tUA\n1.0\t10297\tUA\n1.0\t2098\tWN\n0.0\t13930\tWN\n"},{"type":"TEXT","data":""}]},"apps":[],"jobName":"paragraph_1551832707628_1675474436","id":"20170524-144751_554129160","dateCreated":"2019-03-06T00:38:27+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:7340"},{"title":"Count of Departure Delays by Hour of Day","text":"%sql\nselect crsdephour, count(depdelay)\nfrom flights where depdelay > 40\ngroup by crsdephour\n","user":"anonymous","dateUpdated":"2019-03-06T00:38:36+0000","config":{"editorSetting":{"language":"sql","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/sql","fontSize":9,"editorHide":false,"title":true,"results":{"0":{"graph":{"mode":"multiBarChart","height":300,"optionOpen":false,"setting":{"multiBarChart":{"rotate":{"degree":"-45"},"xLabelStatus":"default"}},"commonSetting":{},"keys":[{"name":"crsdephour","index":0,"aggr":"sum"}],"groups":[],"values":[{"name":"count(depdelay)","index":1,"aggr":"sum"}]},"helium":{}}},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TABLE","data":"crsdephour\tcount(depdelay)\n12\t1893\n22\t1066\n1\t51\n13\t1728\n6\t518\n16\t2309\n20\t2260\n5\t175\n19\t2198\n15\t1969\n17\t2434\n9\t1112\n8\t1067\n23\t364\n7\t1068\n10\t1472\n24\t58\n21\t1180\n11\t1321\n14\t2041\n0\t106\n18\t2929\n"},{"type":"TEXT","data":""}]},"apps":[],"jobName":"paragraph_1551832707628_-74779242","id":"20171129-200107_756396508","dateCreated":"2019-03-06T00:38:27+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:7341"},{"title":"Count of Delayed , Not Delayed by Hour","text":"%sql\nSELECT delayed, count(delayed),crsdephour\nFROM flights\nGROUP BY crsdephour, delayed\norder by delayed","user":"anonymous","dateUpdated":"2019-03-06T00:38:36+0000","config":{"editorSetting":{"language":"sql","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/sql","fontSize":9,"editorHide":false,"title":true,"results":{"0":{"graph":{"mode":"multiBarChart","height":300,"optionOpen":false,"setting":{"multiBarChart":{"stacked":false,"rotate":{"degree":"-45"},"xLabelStatus":"default"}},"commonSetting":{},"keys":[{"name":"crsdephour","index":2,"aggr":"sum"}],"groups":[{"name":"delayed","index":0,"aggr":"sum"}],"values":[{"name":"count(delayed)","index":1,"aggr":"sum"}]},"helium":{}}},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TABLE","data":"delayed\tcount(delayed)\tcrsdephour\n0.0\t22365\t7\n0.0\t1499\t0\n0.0\t7242\t22\n0.0\t10675\t20\n0.0\t1217\t1\n0.0\t14966\t18\n0.0\t17327\t10\n0.0\t6511\t21\n0.0\t16790\t12\n0.0\t17001\t8\n0.0\t1017\t24\n0.0\t16660\t6\n0.0\t14946\t9\n0.0\t18\t2\n0.0\t14940\t11\n0.0\t2705\t23\n0.0\t13895\t13\n0.0\t15123\t14\n0.0\t14661\t16\n0.0\t13302\t15\n0.0\t10871\t19\n0.0\t13488\t17\n0.0\t6090\t5\n1.0\t1893\t12\n1.0\t364\t23\n1.0\t1321\t11\n1.0\t2260\t20\n1.0\t2434\t17\n1.0\t1112\t9\n1.0\t2198\t19\n1.0\t2041\t14\n1.0\t1728\t13\n1.0\t175\t5\n1.0\t58\t24\n1.0\t2929\t18\n1.0\t51\t1\n1.0\t1180\t21\n1.0\t1067\t8\n1.0\t1969\t15\n1.0\t1066\t22\n1.0\t1472\t10\n1.0\t1068\t7\n1.0\t2309\t16\n1.0\t518\t6\n1.0\t106\t0\n"},{"type":"TEXT","data":""}]},"apps":[],"jobName":"paragraph_1551832707629_-2047834852","id":"20170524-095127_757444423","dateCreated":"2019-03-06T00:38:27+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:7342"},{"title":"Count of Departure Delays by Origin","text":"%sql\nselect origin, count(depdelay)\nfrom flights where depdelay > 40\ngroup by origin\nORDER BY origin","user":"anonymous","dateUpdated":"2019-03-06T00:38:36+0000","config":{"editorSetting":{"language":"sql","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/sql","fontSize":9,"editorHide":false,"title":true,"results":{"0":{"graph":{"mode":"multiBarChart","height":300,"optionOpen":false,"setting":{"multiBarChart":{"rotate":{"degree":"-45"},"xLabelStatus":"default"}},"commonSetting":{},"keys":[{"name":"origin","index":0,"aggr":"sum"}],"groups":[],"values":[{"name":"count(depdelay)","index":1,"aggr":"sum"}]},"helium":{}}},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TABLE","data":"origin\tcount(depdelay)\nATL\t637\nBOS\t296\nDEN\t484\nEWR\t518\nIAH\t447\nLGA\t432\nMIA\t429\nORD\t679\nSFO\t542\n"},{"type":"TEXT","data":""}]},"apps":[],"jobName":"paragraph_1551832707629_559372247","id":"20171123-101839_1671246939","dateCreated":"2019-03-06T00:38:27+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:7343"},{"title":"Count of Departure Delays by Origin","text":"%sql\nSELECT delayed, count(delayed),src\nFROM flights\nGROUP BY src, delayed\norder by  src\n","user":"anonymous","dateUpdated":"2019-03-06T00:38:36+0000","config":{"editorSetting":{"language":"sql","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/sql","fontSize":9,"editorHide":false,"title":true,"results":{"0":{"graph":{"mode":"multiBarChart","height":300,"optionOpen":false,"setting":{"pieChart":{},"multiBarChart":{"stacked":false,"rotate":{"degree":"-45"},"xLabelStatus":"default"}},"commonSetting":{},"keys":[{"name":"src","index":2,"aggr":"sum"}],"groups":[{"name":"delayed","index":0,"aggr":"sum"}],"values":[{"name":"count(delayed)","index":1,"aggr":"sum"}]},"helium":{}}},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TABLE","data":"delayed\tcount(delayed)\tsrc\n1.0\t3106\tATL\n0.0\t27059\tATL\n1.0\t1711\tBOS\n0.0\t16872\tBOS\n1.0\t1755\tCLT\n0.0\t14953\tCLT\n1.0\t2304\tDEN\n0.0\t21106\tDEN\n0.0\t22190\tDFW\n1.0\t2782\tDFW\n1.0\t2328\tEWR\n0.0\t16323\tEWR\n0.0\t15845\tIAH\n1.0\t1829\tIAH\n1.0\t2126\tLAX\n0.0\t24738\tLAX\n0.0\t18538\tLGA\n1.0\t1944\tLGA\n1.0\t2294\tMIA\n0.0\t15695\tMIA\n0.0\t28039\tORD\n1.0\t4033\tORD\n0.0\t11851\tSEA\n1.0\t846\tSEA\n1.0\t2261\tSFO\n0.0\t20100\tSFO\n"},{"type":"TEXT","data":""}]},"apps":[],"jobName":"paragraph_1551832707629_128063605","id":"20171110-211045_792848918","dateCreated":"2019-03-06T00:38:27+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:7344"},{"title":"Count of Departure Delays by Destination","text":"%sql\nselect dst, count(delayed)\nfrom flights where delayed = 1\ngroup by dst\nORDER BY dst\n","user":"anonymous","dateUpdated":"2019-03-06T00:38:36+0000","config":{"editorSetting":{"language":"sql","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/sql","fontSize":9,"editorHide":false,"title":true,"results":{"0":{"graph":{"mode":"multiBarChart","height":300,"optionOpen":false,"setting":{"multiBarChart":{"rotate":{"degree":"-45"},"xLabelStatus":"default"}},"commonSetting":{},"keys":[{"name":"dst","index":0,"aggr":"sum"}],"groups":[],"values":[{"name":"count(delayed)","index":1,"aggr":"sum"}]},"helium":{}}},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TABLE","data":"dst\tcount(delayed)\nATL\t2759\nBOS\t2078\nCLT\t1390\nDEN\t2171\nDFW\t2471\nEWR\t2796\nIAH\t1468\nLAX\t2480\nLGA\t2363\nMIA\t1741\nORD\t3465\nSEA\t1191\nSFO\t2946\n"},{"type":"TEXT","data":""}]},"apps":[],"jobName":"paragraph_1551832707630_-1122948758","id":"20171123-102221_687729087","dateCreated":"2019-03-06T00:38:27+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:7345"},{"title":"Count of Delayed not Delayed by Destination","text":"%sql\nSELECT delayed, count(delayed),dst\nFROM flights\nGROUP BY dst, delayed\norder by dst","user":"anonymous","dateUpdated":"2019-03-06T00:38:36+0000","config":{"editorSetting":{"language":"sql","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/sql","fontSize":9,"editorHide":false,"title":true,"results":{"0":{"graph":{"mode":"multiBarChart","height":300,"optionOpen":false,"setting":{"multiBarChart":{"rotate":{"degree":"-45"},"xLabelStatus":"default"}},"commonSetting":{},"keys":[{"name":"dst","index":2,"aggr":"sum"}],"groups":[{"name":"delayed","index":0,"aggr":"sum"}],"values":[{"name":"count(delayed)","index":1,"aggr":"sum"}]},"helium":{}}},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TABLE","data":"delayed\tcount(delayed)\tdst\n1.0\t2759\tATL\n0.0\t27458\tATL\n0.0\t16612\tBOS\n1.0\t2078\tBOS\n1.0\t1390\tCLT\n0.0\t15409\tCLT\n1.0\t2171\tDEN\n0.0\t21031\tDEN\n0.0\t22476\tDFW\n1.0\t2471\tDFW\n0.0\t15740\tEWR\n1.0\t2796\tEWR\n1.0\t1468\tIAH\n0.0\t16073\tIAH\n0.0\t24389\tLAX\n1.0\t2480\tLAX\n1.0\t2363\tLGA\n0.0\t18071\tLGA\n0.0\t16262\tMIA\n1.0\t1741\tMIA\n1.0\t3465\tORD\n0.0\t28849\tORD\n0.0\t11535\tSEA\n1.0\t1191\tSEA\n1.0\t2946\tSFO\n0.0\t19404\tSFO\n"},{"type":"TEXT","data":""}]},"apps":[],"jobName":"paragraph_1551832707630_662122234","id":"20171122-211508_2036968500","dateCreated":"2019-03-06T00:38:27+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:7346"},{"title":"Count of Departure Delays by Origin, Destination","text":"%sql\nselect src, dst, count(depdelay)\nfrom flights where depdelay > 40\ngroup by src, dst\nORDER BY count(depdelay) desc\n","user":"anonymous","dateUpdated":"2019-03-06T00:38:36+0000","config":{"editorSetting":{"language":"sql","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/sql","fontSize":9,"editorHide":false,"title":true,"results":{"0":{"graph":{"mode":"multiBarChart","height":300,"optionOpen":false,"setting":{"multiBarChart":{"rotate":{"degree":"-45"},"xLabelStatus":"default"}},"commonSetting":{},"keys":[{"name":"src","index":0,"aggr":"sum"}],"groups":[{"name":"dst","index":1,"aggr":"sum"}],"values":[{"name":"count(depdelay)","index":2,"aggr":"sum"}]},"helium":{}}},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TABLE","data":"src\tdst\tcount(depdelay)\nORD\tLGA\t588\nLAX\tSFO\t578\nATL\tEWR\t561\nLGA\tORD\t532\nORD\tSFO\t470\nSFO\tLAX\t463\nATL\tLGA\t445\nORD\tLAX\t425\nORD\tDFW\t423\nDEN\tSFO\t388\nEWR\tATL\t381\nDFW\tORD\t377\nMIA\tLGA\t355\nORD\tEWR\t347\nLGA\tATL\t344\nSFO\tORD\t343\nDFW\tATL\t328\nORD\tATL\t326\nORD\tBOS\t318\nDEN\tLAX\t311\nLAX\tDEN\t303\nORD\tDEN\t302\nSFO\tDEN\t299\nMIA\tATL\t299\nLAX\tORD\t298\nEWR\tORD\t297\nATL\tDFW\t293\nBOS\tLGA\t279\nLGA\tBOS\t276\nDEN\tEWR\t275\nATL\tLAX\t275\nATL\tORD\t273\nBOS\tEWR\t269\nDFW\tSFO\t269\nIAH\tEWR\t269\nBOS\tORD\t267\nDEN\tORD\t265\nIAH\tDFW\t264\nMIA\tORD\t262\nMIA\tDFW\t259\nEWR\tSFO\t257\nATL\tMIA\t255\nEWR\tBOS\t255\nCLT\tEWR\t255\nDFW\tIAH\t255\nLGA\tMIA\t248\nATL\tBOS\t243\nORD\tSEA\t232\nDFW\tDEN\t222\nORD\tIAH\t217\nDFW\tMIA\t217\nDFW\tLAX\t216\nDFW\tLGA\t214\nSFO\tEWR\t214\nCLT\tORD\t213\nORD\tMIA\t212\nEWR\tLAX\t202\nSFO\tDFW\t202\nLAX\tATL\t201\nMIA\tEWR\t201\nDFW\tEWR\t200\nIAH\tSFO\t199\nDEN\tDFW\t198\nMIA\tLAX\t198\nBOS\tATL\t198\nSFO\tSEA\t196\nATL\tDEN\t192\nSEA\tSFO\t191\nIAH\tORD\t189\nEWR\tMIA\t188\nCLT\tATL\t186\nDFW\tCLT\t185\nATL\tSFO\t185\nDEN\tLGA\t184\nLGA\tDEN\t182\nCLT\tBOS\t181\nEWR\tDEN\t178\nMIA\tBOS\t178\nEWR\tIAH\t177\nDFW\tSEA\t174\nLAX\tDFW\t174\nMIA\tCLT\t174\nORD\tCLT\t173\nATL\tCLT\t170\nSFO\tBOS\t165\nMIA\tSFO\t164\nDEN\tATL\t164\nLGA\tDFW\t162\nEWR\tCLT\t162\nEWR\tDFW\t159\nDEN\tSEA\t155\nCLT\tDFW\t155\nIAH\tLGA\t151\nSEA\tORD\t149\nCLT\tLGA\t147\nCLT\tMIA\t144\nLAX\tEWR\t140\nIAH\tDEN\t139\nIAH\tLAX\t136\nIAH\tATL\t136\nSFO\tATL\t128\nSEA\tDEN\t126\nLAX\tMIA\t126\nDFW\tBOS\t125\nCLT\tSFO\t125\nATL\tIAH\t124\nLGA\tCLT\t124\nMIA\tIAH\t123\nSFO\tIAH\t122\nDEN\tIAH\t120\nBOS\tSFO\t120\nBOS\tCLT\t116\nLAX\tBOS\t114\nBOS\tLAX\t113\nDEN\tBOS\t112\nCLT\tDEN\t106\nBOS\tMIA\t97\nSEA\tDFW\t97\nIAH\tMIA\t94\nCLT\tLAX\t93\nATL\tSEA\t90\nIAH\tBOS\t90\nIAH\tCLT\t86\nCLT\tIAH\t86\nBOS\tDFW\t85\nBOS\tDEN\t81\nLGA\tIAH\t76\nIAH\tSEA\t76\nEWR\tSEA\t72\nSFO\tMIA\t70\nLAX\tSEA\t69\nSEA\tATL\t68\nDEN\tCLT\t67\nLAX\tCLT\t65\nDEN\tMIA\t65\nSEA\tEWR\t65\nCLT\tSEA\t64\nBOS\tIAH\t63\nSFO\tCLT\t59\nLAX\tIAH\t58\nSEA\tLAX\t48\nSEA\tIAH\t47\nMIA\tDEN\t41\nMIA\tSEA\t40\nSEA\tMIA\t25\nBOS\tSEA\t23\nSEA\tBOS\t21\nSEA\tCLT\t9\n"},{"type":"TEXT","data":""}]},"apps":[],"jobName":"paragraph_1551832707630_1639197331","id":"20171123-102627_1669385618","dateCreated":"2019-03-06T00:38:27+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:7347"},{"text":"%md\nStratified Sampling\nIn order to ensure that our model is sensitive to the delayed samples we can put the two sample types on the same footing using stratified sampling. The DataFrames sampleBy() function does this when provided with fractions of each sample type to be returned. Here, we're keeping all instances of delayed, but downsampling the not delayed instances to 29%, then displaying the results\n","user":"anonymous","dateUpdated":"2019-03-06T00:38:27+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>Stratified Sampling<br/>In order to ensure that our model is sensitive to the delayed samples we can put the two sample types on the same footing using stratified sampling. The DataFrames sampleBy() function does this when provided with fractions of each sample type to be returned. Here, we&rsquo;re keeping all instances of delayed, but downsampling the not delayed instances to 29%, then displaying the results</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1551832707631_-2114215313","id":"20190305-223154_803200822","dateCreated":"2019-03-06T00:38:27+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:7348"},{"title":"Stratify the sampling to fewer Not Delayed","text":"// keep all delayed , keep 13% not delayed\nval fractions = Map(0.0 -> .13, 1.0->1.0) // \nval df3 =df2.stat.sampleBy(\"delayed\", fractions, 36L)\n// original distribution\ndf2.groupBy(\"delayed\").count.show\n// now\ndf3.groupBy(\"delayed\").count.show\n","user":"anonymous","dateUpdated":"2019-03-06T00:38:27+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+-------+------+\n|delayed| count|\n+-------+------+\n|    0.0|253309|\n|    1.0| 29319|\n+-------+------+\n\n+-------+-----+\n|delayed|count|\n+-------+-----+\n|    0.0|33063|\n|    1.0|29319|\n+-------+-----+\n\nfractions: scala.collection.immutable.Map[Double,Double] = Map(0.0 -> 0.13, 1.0 -> 1.0)\ndf3: org.apache.spark.sql.DataFrame = [id: string, fldate: string ... 14 more fields]\n"}]},"apps":[],"jobName":"paragraph_1551832707631_1375229468","id":"20171123-050717_1328190278","dateCreated":"2019-03-06T00:38:27+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:7349"},{"title":"Split Into Training and Test set","text":"val splitSeed = 5043\nval Array(trainingData, testData) = df3.randomSplit(Array(0.7, 0.3), splitSeed)\ntrainingData.groupBy(\"delayed\").count.show","user":"anonymous","dateUpdated":"2019-03-06T00:38:27+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+-------+-----+\n|delayed|count|\n+-------+-----+\n|    0.0|23149|\n|    1.0|20500|\n+-------+-----+\n\nsplitSeed: Int = 5043\ntrainingData: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [id: string, fldate: string ... 14 more fields]\ntestData: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [id: string, fldate: string ... 14 more fields]\n"}]},"apps":[],"jobName":"paragraph_1551832707632_-335535242","id":"20190305-223741_1028691135","dateCreated":"2019-03-06T00:38:27+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:7350"},{"text":"%md\nIn order for the features to be used by a machine learning algorithm, they must be transformed and put into Feature Vectors, which are vectors of numbers \nrepresenting the value for each feature.\n<img src=\"https://mapr.com/blog/fast-data-processing-pipeline-predicting-flight-delays-using-apache-apis-pt-1/assets/reference-learning-spark.png\">\nSpark ML provides a uniform set of high-level APIs built on top of DataFrames. We will use an ML Pipeline to pass the data through transformers in order to extract the features and an estimator to produce the model.\n<img src=\"https://mapr.com/blog/fast-data-processing-pipeline-predicting-flight-delays-using-apache-apis-pt-1/assets/ml-pipeline.png\">\nTransformer: A Transformer is an algorithm which transforms one DataFrame into another DataFrame. We will use a transformer to get a DataFrame with a features vector column.\nEstimator: An Estimator is an algorithm which can be fit on a DataFrame to produce a Transformer. We will use a an estimator to train a model which can transform data to get predictions.\nPipeline: A Pipeline chains multiple Transformers and Estimators together to specify a ML workflow.","user":"anonymous","dateUpdated":"2019-03-06T00:38:27+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>In order for the features to be used by a machine learning algorithm, they must be transformed and put into Feature Vectors, which are vectors of numbers<br/>representing the value for each feature.<br/><img src=\"https://mapr.com/blog/fast-data-processing-pipeline-predicting-flight-delays-using-apache-apis-pt-1/assets/reference-learning-spark.png\"><br/>Spark ML provides a uniform set of high-level APIs built on top of DataFrames. We will use an ML Pipeline to pass the data through transformers in order to extract the features and an estimator to produce the model.<br/><img src=\"https://mapr.com/blog/fast-data-processing-pipeline-predicting-flight-delays-using-apache-apis-pt-1/assets/ml-pipeline.png\"><br/>Transformer: A Transformer is an algorithm which transforms one DataFrame into another DataFrame. We will use a transformer to get a DataFrame with a features vector column.<br/>Estimator: An Estimator is an algorithm which can be fit on a DataFrame to produce a Transformer. We will use a an estimator to train a model which can transform data to get predictions.<br/>Pipeline: A Pipeline chains multiple Transformers and Estimators together to specify a ML workflow.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1551832707632_-1626606036","id":"20190305-223449_516878384","dateCreated":"2019-03-06T00:38:27+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:7351"},{"text":"%md\n## Feature Extraction and Pipelining\nThe ML package needs the label and feature vector to be added as columns to the input dataframe. We set up a pipeline to pass the data through transformers in order to extract the features and label. \nA StringIndexer is used to to encode a string column to a column of number indices.\nA Bucketizer is used to add a label of delayed 0/1. \nA VectorAssembler combines a given list of columns into a single feature vector column.\n","user":"anonymous","dateUpdated":"2019-03-06T00:38:27+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>Feature Extraction and Pipelining</h2>\n<p>The ML package needs the label and feature vector to be added as columns to the input dataframe. We set up a pipeline to pass the data through transformers in order to extract the features and label.<br/>A StringIndexer is used to to encode a string column to a column of number indices.<br/>A Bucketizer is used to add a label of delayed 0/1.<br/>A VectorAssembler combines a given list of columns into a single feature vector column.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1551832707632_269702219","id":"20170603-184811_78732818","dateCreated":"2019-03-06T00:38:27+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:7352"},{"title":"Use a StringIndexer  to encode categorical columns","text":"// categorical Column names\nval categoricalColumns = Array(\"carrier\", \"src\", \"dst\", \"dofW\", \"orig_dest\")\n\n// a StringIndexer will encode a string categorial column into a column of numbers\nval stringIndexers = categoricalColumns.map { colName =>\n      new StringIndexer()\n        .setInputCol(colName)\n        .setOutputCol(colName + \"Indexed\")\n        .fit(trainingData)\n}\n","user":"anonymous","dateUpdated":"2019-03-06T00:38:27+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"categoricalColumns: Array[String] = Array(carrier, src, dst, dofW, orig_dest)\nstringIndexers: Array[org.apache.spark.ml.feature.StringIndexerModel] = Array(strIdx_610f65c66a7c, strIdx_aa34624e24b0, strIdx_f5c7cbd239ec, strIdx_75867bdabcc5, strIdx_5e3d4edcb613)\n"}]},"apps":[],"jobName":"paragraph_1551832707633_335524887","id":"20170508-150543_958647761","dateCreated":"2019-03-06T00:38:27+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:7353"},{"title":"Use VectorAssembler, a transformer,  to put features into a feature vector column","text":"//a Bucketizer is used to add a label column of delayed 0/1.\nval labeler = new Bucketizer().setInputCol(\"depdelay\").setOutputCol(\"label\").setSplits(Array( 0.0, 40.0, Double.PositiveInfinity))\n\n// list of all the feature columns\nval featureCols = Array(\"carrierIndexed\", \"dstIndexed\", \"srcIndexed\", \"dofWIndexed\", \"orig_destIndexed\",\"crsdephour\", \"crsdeptime\", \"crsarrtime\",\"crselapsedtime\", \"dist\")\n\n//The VectorAssembler combines a given list of columns into a single feature vector column. \nval assembler = new VectorAssembler().setInputCols(featureCols).setOutputCol(\"features\")\n\n","user":"anonymous","dateUpdated":"2019-03-06T00:38:27+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"labeler: org.apache.spark.ml.feature.Bucketizer = bucketizer_9aa65d94a209\nfeatureCols: Array[String] = Array(carrierIndexed, dstIndexed, srcIndexed, dofWIndexed, orig_destIndexed, crsdephour, crsdeptime, crsarrtime, crselapsedtime, dist)\nassembler: org.apache.spark.ml.feature.VectorAssembler = vecAssembler_cbc25c269413\n"}]},"apps":[],"jobName":"paragraph_1551832707633_-2056279743","id":"20170524-223310_2121058884","dateCreated":"2019-03-06T00:38:27+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:7354"},{"title":"Create Random Forest Estimator , set Label and Feature Columns ","text":"// The final element in our ml pipeline is an estimator (a random forest classifier), \n// which will training on the vector of label and features.\nval rf = new RandomForestClassifier().setLabelCol(\"label\").setFeaturesCol(\"features\").setNumTrees(20).setMaxBins(7000).setMaxDepth(10)    ","user":"anonymous","dateUpdated":"2019-03-06T00:38:27+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"rf: org.apache.spark.ml.classification.RandomForestClassifier = rfc_c01c537ab5d0\n"}]},"apps":[],"jobName":"paragraph_1551832707633_-1772588151","id":"20170603-185445_276463997","dateCreated":"2019-03-06T00:38:27+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:7355"},{"text":"%md\n## Setup Spark ML pipeline stages\nSet up a pipeline to pass the data through transformers to extract the features and label, and pass this to a random forest estimator to fit the model \n","user":"anonymous","dateUpdated":"2019-03-06T00:38:27+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>Setup Spark ML pipeline stages</h2>\n<p>Set up a pipeline to pass the data through transformers to extract the features and label, and pass this to a random forest estimator to fit the model</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1551832707634_-89969923","id":"20170601-154525_1033166149","dateCreated":"2019-03-06T00:38:27+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:7356"},{"title":"Set up pipeline with  feature transformers and model estimator","text":"// Below we chain the stringindexers, vector assembler and randomforest in a Pipeline.\nval steps = stringIndexers ++ Array(labeler, assembler, rf)\nval pipeline = new Pipeline().setStages(steps)\n","user":"anonymous","dateUpdated":"2019-03-06T00:38:27+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"steps: Array[org.apache.spark.ml.PipelineStage with org.apache.spark.ml.util.MLWritable{def copy(extra: org.apache.spark.ml.param.ParamMap): org.apache.spark.ml.PipelineStage with org.apache.spark.ml.util.MLWritable{def copy(extra: org.apache.spark.ml.param.ParamMap): org.apache.spark.ml.PipelineStage with org.apache.spark.ml.util.MLWritable}}] = Array(strIdx_610f65c66a7c, strIdx_aa34624e24b0, strIdx_f5c7cbd239ec, strIdx_75867bdabcc5, strIdx_5e3d4edcb613, bucketizer_9aa65d94a209, vecAssembler_cbc25c269413, rfc_c01c537ab5d0)\npipeline: org.apache.spark.ml.Pipeline = pipeline_07fbdb60ddb8\n"}]},"apps":[],"jobName":"paragraph_1551832707634_162802526","id":"20170508-151557_1422077156","dateCreated":"2019-03-06T00:38:27+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:7357"},{"title":"Train the Model","text":"val model = pipeline.fit(trainingData)","user":"anonymous","dateUpdated":"2019-03-06T00:38:27+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"ERROR","msg":[{"type":"TEXT","data":"java.net.ConnectException: Connection refused (Connection refused)\n\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n\tat java.net.Socket.connect(Socket.java:589)\n\tat org.apache.thrift.transport.TSocket.open(TSocket.java:182)\n\tat org.apache.zeppelin.interpreter.remote.ClientFactory.create(ClientFactory.java:51)\n\tat org.apache.zeppelin.interpreter.remote.ClientFactory.create(ClientFactory.java:37)\n\tat org.apache.commons.pool2.BasePooledObjectFactory.makeObject(BasePooledObjectFactory.java:60)\n\tat org.apache.commons.pool2.impl.GenericObjectPool.create(GenericObjectPool.java:861)\n\tat org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:435)\n\tat org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:363)\n\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreterProcess.getClient(RemoteInterpreterProcess.java:62)\n\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreterProcess.callRemoteFunction(RemoteInterpreterProcess.java:133)\n\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreter.interpret(RemoteInterpreter.java:228)\n\tat org.apache.zeppelin.notebook.Paragraph.jobRun(Paragraph.java:437)\n\tat org.apache.zeppelin.scheduler.Job.run(Job.java:188)\n\tat org.apache.zeppelin.scheduler.RemoteScheduler$JobRunner.run(RemoteScheduler.java:315)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n"}]},"apps":[],"jobName":"paragraph_1551832707634_170516301","id":"20171129-113112_994877662","dateCreated":"2019-03-06T00:38:27+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:7358"},{"title":"Print out the feature importances for the random forest model","text":"// Print out the feature importances\nval rfm = model.stages.last.asInstanceOf[RandomForestClassificationModel]\nval featureImportances =rfm.featureImportances\nassembler.getInputCols.zip(featureImportances.toArray).sortBy(-_._2).foreach { case (feat, imp) => println(s\"feature: $feat, importance: $imp\") }\n\nassembler.getInputCols.zip(featureImportances.toArray).sortBy(-_._2).foreach { case (feat, imp) => println(s\"feature: $feat, importance: $imp\") }\n","user":"anonymous","dateUpdated":"2019-03-06T00:38:27+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"feature: crsdeptime, importance: 0.25434598344579173\nfeature: crsarrtime, importance: 0.22645018613800164\nfeature: orig_destIndexed, importance: 0.19194350367566315\nfeature: crsdephour, importance: 0.11921205532664048\nfeature: destIndexed, importance: 0.06609553590373374\nfeature: dofWIndexed, importance: 0.03781167379653163\nfeature: carrierIndexed, importance: 0.037636670623576896\nfeature: dist, importance: 0.03445973902781022\nfeature: originIndexed, importance: 0.017004831687461995\nfeature: crselapsedtime, importance: 0.015039820374788621\nfeatureImportances: org.apache.spark.ml.linalg.Vector = (10,[0,1,2,3,4,5,6,7,8,9],[0.037636670623576896,0.06609553590373374,0.017004831687461995,0.03781167379653163,0.19194350367566315,0.11921205532664048,0.25434598344579173,0.22645018613800164,0.015039820374788621,0.03445973902781022])\n"}]},"apps":[],"jobName":"paragraph_1551832707635_374536110","id":"20171122-232203_359528816","dateCreated":"2019-03-06T00:38:27+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:7359"},{"text":"val bestEstimatorParamMap = pipelineModel.getEstimatorParamMaps.zip(pipelineModel.avgMetrics).maxBy(_._2)._1\nprintln(s\"Best params:\\n$bestEstimatorParamMap\")","user":"anonymous","dateUpdated":"2019-03-06T00:38:27+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"Best params:\n{\n\trfc_ac7eebf816e9-impurity: gini,\n\trfc_ac7eebf816e9-maxBins: 200,\n\trfc_ac7eebf816e9-maxDepth: 4,\n\trfc_ac7eebf816e9-numTrees: 20\n}\nbestEstimatorParamMap: org.apache.spark.ml.param.ParamMap =\n{\n\trfc_ac7eebf816e9-impurity: gini,\n\trfc_ac7eebf816e9-maxBins: 200,\n\trfc_ac7eebf816e9-maxDepth: 4,\n\trfc_ac7eebf816e9-numTrees: 20\n}\n"}]},"apps":[],"jobName":"paragraph_1551832707635_973763743","id":"20171122-232845_814296940","dateCreated":"2019-03-06T00:38:27+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:7360"},{"text":"%md\r\n## Evaluate the model on a test set\r\nThe actual performance of the model can be determined using the test data set which has not been used for any training or cross-validation activities. We'll transform the test set with the model pipeline, which will map the features according to the same recipe. \r\n","user":"anonymous","dateUpdated":"2019-03-06T00:38:27+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>Evaluate the model on a test set</h2>\n<p>The actual performance of the model can be determined using the test data set which has not been used for any training or cross-validation activities. We&rsquo;ll transform the test set with the model pipeline, which will map the features according to the same recipe.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1551832707636_-514543245","id":"20170602-155317_1487132664","dateCreated":"2019-03-06T00:38:27+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:7361"},{"title":"Get Predictions from Test data","text":"//transform the test set with the model pipeline,\n//which will map the features according to the same recipe\n\nval predictions = pipelineModel.transform(testData)\n","user":"anonymous","dateUpdated":"2019-03-06T00:38:27+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"predictions: org.apache.spark.sql.DataFrame = [_id: string, dofW: int ... 22 more fields]\n"}]},"apps":[],"jobName":"paragraph_1551832707636_-1767247200","id":"20170508-155848_1997894070","dateCreated":"2019-03-06T00:38:27+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:7362"},{"text":"%md\nAccuracy is measured by the area under the ROC curve. The area measures the ability of the test to correctly classify true positives from false positives. A random predictor would have .5 accuracy. The closer the value is to 1 the better its predictions are. \n\n","user":"anonymous","dateUpdated":"2019-03-06T00:38:27+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>Accuracy is measured by the area under the ROC curve. The area measures the ability of the test to correctly classify true positives from false positives. A random predictor would have .5 accuracy. The closer the value is to 1 the better its predictions are.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1551832707636_-593840996","id":"20170602-161538_1648758337","dateCreated":"2019-03-06T00:38:27+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:7363"},{"title":"Evaluate the predictions accuracy","text":"\nval areaUnderROC = evaluator.evaluate(predictions)\nprintln(\"areaUnderROC \"  + areaUnderROC)\n","user":"anonymous","dateUpdated":"2019-03-06T00:38:27+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"areaUnderROC 0.6945482322554366\nareaUnderROC: Double = 0.6945482322554366\n"}]},"apps":[],"jobName":"paragraph_1551832707637_-158667689","id":"20170602-155622_1453197792","dateCreated":"2019-03-06T00:38:27+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:7364"},{"title":"Calculate some more metrics","text":"val lp = predictions.select( \"label\", \"prediction\")\nval counttotal = predictions.count()\nval correct = lp.filter($\"label\" === $\"prediction\").count()\nval wrong = lp.filter(not($\"label\" === $\"prediction\")).count()\nval truep =( lp.filter($\"prediction\" === 0.0).filter($\"label\" === $\"prediction\").count()) /counttotal.toDouble\nval truen = (lp.filter($\"prediction\" === 1.0).filter($\"label\" === $\"prediction\").count())/counttotal.toDouble\nval falsen = (lp.filter($\"prediction\" === 0.0).filter(not($\"label\" === $\"prediction\")).count())/counttotal.toDouble\nval falsep = (lp.filter($\"prediction\" === 1.0).filter(not($\"label\" === $\"prediction\")).count())/counttotal.toDouble\nval ratioWrong=wrong.toDouble/counttotal.toDouble\nval ratioCorrect=correct.toDouble/counttotal.toDouble\n\nval precision = truep / (truep + falsep)\nval recall = truep / (truep + falsen)\nval fmeasure = 2 * precision * recall / (precision + recall)","user":"anonymous","dateUpdated":"2019-03-06T00:38:27+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"lp: org.apache.spark.sql.DataFrame = [label: double, prediction: double]\ncounttotal: Long = 41348\ncorrect: Long = 25286\nwrong: Long = 16062\ntruep: Double = 0.5360839702041211\ntruen: Double = 0.0754570958692077\nfalsen: Double = 0.03477798200638483\nfalsep: Double = 0.35368095192028637\nratioWrong: Double = 0.3884589339266712\nratioCorrect: Double = 0.6115410660733288\nprecision: Double = 0.6025006795324817\nrecall: Double = 0.9390781223521437\nfmeasure: Double = 0.7340464284531576\n"}]},"apps":[],"jobName":"paragraph_1551832707637_-318005811","id":"20181015-224231_2027590368","dateCreated":"2019-03-06T00:38:27+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:7365"},{"text":"println( \"ratio Correct\" + ratioCorrect +\"\\nratio wrong \"+ratioWrong +\"\\ntrue positive \"+truep + \"\\ntrue negative \"+ truen + \"\\nfalse negative \" + falsen+  \"\\nfalse positive \"+ falsep )","user":"anonymous","dateUpdated":"2019-03-06T00:38:27+0000","config":{"tableHide":false,"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"ratio Correct0.6115410660733288\nratio wrong 0.3884589339266712\ntrue positive 0.5360839702041211\ntrue negative 0.0754570958692077\nfalse negative 0.03477798200638483\nfalse positive 0.35368095192028637\n"}]},"apps":[],"jobName":"paragraph_1551832707637_-972521865","id":"20181004-211413_1357524146","dateCreated":"2019-03-06T00:38:27+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:7366"},{"text":"println( \"\\nprecision \"+ precision+ \"\\nrecall \" + recall+ \"\\nf_measure \" + fmeasure )","user":"anonymous","dateUpdated":"2019-03-06T00:38:27+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\nprecision 0.6025006795324817\nrecall 0.9390781223521437\nf_measure 0.7340464284531576\n"}]},"apps":[],"jobName":"paragraph_1551832707638_435892652","id":"20181015-213933_2083506099","dateCreated":"2019-03-06T00:38:27+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:7367"},{"text":"predictions.select(\"label\",\"prediction\",\"crsdephour\").show","user":"anonymous","dateUpdated":"2019-03-06T00:38:27+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+-----+----------+----------+\n|label|prediction|crsdephour|\n+-----+----------+----------+\n|  0.0|       0.0|        11|\n|  0.0|       0.0|        13|\n|  0.0|       0.0|        14|\n|  0.0|       1.0|        16|\n|  0.0|       1.0|        18|\n|  0.0|       1.0|        19|\n|  0.0|       0.0|        22|\n|  0.0|       0.0|         9|\n|  0.0|       0.0|        10|\n|  0.0|       0.0|        11|\n|  0.0|       0.0|        13|\n|  0.0|       0.0|        14|\n|  0.0|       0.0|        14|\n|  0.0|       0.0|        15|\n|  1.0|       1.0|        16|\n|  1.0|       1.0|        18|\n|  0.0|       1.0|        19|\n|  1.0|       1.0|        21|\n|  0.0|       0.0|        22|\n|  0.0|       0.0|         7|\n+-----+----------+----------+\nonly showing top 20 rows\n\n"}]},"apps":[],"jobName":"paragraph_1551832707638_-234229197","id":"20171107-112947_525619195","dateCreated":"2019-03-06T00:38:27+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:7368"},{"user":"anonymous","dateUpdated":"2019-03-06T00:38:27+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1551832707638_1137752316","id":"20171122-091021_1615582434","dateCreated":"2019-03-06T00:38:27+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:7369"}],"name":"FlightMaprDB","id":"2E7XZ7E8D","noteParams":{},"noteForms":{},"angularObjects":{"md:shared_process":[],"spark:shared_process":[]},"config":{"isZeppelinNotebookCronEnable":false,"looknfeel":"default","personalizedMode":"false"},"info":{}}